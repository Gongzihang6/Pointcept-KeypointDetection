{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\u9996\u9875","text":"<p>   \ud83c\udfa8 \u6362\u4e2a\u989c\u8272\uff0c\u6362\u4e2a\u5fc3\u60c5 </p> red pink purple indigo blue cyan teal green orange brown grey black"},{"location":"#pointcept-keypointdetection","title":"Pointcept-KeypointDetection","text":"<p>Note</p> <p>Pointcept-KeypointDetection \u662f\u4e00\u4e2a\u57fa\u4e8e Pointcept \u6846\u67b6\u7684 3D \u5173\u952e\u70b9\u68c0\u6d4b\u9879\u76ee\u3002</p> <p></p>Figure 1: License<p></p>"},{"location":"#_1","title":"\u2728 \u4e3b\u8981\u7279\u6027","text":"<ul> <li>\ud83d\ude80 \u9ad8\u6027\u80fd\uff1a\u57fa\u4e8e Pointcept \u7684\u9ad8\u6548\u5b9e\u73b0\u3002</li> <li>\ud83d\udcd0 \u7cbe\u786e\uff1a\u9488\u5bf9 3D \u70b9\u4e91\u7684\u7cbe\u786e\u5173\u952e\u70b9\u5b9a\u4f4d\u3002</li> <li>\ud83d\udee0\ufe0f \u6613\u7528\uff1a\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u6613\u4e8e\u6269\u5c55\u3002</li> </ul>"},{"location":"#_2","title":"\ud83d\udce6 \u5feb\u901f\u9884\u89c8","text":"\u793a\u4f8b\u4ee3\u7801 <pre><code># \u8fd9\u662f\u4e00\u4e2a\u4ee3\u7801\u793a\u4f8b\nimport pointcept\nprint(\"Hello Pointcept!\")\n</code></pre>"},{"location":"#_3","title":"\u5b89\u88c5\u6307\u5357","text":""},{"location":"#_4","title":"\u73af\u5883\u8981\u6c42","text":"<ul> <li>Python &gt;= 3.8</li> <li>PyTorch &gt;= 1.10</li> <li>CUDA \u53ef\u7528</li> </ul>"},{"location":"#_5","title":"\u5b89\u88c5\u6b65\u9aa4","text":"<ol> <li>\u514b\u9686\u4ed3\u5e93\uff1a    <pre><code>git clone https://github.com/Gongzihang6/Pointcept-KeypointDetection.git\n</code></pre></li> </ol>"},{"location":"models/PointTransformer/","title":"PointTransformer","text":"<p>   \ud83c\udfa8 \u6362\u4e2a\u989c\u8272\uff0c\u6362\u4e2a\u5fc3\u60c5 </p>  red   pink   purple   indigo   blue   cyan   teal   green   orange   brown   grey   black"},{"location":"models/PointTransformer/#point-transformer","title":"Point Transformer","text":""},{"location":"models/PointTransformer/#ptv1","title":"PTv1","text":"<p>\u5173\u952e\u8bcd\uff1a\u5411\u91cf\u6ce8\u610f\u529b\uff08Vector Attention\uff09\u3001\u5c40\u90e8\u90bb\u57df\uff08Local Neighborhood\uff09\u3001\u53ef\u5b66\u4e60\u4f4d\u7f6e\u7f16\u7801\uff1b</p>"},{"location":"models/PointTransformer/#_1","title":"\u80cc\u666f","text":"<p>Self-attention \u5728 NLP \u548c 2D \u56fe\u50cf\u9886\u57df\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u70b9\u4e91\u672c\u8d28\u4e0a\u662f\u5d4c\u5165\u5728\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u7684\u51e0\u4f55\uff0c\u5177\u6709\u6392\u5217\u4e0d\u53d8\u6027\uff0c\u8fd9\u4e0e transformer \u7684\u6838\u5fc3\u64cd\u4f5c\uff08\u81ea\u6ce8\u610f\u529b\uff0c\u96c6\u5408\u7b97\u5b50\uff08Set Operator\uff09\uff09\u9ad8\u5ea6\u5951\u5408\u3002</p> <p>\u89e3\u51b3\u7684\u95ee\u9898\uff1a</p> <ul> <li>\u4ee5\u5f80\u7684\u70b9\u4e91\u7f51\u7edc\uff08\u5982 Pointnet++\uff09\u4f7f\u7528\u6700\u5927\u6c60\u5316\u6765\u805a\u5408\u4fe1\u606f\uff0c\u53ef\u80fd\u4e22\u5931\u5c40\u90e8\u7ec6\u8282\uff1b</li> <li>\u4ee5\u5f80\u7684 3D \u6ce8\u610f\u529b\u5c1d\u8bd5\u901a\u5e38\u662f\u5168\u5c40\u7684\uff08\u8ba1\u7b97\u91cf\u8fc7\u5927\uff09\u6216\u76f4\u63a5\u6cbf\u7528\u6807\u91cf\u70b9\u79ef\u6ce8\u610f\u529b\uff08Scalar Dot-production Attention\uff09\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528 3D \u7a7a\u95f4\u4fe1\u606f\uff1b</li> </ul> <p>\u6838\u5fc3\u521b\u65b0\u4e0e\u7f51\u7edc\u7ed3\u6784\uff1a</p> <p>1\u3001Point Transformer Layer (\u6838\u5fc3\u5c42) \u8fd9\u662f\u7f51\u7edc\u7684\u57fa\u672c\u6784\u5efa\u5757\uff0c\u5176\u6838\u5fc3\u662f \u5411\u91cf\u81ea\u6ce8\u610f\u529b (Vector Self-Attention) \u673a\u5236\uff0c\u800c\u975e\u6807\u51c6\u7684\u6807\u91cf\u6ce8\u610f\u529b\u3002\u4f20\u7edf\u7684\u6807\u91cf\u6ce8\u610f\u529b\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u70b9\u7684\u6743\u91cd\uff0c\u7136\u540e\u5bf9\u6bcf\u4e2a\u70b9\u7684\u6240\u6709\u7279\u5f81\u90fd\u6309\u7167\u540c\u4e00\u4e2a\u6743\u91cd\u8fdb\u884c\u52a0\u6743\uff0c\u7136\u540e\u7d2f\u52a0\u6c42\u548c\uff1b\u4f46\u662f\u5411\u91cf\u81ea\u6ce8\u610f\u529b\uff0c\u901a\u8fc7 mlp \u8ba1\u7b97\u70b9\u7684\u76f8\u5bf9\u6743\u91cd\uff08\u4f7f\u7528 <code>x_k-x_q+p_r</code> \u4f5c\u4e3a\u7279\u5f81\uff09\u65f6\uff0c\u628a\u70b9\u7684\u7279\u5f81\u7ef4\u5ea6\u5206\u4e3a \\(s\\) \u7ec4\uff0c\u8fd9\u6837\u8ba1\u7b97\u67d0\u4e2a\u70b9\u7684\u8d21\u732e\u65f6\uff0c\u5b83\u7684\u6240\u6709\u7279\u5f81\u4e0d\u662f\u90fd\u5177\u6709\u76f8\u540c\u7684\u8d21\u732e\uff0c\u7279\u5f81\u805a\u5408\u548c\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u3002\u5177\u4f53\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a</p> \\[ y_{i} = \\sum_{x_{j} \\in \\mathcal{X}(i)} \\rho(\\gamma(\\varphi(x_{i}) - \\psi(x_{j}) + \\delta)) \\odot (\\alpha(x_{j}) + \\delta) \\] <p>\u5176\u4e2d \\(\\mathcal{X}(i)\\) \u8868\u793a \\(x_i\\) \u7684\u90bb\u57df\uff0c \\(\\alpha()\\) \u8868\u793a\u7ebf\u6027\u53d8\u6362 <code>linear_v</code>\uff0c\u7c7b\u4f3c\u81ea\u6ce8\u610f\u529b\u91cc\u9762\u7684 \\(W^V\\)\uff1b\\(\\delta\\) \u662f\u4f4d\u7f6e\u7f16\u7801\uff0c\u4f7f\u7528\u5f53\u524d\u70b9\u548c\u5f53\u524d\u70b9\u7684 KNN \u83b7\u53d6\u7684\u90bb\u5c45\u70b9\u7684\u5750\u6807\u5dee\u4f7f\u7528 <code>linear_p</code> \u7ebf\u6027\u53d8\u6362\u83b7\u53d6\uff1b\\(\\varphi()\\) \u8868\u793a\u7ebf\u6027\u53d8\u6362 <code>linear_k</code>\uff0c\\(\\psi()\\) \u8868\u793a\u7ebf\u6027\u53d8\u6362 <code>linear_q</code>\uff0c\u76f8\u5f53\u4e8e\u81ea\u6ce8\u610f\u529b\u91cc\u9762\u7684 \\(W^K\\) \u548c \\(W^Q\\)\uff1b\\(\\gamma()\\) \u662f\u7ebf\u6027\u53d8\u6362 <code>linear_W</code>\uff0c\u7528\u4e8e\u8ba1\u7b97\u6743\u91cd\uff1b\\(\\rho()\\) \u662f\u5f52\u4e00\u5316\u51fd\u6570\uff0c\u5c06\u6743\u91cd\u5f52\u4e00\u5316\uff0c\u6bd4\u5982 softmax \u51fd\u6570\uff1b\\(\\odot\\) \u662f\u54c8\u8fbe\u739b\u79ef\uff0c\u8868\u793a\u9010\u5143\u7d20\u76f8\u4e58\uff1b</p> <p>\u5176\u4e2d \\(x_i(n,c)\\) \u662f\u6211\u4eec\u5f53\u524d\u8981\u66f4\u65b0\u7279\u5f81\u7684\u70b9\uff0c\\(x_j(n,k,c)\\) \u662f \\(x_i\\) \u4f7f\u7528 KNN \u67e5\u8be2\u83b7\u53d6\u5230\u7684\u90bb\u5c45\u70b9\uff0c\u6240\u4ee5\u5750\u6807\u5dee\u7684\u5f62\u72b6\u662f \\((n,k,c)\\)\uff0c\u6743\u91cd\u5f62\u72b6\u4e3a \\((n,k,c/s)\\)\uff1b\u5728\u8ba1\u7b97\u7684\u65f6\u5019\uff0c\u5c06 \\(\\alpha(x_j)\\) \u7684 \\((n,k,c)\\) \u62c6\u5206\u4e3a \\((n,k,s,c/s)\\)\uff0c\u4e5f\u5c31\u662f\u5c06\u901a\u9053\u7ef4\u5206\u7ec4\uff0c\u5206\u6210 \\(s\\) \u7ec4\uff0c\u7ec4\u5185\u5171\u4eab\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u7ec4\u95f4\u6743\u91cd\u4e0d\u540c\uff0c\u5b9e\u73b0\u66f4\u7ec6\u7c92\u5ea6\u7684\u63a7\u5236\uff0c\u7ec4 \\(s\\) \u8d8a\u5c0f\uff0c\u7c92\u5ea6\u8d8a\u7ec6\u3002</p> <p>2\u3001\u5c40\u90e8\u6ce8\u610f\u529b\uff1a \u4e3a\u4e86\u5904\u7406\u5927\u89c4\u6a21\u573a\u666f\uff0c\u6ce8\u610f\u529b\u9650\u5236\u5728\u5c40\u90e8\u90bb\u57df\u5185\uff08\u901a\u8fc7 k-NN \u641c\u7d22 \\(k\\) \u4e2a\u6700\u8fd1\u90bb\uff09\uff0c\u800c\u4e0d\u662f\u5168\u5c40 \u3002</p> <p>\u6574\u4f53\u67b6\u6784</p> <p>\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6574\u4f53\u67b6\u6784\u91c7\u7528\u4e86\u7ecf\u5178\u7684 U-Net \u7ed3\u6784\uff08\u7f16\u7801\u5668-\u89e3\u7801\u5668\uff09\uff0c\u5305\u542b\u4e0b\u91c7\u6837\uff08Transition Down\uff09\u548c\u4e0a\u91c7\u6837\uff08Transition Up\uff09\u6a21\u5757\uff0c\u4ee5\u53ca\u6838\u5fc3\u7684 point transformer block\uff08\u501f\u9274\u4e86 Botterneck \u7684\u7ed3\u6784\uff09</p> <p></p>Figure 1: ptv1 \u7f51\u7edc\u6574\u4f53\u67b6\u6784\u56fe<p></p>"},{"location":"models/PointTransformer/#transition-down","title":"transition down","text":"<p>\u4e0b\u91c7\u6837\u6a21\u5757\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u56fe\u6d41\u7a0b\u6240\u793a\uff0c\u4e3b\u8981\u5305\u62ec FPS \u6700\u8fdc\u70b9\u91c7\u6837\u548c KNN \u90bb\u57df\u67e5\u8be2\uff0c\u5bf9\u4e8e\u539f\u59cb\u8f93\u5165\u70b9\u5750\u6807\uff08\u901a\u5e38\u662f \\(x,y,z\\)\uff09\u548c\u7279\u5f81\uff08\u901a\u5e38\u662f\u989c\u8272 RGB \u6216\u8005\u6cd5\u5411\u91cf\uff09\uff0c\u5047\u8bbe\u539f\u59cb\u8f93\u5165\u70b9\u4e91\u70b9\u4e2a\u6570\u4e3a \\(N\\)\uff0c\u9996\u5148\u7ecf\u8fc7 FPS \u4e0b\u91c7\u6837\u9009\u62e9 \\(M\\) \u4e2a\u70b9\u4f5c\u4e3a\u7279\u5f81\u70b9\uff0c\u7136\u540e\u4ee5\u8fd9 \\(M\\) \u4e2a\u7279\u5f81\u70b9\u4e3a\u4e2d\u5fc3\uff0c\u67e5\u8be2\u90bb\u57df\u5185\u6700\u8fd1\u7684 \\(K\\) \u4e2a\u70b9\uff0c\u805a\u5408\u8fd9 \\(K\\) \u4e2a\u70b9\u7684\u5750\u6807\u548c\u7279\u5f81\uff0c\u8fd9\u5c31\u5f97\u5230\u4e86 Linear \u5c42\u7684\u8f93\u5165 \\((M,K,C_{in}+3)\\)\uff0c\u7136\u540e\u7ecf\u8fc7 Linear \u5c42\u5904\u7406\uff0c\u63d0\u5347\u7279\u5f81\u7ef4\u5ea6\u5230 \\(C_{out}\\)\uff0c\u7136\u540e\u5728 \\(K\\) \u8fd9\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u6700\u5927\u6c60\u5316\uff0c\u5f97\u5230\u8fd9 \\(M\\) \u4e2a\u70b9\u7684\u65b0\u7279\u5f81 \\((M,C_{out})\\)\uff0c\u7136\u540e\u548c\u8fd9 \\(M\\) \u4e2a\u70b9\u7684\u5750\u6807\uff0c\u4e00\u8d77\u8fd4\u56de\u3002</p> <p></p>Figure 2: Generated Image December 25, 2025 - 5_28PM<p></p> <p>\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a\u4f4d\u4e8e <code>pointcept/models/point_transformer/point_transformer_seg.py</code> \u4e2d</p> Note <pre><code>def forward(self, pxo):\n    p, x, o = pxo  # (n, 3), (n, c), (b)\n    if self.stride != 1:\n        n_o, count = [o[0].item() // self.stride], o[0].item() // self.stride   # \u8ba1\u7b97\u4e0b\u91c7\u6837\u540e\u7684\u70b9\u4e91\u6570\u91cf\n        for i in range(1, o.shape[0]):\n            count += (o[i].item() - o[i - 1].item()) // self.stride\n            n_o.append(count)\n            n_o = torch.cuda.IntTensor(n_o)\n\n            # [\u6838\u5fc3\u64cd\u4f5c 1] \u6700\u8fdc\u70b9\u91c7\u6837 (FPS)\n            # \u4ece\u539f\u59cb\u70b9\u4e91 p \u4e2d\uff0c\u6839\u636e n_o \u89c4\u5b9a\u7684\u6570\u91cf\uff0c\u91c7\u6837\u51fa\u5206\u5e03\u6700\u8fdc\u7684\u5173\u952e\u70b9\u7d22\u5f15 idx\n            # idx \u5f62\u72b6\u4e3a (m)\uff0cm \u662f\u4e0b\u91c7\u6837\u540e\u7684\u603b\u70b9\u6570\uff0c\u4e0b\u91c7\u6837\u540e\u7684\u603b\u70b9\u6570\u7531stride\u51b3\u5b9a\n            idx = pointops.farthest_point_sampling(p, o, n_o)  # (m)\n            # \u83b7\u53d6\u91c7\u6837\u540e\u7684\u65b0\u5750\u6807 n_p\uff0c\u5f62\u72b6 (m, 3)\n            n_p = p[idx.long(), :]  # (m, 3)\n\n            # [\u6838\u5fc3\u64cd\u4f5c 2] kNN \u67e5\u8be2\u4e0e\u5206\u7ec4\n            # \u5bf9\u4e8e\u6bcf\u4e2a\u65b0\u70b9 n_p\uff0c\u5728\u8001\u70b9 p \u4e2d\u627e\u5230\u6700\u8fd1\u7684 nsample \u4e2a\u90bb\u5c45\n            # \u5e76\u5c06\u90bb\u5c45\u7684\u7279\u5f81\u805a\u96c6\u8d77\u6765\uff0cknn\u67e5\u8be2\u7684\u90bb\u57df\u70b9\u6570\u91cf\u7531nsample\u51b3\u5b9a\n            x, _ = pointops.knn_query_and_group(\n                x,                      # \u8f93\u5165\u7279\u5f81\n                p,                      # \u8f93\u5165\u5750\u6807\n                offset=o,               # \u8f93\u5165 offset\n                new_xyz=n_p,            # \u4e2d\u5fc3\u70b9\u5750\u6807 (\u65b0\u7684\u70b9)\n                new_offset=n_o,         # \u4e2d\u5fc3\u70b9 offset\n                nsample=self.nsample,   # kNN \u7684 k (\u5982 16)\n                with_xyz=True,          # \u5173\u952e\u53c2\u6570\uff1aTrue \u8868\u793a\u8fd4\u56de\u7684\u7279\u5f81\u4e2d\u5305\u542b\u76f8\u5bf9\u5750\u6807 (p_neighbor - p_center)\n            )   # \u6b64\u65f6 x \u7684\u5f62\u72b6\u901a\u5e38\u4e3a (m, nsample, 3 + c)\n            x = self.relu(\n                self.bn(self.linear(x).transpose(1, 2).contiguous())\n            )  # (m, c_out, nsample)\n            x = self.pool(x).squeeze(-1)  # (m, c_out)\n            p, o = n_p, n_o     # m 3  m\n        else:   # \u5982\u679c\u6b65\u957fstride\u4e3a1\uff0c\u4e0d\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u76f4\u63a5\u8fdb\u884c\u7ebf\u6027\u53d8\u6362\n            x = self.relu(self.bn(self.linear(x)))  # (n, c_out)\n            return [p, x, o]\n</code></pre>"},{"location":"models/PointTransformer/#point-transformer-block","title":"point transformer block","text":"<p>\u8fd9\u91cc\u501f\u9274\u4e86 BottnerNeck \u7684\u6b8b\u5dee\u8fde\u63a5\u7ed3\u6784\uff0c\u907f\u514d\u7f51\u7edc\u5c42\u6570\u5bfc\u81f4\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002\u5177\u4f53\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\uff1a</p> <p></p>Figure 3: point transformer block<p></p> <p>\u6838\u5fc3\u662f\u4e2d\u95f4\u7684 point Transformer Layer \u5c42\uff0c\u524d\u9762\u5df2\u7ecf\u4ecb\u7ecd\u4e86\u516c\u5f0f\u548c\u8ba1\u7b97\u6d41\u7a0b\u3002\u4e0b\u9762\u662f\u5b9e\u73b0\u4ee3\u7801\uff1a</p> Note <pre><code>class PointTransformerLayer(nn.Module):\n    \"\"\"\n    point transformer\u5c42\n    \u201c\u4f53\u4f1a\u57fa\u4e8eMLP\u7684\u5411\u91cf\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u666e\u901a\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u5dee\u5f02\u201d\n    \u6839\u636e\u8bba\u6587\u4e2dfig 2\u7ed3\u6784\uff0c\u672c\u8d28\u4e0a\u5c31\u662f\u5bf9\u8f93\u5165\u70b9\u4e91\u8fdb\u884c\u5982\u4e0b\u64cd\u4f5c\uff1a\n    1\u3001\u5bf9\u8f93\u5165\u70b9\u4e91\u7684\u7279\u5f81x\u8fdb\u884c\u7ebf\u6027\u53d8\u6362\uff0c\u5f97\u5230\u67e5\u8be2\u70b9\u3001\u952e\u70b9\u3001\u503c\u70b9\u7684\u7279\u5f81\u8868\u793a\uff1b\n    2\u3001\u5bf9\u952e\u70b9\u548c\u503c\u70b9\u8fdb\u884cknn_and_group\u64cd\u4f5c\uff0c\u5f97\u5230\u6bcf\u4e2a\u67e5\u8be2\u70b9\u7684nsample\u4e2a\u6700\u8fd1\u90bb\u952e\u70b9\u7684\u7279\u5f81\u8868\u793a\uff1b\n                Input: (p, x, o)\n                        |\n    +-----------------+-----------------+\n    |                 |                 |\n[linear_q]        [linear_k]        [linear_v]\n    |                 |                 |\n    x_q               x_k               x_v\n    |                 |                 |\n    |          [ KNN &amp; Grouping ] &lt;-----+--- (uses p, o)\n    |           /     |             \\\n    |    (neighbors) (neighbors)  (relative p)\n    |      x_k       x_v             p_r\n    |       |         |               |\n    |       |         |          [linear_p]\n    |       |         |               |\n    |       |         |               v (pos encoding)\n    |       |         |           +---+---+\n    |       |         |           |       |\n    v       v         |           v       v\n(x_k - x_q + p_r)    |        (x_v  +  p_r)\n        |             |               |\n    (r_qk)           |               |\n        |             |               |\n    [linear_w]        |               |\n        |             |               |\n    [Softmax]         |               |\n        |             |               |\n        (w)             |               |\n        \\             |               /\n        \\-----------(\u2297)-------------/\n                        |\n                [ einsum ] (Weighted Sum)\n                        |\n                        v\n                    Output: (p, x, o)\n    \"\"\"\n    def __init__(self, in_planes, out_planes, share_planes=8, nsample=16):\n        super().__init__()\n        self.mid_planes = mid_planes = out_planes // 1\n        self.out_planes = out_planes\n        self.share_planes = share_planes\n        self.nsample = nsample\n        self.linear_q = nn.Linear(in_planes, mid_planes)\n        self.linear_k = nn.Linear(in_planes, mid_planes)\n        self.linear_v = nn.Linear(in_planes, out_planes)\n        self.linear_p = nn.Sequential(\n            nn.Linear(3, 3),\n            LayerNorm1d(3),\n            nn.ReLU(inplace=True),\n            nn.Linear(3, out_planes),\n        )\n        self.linear_w = nn.Sequential(\n            LayerNorm1d(mid_planes),\n            nn.ReLU(inplace=True),\n            nn.Linear(mid_planes, out_planes // share_planes),\n            LayerNorm1d(out_planes // share_planes),\n            nn.ReLU(inplace=True),\n            nn.Linear(out_planes // share_planes, out_planes // share_planes),\n        )\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, pxo) -&gt; torch.Tensor:\n        p, x, o = pxo  # (n, 3), (n, c), (b)\n        x_q, x_k, x_v = self.linear_q(x), self.linear_k(x), self.linear_v(x)\n        x_k, idx = pointops.knn_query_and_group(    # \u8fdb\u884cKNN\u67e5\u8be2\u6700\u8fd1\u7684nsample\u4e2a\u70b9\uff0c\u56e0\u4e3awith_xyz\u8bbe\u7f6e\u4e3atrue\uff0c\u8fd4\u56de\u7684x_k\u4e2d\u7684\u524d3\u7ef4\u662f\u5750\u6807\u5dee\uff0c\u7136\u540eC\u7ef4\u662f\u7279\u5f81\u7ef4\u5ea6\n            x_k, p, o, new_xyz=p, new_offset=o, nsample=self.nsample, with_xyz=True\n        )\n        x_v, _ = pointops.knn_query_and_group(\n            x_v,\n            p,\n            o,\n            new_xyz=p,\n            new_offset=o,\n            idx=idx,\n            nsample=self.nsample,\n            with_xyz=False,\n        )\n        p_r, x_k = x_k[:, :, 0:3], x_k[:, :, 3:]\n        p_r = self.linear_p(p_r)    # \u4f7f\u7528p\u548cp\u7684\u90bb\u5c45\u7684\u5750\u6807\u5dee\u8fdb\u884c\u4f4d\u7f6e\u7f16\u7801\n        r_qk = (\n            x_k     # n k c\n            - x_q.unsqueeze(1)  # n 1 c \u5728\u4e2d\u95f4\u90bb\u5c45\u70b9\u6570\u91cf\u7ef4\u5ea6\u4e0a\u589e\u52a0\u4e00\u7ef4\uff0c\u81ea\u52a8\u8fdb\u884c\u5e7f\u64ad\uff0c\u8ba1\u7b97\u4e2d\u5fc3\u70b9\u4e0e\u6bcf\u4e2a\u90bb\u5c45\u70b9\u4e4b\u95f4\u7684\u7279\u5f81\u5dee\u5f02\n            + einops.reduce(\n                p_r, \"n ns (i j) -&gt; n ns j\", reduction=\"sum\", j=self.mid_planes     # n k c\n            )\n        )\n        w = self.linear_w(r_qk)  # (n, nsample, c/s)\n        w = self.softmax(w)\n        x = torch.einsum(\n            \"n t s i, n t i -&gt; n s i\",\n            einops.rearrange(x_v + p_r, \"n ns (s i) -&gt; n ns s i\", s=self.share_planes),     # n k s c/s\n            w,  # n k c/s \u81ea\u52a8\u5e7f\u64ad \u5230 n k s c/s \uff0c\u76f8\u5f53\u4e8e\u628a\u7279\u5f81\u5206\u4e3as\u4e2a\u90e8\u5206\uff0c\u6bcf\u4e2a\u90e8\u5206\u7684\u6743\u91cd\u4e0d\u540c\uff0c\u7ec4\u5185\u6743\u91cd\u5171\u4eab\n        )\n        x = einops.rearrange(x, \"n s i -&gt; n (s i)\")     # n c\n        return x\n</code></pre>"},{"location":"models/PointTransformer/#transitionup","title":"transitionUp","text":"<p>\u5206\u4e3a\u4e24\u79cd\u60c5\u51b5\uff0c\u7b2c\u4e00\u79cd\u662f\u4ece encoder5 \u5230 decoder1 \u7684\u8fd0\u7b97\uff0c\u8fd9\u79cd\u60c5\u51b5\u4e0b\u70b9\u6ca1\u6709\u53d8\u591a\uff0c\u53ea\u662f\u5bf9\u7279\u5f81\u8fdb\u884c\u4e86\u91cd\u7ec4\u8fd0\u7b97</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u5c06 encoder5 \u7684\u8f93\u51fa\u9996\u5148\u5728\u70b9\u4e2a\u6570\u7ef4\u5ea6\u505a\u4e00\u4e2a\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff08\u4e5f\u5c31\u662f\u5bf9\u6240\u6709\u70b9\u7279\u5f81\u53d6\u5e73\u5747\u503c\uff09\uff0c\u7136\u540e\u4e00\u4e2a Linear \u5c42\u53d8\u6362\u4e00\u4e0b\uff08\u4e0d\u6539\u53d8\u7279\u5f81\u7ef4\u5ea6\uff09\uff0c\u7136\u540e\u91cd\u590d\u539f\u5148\u7684\u70b9\u4e91\u4e2a\u6570 cnt \u6b21\uff0c\u8fd9\u6837\u53d8\u6362\u4e4b\u540e\u5f62\u72b6\u4e0d\u53d1\u751f\u6539\u53d8\uff0c\u7136\u540e\u518d\u548c\u539f\u59cb encoder5 \u7684\u8f93\u51fa\u5728\u901a\u9053\u7ef4 concat \u8d77\u6765\uff0c\u62fc\u63a5\u8d77\u6765\u4e4b\u540e\u518d\u4f7f\u7528 Linear \u63d0\u53d6\u4e00\u6b21\u7279\u5f81\uff0c\u5c31\u5f97\u5230 transitionUp \u6a21\u5757\u7684\u8f93\u51fa\u3002</p> <p>\u7b2c\u4e8c\u79cd\u60c5\u51b5\u662f decoder \u5c42\u4e4b\u95f4\u7684\u53d8\u5316\uff0c\u6b64\u65f6\u9700\u8981\u8fdb\u884c\u8de8\u5c42\u878d\u5408\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e decoder1 \u5230 decoder2 \u7684\u53d8\u5316\uff0cdecoder1 \u9700\u8981\u548c encoder4 \u878d\u5408\uff0cdecoder1 \u7684\u70b9\u7a00\u758f\uff0c\u7279\u5f81\u7ef4\u5ea6\u9ad8\uff0cencoder4 \u7684\u70b9\u5bc6\u96c6\uff0c\u7279\u5f81\u7ef4\u5ea6\u4f4e\uff0c\u8fd9\u91cc\u548c PointNet++\u7684\u7279\u5f81\u5e7f\u64ad\u6709\u70b9\u50cf\uff0c\u6211\u4eec\u5148\u628a decoder1 \u5c42\u7684\u9ad8\u7ef4\u7279\u5f81\u964d\u4f4e\u5230\u548c encoder4 \u4e00\u81f4\uff0c\u7136\u540e\u904d\u5386 encoder4 \u7684\u6bcf\u4e00\u4e2a\u70b9\uff0c\u5728 decoder1 \u627e\u8ddd\u79bb\u5b83\u6700\u8fd1\u7684 k \u4e2a\u70b9\uff0c\u7136\u540e\u5bf9\u8fd9 k \u4e2a\u70b9\u7684\u7279\u5f81\u6309\u7167\u8ddd\u79bb\u53cd\u6bd4\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230 encoder4 \u4e2d\u8fd9\u4e2a\u70b9\u7684\u65b0\u7279\u5f81\uff1b\u5f97\u5230 encoder4 \u4e2d\u6bcf\u4e2a\u70b9\u7684\u65b0\u7279\u5f81\u540e\uff0c\u5bf9\u6bcf\u4e2a\u70b9\u539f\u6765\u7684\u65e7\u7279\u5f81\u8fdb\u884c\u7ebf\u6027\u53d8\u6362\uff08\u4e0d\u6539\u53d8\u7ef4\u5ea6\uff09\uff0c\u7136\u540e\u5c06\u53d8\u6362\u540e\u7684\u65e7\u7279\u5f81\u548c\u65b0\u7279\u5f81\u8fdb\u884c\u9010\u5143\u7d20\u76f8\u52a0\uff08\u56e0\u4e3a\u901a\u9053\u5df2\u7ecf\u5bf9\u9f50\uff0c\u53ef\u4ee5\u76f8\u52a0\uff09\uff0c\u5c31\u5f97\u5230\u6700\u7ec8\u8f93\u51fa</p> <p>\u8be6\u7ec6\u4ee3\u7801\u5982\u4e0b\uff1a</p> Note <pre><code>class TransitionUp(nn.Module):\n    \"\"\"\n    \u4e0a\u91c7\u6837\u5c42\uff0c\u7528\u4e8e\u5c06\u8f93\u5165\u7684\u70b9\u4e91\u7279\u5f81\u8fdb\u884c\u4e0a\u91c7\u6837\n    input: pxo1: (p, x, o)\n    output: (n, x, o)\n        Structure (Mode 1: Upsampling / Interpolation):\n            Target (Fine)                Source (Coarse)\n            (p1, x1, o1)                  (p2, x2, o2)\n                |                             |\n                |                       [ Linear 2 ]\n                |                             |\n                |                   [ Point Interpolation ]\n                |                (Map features from p2 to p1)\n                |                             |\n                v                             |\n            [ Linear 1 ]                       |\n                |                             |\n                v                             v\n                +------------&gt; ( + ) &lt;--------+\n                                    |\n                                Output\n\n        Structure (Mode 2: Global Aggregation - if pxo2 is None):\n                    Input: x (Local Features)\n                                |\n                    +-----------+-----------+\n                    |                       |\n            (Local Feats)          (Global Mean)\n                    |                 [ Linear 2 ]\n                    |                 [  Repeat  ]\n                    v                       v\n                    +---------&gt;( Concat )&lt;--+\n                                |\n                            [ Linear 1 ]\n                                |\n                                Output\n        \"\"\"\n        def __init__(self, in_planes, out_planes=None):\n            super().__init__()\n            if out_planes is None:\n                self.linear1 = nn.Sequential(\n                    nn.Linear(2 * in_planes, in_planes),\n                    nn.BatchNorm1d(in_planes),\n                    nn.ReLU(inplace=True),\n                )\n                self.linear2 = nn.Sequential(\n                    nn.Linear(in_planes, in_planes), nn.ReLU(inplace=True)\n                )\n            else:\n                self.linear1 = nn.Sequential(\n                    nn.Linear(out_planes, out_planes),\n                    nn.BatchNorm1d(out_planes),\n                    nn.ReLU(inplace=True),\n                )\n                self.linear2 = nn.Sequential(\n                    nn.Linear(in_planes, out_planes),\n                    nn.BatchNorm1d(out_planes),\n                    nn.ReLU(inplace=True),\n                )\n\n        def forward(self, pxo1, pxo2=None):\n            # === \u6a21\u5f0f 2\uff1a\u5168\u5c40\u7279\u5f81\u805a\u5408 (\u5f53\u6ca1\u6709\u63d0\u4f9b\u7b2c\u4e8c\u4e2a\u8f93\u5165 pxo2 \u65f6) ===\n            # \u8fd9\u901a\u5e38\u53d1\u751f\u5728 Encoder \u521a\u7ed3\u675f\uff0c\u51c6\u5907\u8fdb\u5165 Decoder \u7684\u6700\u6df1\u5c42 (Stage 5)\n            if pxo2 is None:\n                _, x, o = pxo1  # (n, 3), (n, c), (b)\n                x_tmp = []\n                # \u904d\u5386 Batch \u4e2d\u7684\u6bcf\u4e00\u4e2a\u6837\u672c\uff08\u70b9\u4e91\uff09\n                for i in range(o.shape[0]):\n                    # \u8ba1\u7b97\u5f53\u524d\u6837\u672c\u5728 packed Tensor \u4e2d\u7684\u8d77\u59cb\u7d22\u5f15 s_i \u548c\u7ed3\u675f\u7d22\u5f15 e_i\uff0c\u4ee5\u53ca\u70b9\u6570 cnt\n                    if i == 0:\n                        s_i, e_i, cnt = 0, o[0], o[0]\n                    else:\n                        s_i, e_i, cnt = o[i - 1], o[i], o[i] - o[i - 1]\n                    # \u53d6\u51fa\u5f53\u524d\u6837\u672c\u7684\u6240\u6709\u70b9\u7279\u5f81\n                    x_b = x[s_i:e_i, :]\n                    # [\u6838\u5fc3\u64cd\u4f5c]\uff1a\n                    # 1. x_b.sum(0, True) / cnt: \u8ba1\u7b97\u5f53\u524d\u6837\u672c\u6240\u6709\u70b9\u7684\u5e73\u5747\u503c\uff08Global Mean Pooling\uff09\n                    # 2. self.linear2(...): \u5bf9\u5168\u5c40\u7279\u5f81\u8fdb\u884c\u53d8\u6362\n                    # 3. .repeat(cnt, 1): \u5c06\u5168\u5c40\u7279\u5f81\u590d\u5236 cnt \u6b21\uff0c\u4f7f\u5176\u4e0e\u70b9\u6570\u5bf9\u9f50\n                    # 4. torch.cat((x_b, ...), 1): \u5c06 \u539f\u59cb\u5c40\u90e8\u7279\u5f81 \u4e0e \u5168\u5c40\u7279\u5f81 \u62fc\u63a5\n                    x_b = torch.cat(\n                        (x_b, self.linear2(x_b.sum(0, True) / cnt).repeat(cnt, 1)), 1\n                    )\n                    x_tmp.append(x_b)   # (cnt,c)-&gt;(c)-&gt;(c_new)-&gt;(cnt,c_new)\n                # \u5c06\u5904\u7406\u5b8c\u7684 batch \u91cd\u65b0\u62fc\u56de\u4e00\u4e2a\u5927 Tensor\n                x = torch.cat(x_tmp, 0)\n                # \u901a\u8fc7 linear1 \u878d\u5408\u62fc\u63a5\u540e\u7684\u7279\u5f81\n                x = self.linear1(x)\n            else:\n                # === \u6a21\u5f0f 1\uff1a\u4e0a\u91c7\u6837\u4e0e\u878d\u5408 (\u6807\u51c6\u7528\u6cd5) ===\n                # pxo1: Target (Fine)\uff0c\u6765\u81ea Encoder \u7684\u9ad8\u5206\u8fa8\u7387\u7279\u5f81\uff08\u8df3\u8dc3\u8fde\u63a5\uff09\uff0cp1\u662f\u5bc6\u96c6\u70b9\u4e91\uff0cx1\u662f\u4f4e\u7ef4\u7279\u5f81\n                p1, x1, o1 = pxo1\n                # pxo2: Source (Coarse)\uff0c\u6765\u81ea\u4e0a\u4e00\u5c42 Decoder \u7684\u4f4e\u5206\u8fa8\u7387\u7279\u5f81\uff0cp2\u662f\u7a00\u758f\u70b9\u4e91\uff0cx2\u662f\u9ad8\u7ef4\u7279\u5f81\n                p2, x2, o2 = pxo2\n\n                # [\u6838\u5fc3\u64cd\u4f5c]\uff1a\u4e0a\u91c7\u6837 (Interpolation) + \u878d\u5408 (Summation)\n                # 1. self.linear2(x2): \u5148\u53d8\u6362\u6210\u4f4e\u7ef4\u7279\u5f81\n                # 2. pointops.interpolation(...): \n                #    \u5728 p1 (\u5bc6\u96c6\u70b9\u4e91) \u4e2d\u5bfb\u627e p2 (\u7a00\u758f\u70b9\u4e91) \u7684\u6700\u8fd1\u90bb\uff0c\u5229\u7528\u8ddd\u79bb\u6743\u91cd\u5c06 x2 \u63d2\u503c\u6620\u5c04\u5230 p1 \u7684\u4f4d\u7f6e\u3002\n                #    \u8fd9\u4e00\u6b65\u5c06\u6df1\u5c42\u7684\u7279\u5f81\u4f20\u64ad\u5230\u4e86\u5bc6\u96c6\u7684\u70b9\u4e91\u5750\u6807\u4e0a\n                # 3. self.linear1(x1): \u4f4e\u7ef4\u7279\u5f81\u4e5f\u53d8\u5316\u4e00\u4e0b\uff0c\u63d0\u53d6\u7279\u5f81\n                # 4. + : \u5c06 \u63d2\u503c\u540e\u7684\u6df1\u5c42\u7279\u5f81 \u4e0e \u6d45\u5c42\u7ec6\u8282\u7279\u5f81 \u76f8\u52a0\u878d\u5408\n                x = self.linear1(x1) + pointops.interpolation(\n                    p2, p1, self.linear2(x2), o2, o1\n                )   # \u548cPointNet++\u7684\u627e\u90bb\u5c45\u4e00\u6837\uff0c\u5bf9\u5bc6\u96c6\u70b9\u4e91\u4e2d\u7684\u6bcf\u4e00\u4e2a\u70b9\uff0c\u5728\u7a00\u758f\u70b9\u4e91\u4e2d\u5bfb\u627e\u6700\u8fd1\u7684k\u4e2a\u70b9\uff0c\u6743\u91cd\u4f9d\u7136\u662f\u6839\u636e\u8ddd\u79bb\u53cd\u6bd4\u83b7\u5f97\uff0c\u7136\u540e\u5bf9\u7a00\u758f\u70b9\u4e91\uff08\u9ad8\u7ef4\u7279\u5f81\uff09\u8fdb\u884c\u52a0\u6743\u6c42\u548c\n                # \u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0cPointNet++\u5c06\u63d2\u503c\u5f97\u5230\u7684\u9ad8\u7ef4\u7279\u5f81\u548c\u539f\u6765\u5bc6\u96c6\u70b9\u4e91\u7684\u4f4e\u7ef4\u7279\u5f81\u76f4\u63a5\u5728\u901a\u9053\u7ef4\u5ea6\u62fc\u63a5\uff0c\u4f46\u662fptv1\u662f\u5148\u5c06\u9ad8\u7ef4\u7279\u5f81\u964d\u7ef4\uff08\u548c\u5bc6\u96c6\u70b9\u4e91\u4e2d\u7684\u4f4e\u7ef4\u7279\u5f81\u7ef4\u5ea6\u4e00\u81f4\uff09\uff0c\n                # \u7136\u540e\u5728\u5bc6\u96c6\u70b9\u4e91\u4e2d\u5bfb\u627e\u7a00\u758f\u70b9\u4e91\u7684\u90bb\u5c45\uff0c\u5229\u7528\u8ddd\u79bb\u6743\u91cd\u5c06\u9ad8\u964d\u7ef4\u540e\u7684\u7279\u5f81\u63d2\u503c\u6620\u5c04\u5230\u5bc6\u96c6\u70b9\u4e91\u7684\u4f4d\u7f6e\uff0c\u6700\u540e\u5c06\u5bc6\u96c6\u70b9\u4e91\u7684\u65b0\u7279\u5f81\u548c\u65e7\u7279\u5f81\u76f4\u63a5\u9010\u5143\u7d20\u76f8\u52a0\n            return x\n</code></pre> <p>\u4ee5\u4e0a\u5c31\u662f ptv1 \u6240\u6709\u4e3b\u8981\u6a21\u5757\u7684\u89e3\u8bfb\u4e86\uff0c\u5982\u679c\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u5219\u4e0d\u9700\u8981 decoder \u6a21\u5757\uff0c\u76f4\u63a5\u5c06 encoder5 \u7684\u8f93\u51fa\u7279\u5f81\u5e73\u5747\u6c60\u5316\uff0c\u518d\u52a0\u4e0a\u4e00\u4e2a\u5206\u7c7b MLP \u5934\u5c31\u53ef\u4ee5\u4e86\u3002\u5982\u679c\u662f\u5206\u5272\u4efb\u52a1\uff0c\u5219\u9700\u8981 decoder \u6a21\u5757\uff0c\u5c06\u4e0b\u91c7\u6837\u5931\u53bb\u7684\u70b9\uff0c\u901a\u8fc7 transitionUp \u6a21\u5757\u9010\u6b65\u6dfb\u52a0\u56de\u6765\uff0c\u6062\u590d\u70b9\u6570\u540e\uff0c\u518d\u5229\u7528\u6bcf\u4e2a\u70b9\u7684\u7279\u5f81\u8fdb\u884c\u9010\u70b9\u5206\u7c7b\uff0c\u8fd9\u5c31\u662f\u5206\u5272\u4efb\u52a1\u3002</p>"},{"location":"models/PointTransformer/#ptv2","title":"PTv2","text":"<p>\u8bba\u6587\u6807\u9898\u4e3a\uff1aPoint Transformer V2: Grouped Vector Attention and Partion-based Pooling</p> <p>\u5173\u952e\u8bcd\uff1a\u5206\u7ec4\u5411\u91cf\u6ce8\u610f\u529b\uff08Grouped Vector Attenion\uff09\u3001\u5206\u533a\u6c60\u5316\uff08Partion-based Pooling\uff09\u3001\u66f4\u5f3a\u7684\u4f4d\u7f6e\u7f16\u7801</p>"},{"location":"models/PointTransformer/#_2","title":"\u80cc\u666f","text":"<p>PTv1 \u867d\u7136\u6548\u679c\u597d\uff0c\u4f46\u5b58\u5728\u6548\u7387\u548c\u53c2\u6570\u91cf\u7684\u7f3a\u9677\uff0c\u5177\u4f53\u6765\u8bf4\uff1a</p> <ol> <li>\u53c2\u6570\u8fc7\u62df\u5408\u4e0e\u6df1\u5ea6\u9650\u5236\u3002PTv1 \u7684\u5411\u91cf\u6ce8\u610f\u529b\u4f7f\u7528\u5168\u8fde\u63a5\u5c42\u6765\u751f\u6210\u6743\u91cd\uff0c\u968f\u7740\u901a\u9053\u6570\u589e\u52a0\uff0c\u53c2\u6570\u91cf\u5267\u589e\uff0c\u5bfc\u81f4\u8fc7\u62df\u5408\uff0c\u9650\u5236\u4e86\u7f51\u7edc\u6df1\u5ea6\uff1b</li> <li>\u6c60\u5316\u6548\u7387\u4f4e\u3002PTv1 \u4f7f\u7528\u7684 FPS+KNN \u91c7\u6837\u65b9\u5f0f\uff0c\u65e2\u8017\u65f6\uff0c\u53c8\u5bfc\u81f4\u7a7a\u95f4\u5bf9\u9f50\u4e0d\u4f73\uff08\u90bb\u57df\u91cd\u53e0\u4e0d\u53ef\u63a7\uff09\uff1b</li> <li>\u4f4d\u7f6e\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u3002\u4ee5\u524d\u7684\u65b9\u6cd5\u6ca1\u6709\u5145\u5206\u5229\u7528 3D \u5750\u6807\u4e2d\u7684\u51e0\u4f55\u77e5\u8bc6\u3002</li> </ol> <p>\u6574\u4f53\u67b6\u6784</p> <p>ptv2 \u7684\u6574\u4f53\u67b6\u6784\u548c ptv1 \u5dee\u4e0d\u591a\uff0c\u90fd\u662f\u57fa\u4e8e U-Net \u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u53ea\u662f\u5728\u5411\u91cf\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u3001\u53ef\u5b66\u4e60\u4f4d\u7f6e\u7f16\u7801\u4e0a\u7684\u5229\u7528\u3001\u4ee5\u53ca\u6c60\u5316\u65b9\u5f0f\u7b49\u65b9\u9762\uff0c\u505a\u4e86\u4f18\u5316\uff0c\u6240\u4ee5\u8bba\u6587\u4e2d\u6ca1\u6709\u7ed8\u5236\u6574\u4f53\u7f51\u7edc\u67b6\u6784\u56fe\u3002</p>"},{"location":"models/PointTransformer/#grouped-vector-attention","title":"Grouped Vector Attention","text":"<p>\u7b2c\u4e00\u4e2a\u6838\u5fc3\u6539\u8fdb\u5728\u4e8e\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\uff0c\u4e3a\u4e86\u89e3\u51b3\u53c2\u6570\u91cf\u7206\u70b8\u95ee\u9898\uff0cptv2 \u5c06\u7279\u5f81\u901a\u9053\u5212\u5206\u4e3a\u4e86 \\(g\\) \u4e2a\u7ec4\uff08\u4f46\u662f\u8fd9\u4e00\u70b9 pointcept \u5728 ptv1 \u7684\u4ee3\u7801\u4e2d\u4e5f\u5b9e\u73b0\u4e86\uff0c\u5728\u4ee3\u7801\u4e2d\u5c06\u7279\u5f81\u5206\u4e3a\u4e86 \\(s\\) \u7ec4\uff0c\u4f46\u662f ptv1 \u539f\u59cb\u8bba\u6587\u4e2d\u6ca1\u6709\u63d0\u5230\u5206\u7ec4\u5411\u91cf\u6ce8\u610f\u529b\uff0c\u800c\u662f\u4f7f\u7528 MLP \u4e3a\u7279\u5f81\u7684\u6bcf\u4e00\u4e2a\u7ef4\u5ea6\u90fd\u8ba1\u7b97\u5355\u72ec\u7684\u6743\u91cd\uff0c\u53ef\u80fd pointcept \u4ed3\u5e93\u5199\u8fd9\u4e2a\u4ee3\u7801\u7684\u65f6\u5019 ptv2 \u65e9\u5c31\u5df2\u7ecf\u51fa\u4e86\uff0c\u5c31\u628a\u8fd9\u4e2a\u878d\u5408\u5230 ptv1 \u7684\u4ee3\u7801\u91cc\u9762\u4e86\uff09\u3002</p> <p>\u5212\u5206\u4e3a \\(g\\) \u4e2a\u7ec4\u540e\uff0c\u540c\u4e00\u4e2a\u7ec4\u5185\u7684\u7279\u5f81\u901a\u9053\u5171\u4eab\u540c\u4e00\u4e2a\u6ce8\u610f\u529b\u6743\u91cd\u5411\u91cf\uff0c\u800c\u4e0d\u662f\u6bcf\u4e00\u4e2a\u901a\u9053\u4e00\u4e2a\u6743\u91cd\uff0c\u8fd9\u5927\u5927\u51cf\u5c11\u4e86\u53c2\u6570\u91cf\u548c\u8fc7\u62df\u5408\u7684\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u5411\u91cf\u6ce8\u610f\u529b\u7684\u4f18\u52bf\u3002</p> <p>\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5728\u8ba1\u7b97\u5206\u7ec4\u5411\u91cf\u6ce8\u610f\u529b\u7684\u65f6\u5019\uff0c\u8f93\u5165\u7ed9\u8ba1\u7b97\u6743\u91cd\u7684 mlp \u7684\u7279\u5f81\uff0c\u4e0d\u518d\u662f \\(\\gamma(Q,K)\\) \u7684\u5168\u90e8\u7279\u5f81\uff0c\u800c\u662f\u5c06 \\(\\gamma(Q,K)\\) \u548c\u503c\u5411\u91cf \\(v\\) \u4e00\u6837\u8fdb\u884c\u5206\u7ec4\uff08\u5206\u4e3a \\(g\\) \u7ec4\uff09\uff0c\u7136\u540e\u6bcf\u4e2a\u7ec4\u5355\u72ec\u4f7f\u7528 mlp \u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\uff08\u8fd9\u4e00\u70b9\u548c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u6bd4\u8f83\u50cf\uff0c\u8bba\u6587\u4e2d\u4e5f\u753b\u4e86\u56fe c \u8fdb\u884c\u5bf9\u6bd4\uff0c\u533a\u522b\u5728\u4e8e\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u7684\u65b9\u5f0f\u4e0d\u540c\uff0c\u591a\u5934\u6ce8\u610f\u529b\u901a\u8fc7 \\(\\gamma(Q,K)\\) \u7684\u70b9\u79ef\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\uff09\uff0c\u5982\u679c\u662f\u5168\u901a\u9053\u5411\u91cf\u6ce8\u610f\u529b\uff0cmlp \u53c2\u6570\u6570\u91cf\u5c06\u662f \\(c^2\\)\uff0c\u5982\u679c\u5206\u4e3a \\(g\\) \u7ec4\uff0c\u53c2\u6570\u6570\u91cf\u5c31\u662f \\((c/g)^2 \\times g =c^2/g\\)\uff0c\u53c2\u6570\u51cf\u5c11\u4e3a\u539f\u6765\u7684 \\(1/g\\)\uff0c\u517c\u987e\u4e86\u5411\u91cf\u6ce8\u610f\u529b\u7684\u4f18\u52bf\u4ee5\u53ca\u8ba1\u7b97\u6548\u7387\u3002</p> <p>Important</p> <p>\u4f5c\u8005\u53d1\u73b0\uff0c\u4e25\u683c\u9650\u5236\u201c\u7ec4\u5185\u53ea\u770b\u7ec4\u5185\u53c2\u6570 \\(\\gamma(Q,K)\\)\u201d\u7684 <code>GroupedLinear</code> \u5bf9\u6700\u7ec8\u6027\u80fd\u7684\u8d21\u732e\u5fae\u4e4e\u5176\u5fae\uff0c\u4f46\u4f1a\u62d6\u6162\u901f\u5ea6\u3002\u76f4\u63a5\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff08\u8ba9\u6240\u6709\u901a\u9053\u901a\u8fc7\u7ebf\u6027\u7ec4\u5408\u751f\u6210 \\(g\\) \u4e2a\u7ec4\u7684\u6743\u91cd\uff09\u6548\u679c\u4e00\u6837\u597d\uff0c\u4e14\u80fd\u5229\u7528 PyTorch/CUDA \u9ad8\u5ea6\u4f18\u5316\u7684 Dense Layer \u7b97\u5b50\u3002 \u4f18\u52bf\uff1a\u901f\u5ea6\u66f4\u5feb\uff0c\u4ee3\u7801\u66f4\u7b80\u6d01\u3002</p> <p></p>Figure 4: \u5206\u7ec4\u5411\u91cf\u6ce8\u610f\u529b<p></p> <p>\u540c\u6837\uff0c\u8bba\u6587\u4e2d\u4e0b\u9762\u8fd9\u5f20\u56fe\u8fd9\u5bf9\u6bd4\u4e86 ptv2 \u6539\u8fdb\u7684\u5411\u91cf\u6ce8\u610f\u529b\u8ba1\u7b97\u65b9\u5f0f\u548c\u6c60\u5316\u65b9\u5f0f\u548c ptv1 \u7684\u4e00\u4e2a\u5bf9\u6bd4\u3002\u9996\u5148\uff0c\u5728\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u4e0a\uff0c\u524d\u9762\u5df2\u7ecf\u8bf4\u8fc7\u4e86\uff0c\u63d0\u51fa\u4e86\u5206\u7ec4\u6765\u517c\u987e\u5411\u91cf\u6ce8\u610f\u529b\u4f18\u52bf\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861\uff0c\u4f46\u662f\u4f4d\u7f6e\u7f16\u7801\u7684\u4f7f\u7528\u4e0a\u6709\u4e0d\u540c\uff0cptv2 \u4ee3\u7801\u4e2d\u7ed9\u4e86\u4e24\u79cd\u9009\u62e9\uff1a</p> Note <pre><code>    def forward(self, feat, coord, reference_index):\n        query, key, value = (       # \u6839\u636e\u8f93\u5165\u7279\u5f81\u8ba1\u7b97\u6ce8\u610f\u529b\u8ba1\u7b97\u9700\u8981\u7684Q\u3001K\u3001V\n            self.linear_q(feat),\n            self.linear_k(feat),\n            self.linear_v(feat),\n        )\n        key = pointops.grouping(reference_index, key, coord, with_xyz=True)         # \u6839\u636e\u90bb\u57df\u7d22\u5f15\u83b7\u53d6\u6ce8\u610f\u529b\u8303\u56f4\u5185\u6240\u6709\u70b9\u7684K\uff0cK\u7684\u524d\u4e09\u7ef4\u662f\u5750\u6807\u5dee\n        value = pointops.grouping(reference_index, value, coord, with_xyz=False)    # \u6839\u636e\u90bb\u57df\u7d22\u5f15\u83b7\u53d6\u6ce8\u610f\u529b\u8303\u56f4\u5185\u6240\u6709\u70b9\u7684V\n        pos, key = key[:, :, 0:3], key[:, :, 3:]    # \u4eceK\u4e2d\u5206\u79bb\u51fa\u5750\u6807\u5dee\u548c\u771f\u6b63\u7684K\n        relation_qk = key - query.unsqueeze(1)      # \u8ba1\u7b97r(Q,K)\uff0c\u8fd9\u91cc\u662f\u5dee\u8fd0\u7b97\n        if self.pe_multiplier:  # \u4f4d\u7f6e\u7f16\u7801\u4e58\u5b50\u6cd5\n            pem = self.linear_p_multiplier(pos) # \u5bf9\u5750\u6807\u5dee\u8fdb\u884c\u7ebf\u6027\u53d8\u6362\n            relation_qk = relation_qk * pem     # r(Q,K) * pem\n        if self.pe_bias:        # \u4f4d\u7f6e\u7f16\u7801\u504f\u7f6e\u6cd5\n            peb = self.linear_p_bias(pos)\n            relation_qk = relation_qk + peb\n            value = value + peb\n\n        weight = self.weight_encoding(relation_qk)\n        weight = self.attn_drop(self.softmax(weight))\n</code></pre> <p>\u4e00\u79cd\u662f\u4f4d\u7f6e\u7f16\u7801\u4e58\u5b50\u6cd5\uff08\u548c ptv1 \u4e00\u6837\uff0c\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u65f6\u5019\u4f7f\u7528 KNN \u67e5\u8be2\u90bb\u57df\u70b9\uff0c\u7136\u540e\u8ba1\u7b97\u5750\u6807\u5dee\u3001\u6ce8\u610f\u529b\u6743\u91cd\u7b49\uff09\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5c06\u5750\u6807\u5dee pos \u8fdb\u884c\u7ebf\u6027\u53d8\u6362\uff0c\u53d8\u6362\u5230\u548c\u7279\u5f81\u7ef4\u5ea6\u4e00\u81f4\uff0c\u7136\u540e\u548c \\(\\gamma(Q,K)\\) \u8fdb\u884c\u9010\u5143\u7d20\u4e58\u79ef\uff0c\u5c06\u7ed3\u679c\u9001\u5165\u5230\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u7684 mlp \u5c42\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u503c\u5411\u91cf value \u4e0d\u53d8\uff0c\u6ca1\u6709\u52a0\u4f4d\u7f6e\u7f16\u7801\uff1b\u5373</p> \\[ w =\\omega(\\gamma(K, Q)\\odot Linear(\\Delta pos)) \\] <p>\u53e6\u4e00\u79cd\u662f\u4f4d\u7f6e\u7f16\u7801\u504f\u7f6e\u6cd5\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5148\u628a\u5750\u6807\u5dee pos \u8fdb\u884c\u7ebf\u6027\u53d8\u6362\uff0c\u53d8\u6362\u5230\u548c\u7279\u5f81\u7ef4\u5ea6\u4e00\u81f4\uff0c\u7136\u540e\u548c \\(\\gamma(Q,K)\\) \u8fdb\u884c\u76f8\u52a0\uff0c\u5c06\u76f8\u52a0\u7684\u7ed3\u679c\u9001\u5165\u5230\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u7684 mlp \u5c42\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u540c\u65f6\u503c\u5411\u91cf value \u4e5f\u52a0\u4e0a\u53d8\u6362\u540e\u7684\u5750\u6807\u7f16\u7801\uff0c\u5bf9\u53d8\u5316\u540e\u7684\u503c\u5411\u91cf\u8fdb\u884c\u52a0\u6743\u6c42\u548c\uff1b\u5373</p> \\[ w =\\omega(\\gamma(Q, K)+Linear(\\Delta pos)), \\quad y = w(value+Linear(\\Delta pos)) \\] <p>\u8fd9\u4e00\u70b9\u4ee3\u7801\u4e2d\u7684\u5b9e\u73b0\u548c\u8bba\u6587\u4e2d\u8c8c\u4f3c\u6709\u70b9\u4e0d\u4e00\u81f4\uff0c\u8bba\u6587\u4e2d\u56fe\u793a\u7684\u6548\u679c\u611f\u89c9\u5e94\u8be5\u662f\u4e0b\u9762\u8fd9\u79cd\uff1a</p> \\[ w =\\omega(Linear(\\Delta pos)\\odot\\gamma(Q, K)+Linear(\\Delta pos)) \\] <p>\u7136\u540e\u503c\u5411\u91cf\u4fdd\u6301\u4e0d\u53d8\u3002</p> <p></p>Figure 5: ptv2 \u548c v1 \u5728\u5411\u91cf\u6ce8\u610f\u529b\u3001\u6c60\u5316\u65b9\u5f0f\u4e0a\u7684\u5bf9\u6bd4<p></p> <p>\u7136\u540e\u662f\u6c60\u5316\u65b9\u5f0f\u4e0a\u7684\u6539\u8fdb\uff0c\u524d\u9762\u8bf4\u8fc7\uff0cptv1 \u4f7f\u7528 FPS \u548c KNN \u8fdb\u884c\u4e0b\u91c7\u6837\u6c60\u5316\uff0c\u627e\u90bb\u5c45\uff0c\u805a\u5408\u90bb\u5c45\u7279\u5f81\u3002\u4f46\u662f\u8fd9\u79cd\u65b9\u6cd5\u7684\u67e5\u8be2\u96c6\u5728\u7a7a\u95f4\u4e0a\u4e0d\u5bf9\u9f50\uff0c\u4e14\u4e0d\u540c\u67e5\u8be2\u96c6\u4e4b\u95f4\u7684\u91cd\u53e0\u533a\u57df\u4e0d\u53ef\u63a7\uff0c\u8fd9\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u663e\u5b58\u5360\u7528\u9ad8\u3002\u56e0\u6b64 ptv2 \u4f7f\u7528\u4e86\u57fa\u4e8e\u533a\u57df\u5212\u5206\u7684\u6c60\u5316\uff0c\u5982\u4e0a\u56fe\u6240\u793a\uff0cptv1 \u7684\u6c60\u5316\u548c\u53cd\u6c60\u5316\u90fd\u8981\u901a\u8fc7 KNN \u67e5\u8be2\u6700\u8fd1\u70b9\uff0c\u4f46\u662f ptv2 \u901a\u8fc7\u5c06\u70b9\u4e91\u7a7a\u95f4\u5207\u5272\u6210\u4e92\u4e0d\u91cd\u53e0\u7684\u5206\u533a\uff08\u6bd4\u5982\u5747\u5300\u7f51\u683c\uff0c\u5373 Grid Pooling\uff09</p> <p>\u64cd\u4f5c\u6d41\u7a0b\uff1a</p> <ol> <li>\u5212\u5206\uff08Partition\uff09\uff1a \u5c06\u6574\u4e2a\u70b9\u4e91\u7a7a\u95f4 \\(\\mathcal{M}\\) \u5207\u5272\u6210\u591a\u4e2a\u4e92\u4e0d\u91cd\u53e0\u7684\u5b50\u96c6 \\([\\mathcal{M}_1, \\mathcal{M}_2, ..., \\mathcal{M}_{n'}]\\)\u3002\u5c31\u50cf\u628a\u4e00\u4e2a\u5927\u76d2\u5b50\u5207\u6210\u5f88\u591a\u5c0f\u65b9\u5757\uff08Grid\uff09\u3002</li> <li>\u878d\u5408\uff08Fusion\uff09\uff1a \u5bf9\u6bcf\u4e00\u4e2a\u5c0f\u65b9\u5757\u5185\u7684\u6240\u6709\u70b9\u8fdb\u884c\u805a\u5408\uff0c\u751f\u6210 \u4e00\u4e2a \u65b0\u7684\u4ee3\u8868\u70b9\uff08Pooling Point\uff09\u3002</li> </ol> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u5c0f\u65b9\u5757\u5185\u6240\u6709\u70b9\u7279\u5f81\u8fdb\u884c\u7ebf\u6027\u53d8\u6362\uff0c\u7136\u540e\u5bf9\u6bcf\u4e00\u4e2a\u6837\u672c\u70b9\u4e91\u8fdb\u884c\u7f51\u683c\u5212\u5206\uff0c\u540c\u4e00\u4e2a\u7f51\u683c\u4e2d\u70b9\u7684\u5750\u6807\u91c7\u7528\u5e73\u5747\u6c60\u5316\uff0c\u7528\u7f51\u683c\u5185\u6240\u6709\u70b9\u7684\u8d28\u5fc3\u505a\u4ee3\u8868\uff1b\u540c\u4e00\u4e2a\u7f51\u683c\u4e2d\u70b9\u7684\u7279\u5f81\u91c7\u7528\u6700\u5927\u6c60\u5316\uff0c\u6bcf\u4e00\u7ef4\u7279\u5f81\u9009\u62e9\u6240\u6709\u70b9\u4e2d\u503c\u6700\u5927\u7684\u4f5c\u4e3a\u4ee3\u8868\uff0c\u4ece \\((n,c)\\) \u5230 \\((c)\\)\u3002</p>"},{"location":"models/PointTransformer/#ptv3","title":"PTv3","text":"<p>\u8bba\u6587\u6807\u9898\u4e3a\uff1aPoint Transformer V3: Simpler, Faster, Stronger</p> <p>\u5173\u952e\u8bcd\uff1a\u5e8f\u5217\u5316\uff08Serialization\uff09\u3001\u6548\u7387\u4f18\u5148\uff08Simpler, Faster, Stronger\uff09\u3001\u6269\u5927\u611f\u53d7\u91ce\u3001\u591a\u6570\u636e\u96c6\u8054\u5408\u8bad\u7ec3\u3002</p>"},{"location":"models/PointTransformer/#_3","title":"\u80cc\u666f","text":"<p>3D \u9aa8\u5e72\u7f51\u7edc\u7684\u53d1\u5c55\u53d7\u9650\u4e8e\u201c\u6570\u636e\u89c4\u6a21\u201d\u548c\u201c\u611f\u53d7\u91ce\u89c4\u6a21\u201d\uff0c\u4ee5\u5f80\u7684\u6a21\u578b\uff08\u5982 PTv2\uff09\u4e3a\u4e86\u8ffd\u6c42\u5c40\u90e8\u7ed3\u6784\u7684\u7cbe\u786e\u6027\uff08\u6bd4\u5982\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u65f6\u5019\uff0c\u4f9d\u7136\u4f7f\u7528 KNN \u67e5\u8be2\u83b7\u53d6\u90bb\u5c45\u70b9\uff09\uff0c\u727a\u7272\u4e86\u592a\u591a\u6548\u7387\u3002</p> <p>\u540c\u65f6\uff0c\u4f5c\u8005\u53d1\u73b0 PTv2 \u5b58\u5728\u5982\u4e0b\u95ee\u9898\uff1a</p> <ol> <li>\u6548\u7387\u74f6\u9888\uff1a KNN \u67e5\u8be2\u5360\u636e\u4e86 28%\u7684\u63a8\u7406\u65f6\u95f4\uff0c\u590d\u6742\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff08RPE\uff09\u5360\u636e\u4e86 26%\u7684\u65f6\u95f4\u3002\u8fd9\u4e9b\u64cd\u4f5c\u4e0d\u4ec5\u6162\uff0c\u8fd8\u5185\u5b58\u6d88\u8017\u5927\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6269\u5c55\u611f\u53d7\u91ce \uff1b</li> <li>\u611f\u53d7\u91ce\u53d7\u9650\uff1a \u4e3a\u4e86\u4fdd\u6301\u6548\u7387\uff0cPTv2 \u7684\u611f\u53d7\u91ce\u53ea\u80fd\u9650\u5236\u5728 16 \u4e2a\u70b9\u5de6\u53f3\uff0c\u9650\u5236\u4e86\u957f\u8ddd\u79bb\u4e0a\u4e0b\u6587\u7684\u83b7\u53d6 \uff1b</li> <li>\u65e0\u5e8f\u6027\u5e26\u6765\u7684\u56f0\u96be\uff1a \u70b9\u4e91\u7684\u65e0\u5e8f\u6027\uff08Permutation Invariance\uff09\u4f7f\u5f97\u50cf\u56fe\u50cf\u90a3\u6837\u9ad8\u6548\u5904\u7406\u53d8\u5f97\u56f0\u96be\uff1b</li> </ol> <p>\u6838\u5fc3\u521b\u65b0\u4e0e\u7f51\u7edc\u67b6\u6784</p> <p>1\u3001\u70b9\u4e91\u5e8f\u5217\u5316\uff08Point Cloud Serialization\uff09</p> <ul> <li>\u653e\u5f03\u65e0\u5e8f\u96c6\u5408\u7684\u6267\u5ff5\uff0c\u901a\u8fc7\u7a7a\u95f4\u586b\u5145\u66f2\u7ebf\uff08\u4f8b\u5982 Z-order \u6216 Hilbert \u66f2\u7ebf\uff09\u5c06 3D \u70b9\u4e91\u6392\u5217\u6210 1D \u5e8f\u5217\uff1b\u4ece\u800c\u5c06\u65e0\u5e8f\u70b9\u4e91\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4f7f\u5f97\u90bb\u8fd1\u7684\u70b9\u5728\u5e8f\u5217\u4e2d\u4e5f\u5c3d\u53ef\u80fd\u90bb\u8fd1\uff0c\u4ece\u800c\u80fd\u591f\u5229\u7528\u9ad8\u6548\u7684\u6ed1\u7a97\u673a\u5236\u3002</li> </ul> <p>2\u3001\u5e8f\u5217\u5316\u6ce8\u610f\u529b\uff08Serialized Attention\uff09</p> <ul> <li>\u5728\u5e8f\u5217\u5316\u540e\u7684\u70b9\u4e91\u4e0a\u4f7f\u7528\u57fa\u4e8e Patch \u7684\u6ce8\u610f\u529b\u673a\u5236\uff08\u7c7b\u4f3c\u4e8e Swin Transformer\uff09\uff1b</li> <li>\u63d0\u51fa\u4e86 Shift Mask \u548c Shuffle \u7b49\u7b56\u7565\u6765\u4fc3\u8fdb\u4e0d\u540c Patch \u4e4b\u95f4\u7684\u4fe1\u606f\u4ea4\u4e92\uff0c\u6253\u7834\u56fa\u5b9a\u7a97\u53e3\u7684\u9650\u5236\uff1b</li> <li>\u4e3a\u4e86\u6781\u81f4\u6548\u7387\uff0cPTv3 \u653e\u5f03\u4e86 Vector Attenion\uff0c\u56de\u5f52\u5230\u4e86\u70b9\u79ef\u6ce8\u610f\u529b\uff0c\u8fd9\u4f7f\u5f97\u5b83\u80fd\u5229\u7528 FlashAttention \u7b49\u52a0\u901f\u6280\u672f\u3002</li> </ul> <p>3\u3001xCPE\uff08Enhanced Conditional Positional Encoding\uff09</p> <ul> <li>\u79fb\u9664\u4e86\u8017\u65f6\u7684 RPE\uff0c\u6539\u7528\u4e00\u4e2a\u524d\u7f6e\u7684\u7a00\u758f\u5377\u79ef\u5c42\uff08Sparse Convolution\uff09\u6765\u9690\u5f0f\u7f16\u7801\u4f4d\u7f6e\u4fe1\u606f\uff0c\u6548\u7387\u6781\u9ad8\u3002</li> </ul> <p>\u5173\u952e\u8d21\u732e\u4e0e\u6548\u679c</p> <ul> <li>\u89c4\u6a21\u5373\u6b63\u4e49\uff1a \u8bc1\u660e\u4e86\u901a\u8fc7\u7b80\u5316\u8bbe\u8ba1\uff08\u653e\u5f03\u7cbe\u786e\u7684 kNN\uff0c\u4f7f\u7528\u5e8f\u5217\u5316\u8fd1\u4f3c\uff09\uff0c\u6362\u53d6\u66f4\u5927\u7684 \u89c4\u6a21\uff08\u611f\u53d7\u91ce\u4ece 16 \u70b9\u6269\u5c55\u5230 1024 \u70b9\uff09\u662f\u503c\u5f97\u7684 \u3002</li> <li>\u6781\u81f4\u6548\u7387\uff1a \u76f8\u6bd4 PTv2\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347 3.3 \u500d\uff0c\u5185\u5b58\u6d88\u8017\u964d\u4f4e 10 \u500d \u3002</li> <li>\u6548\u679c\uff1a \u5728\u5ba4\u5185\uff08ScanNet, S3DIS\uff09\u548c\u5ba4\u5916\uff08nuScenes, Waymo\uff09\u5171 20 \u591a\u4e2a\u4efb\u52a1\u4e0a\u8fbe\u5230 SOTA\u3002\u7279\u522b\u662f\u7ed3\u5408\u591a\u6570\u636e\u96c6\u8054\u5408\u8bad\u7ec3\uff08PPT\uff09\uff0cScanNet mIoU \u8fbe\u5230\u4e86 79.4% \u3002</li> </ul>"},{"location":"models/PointTransformer/#point-cloud-serialization","title":"Point Cloud Serialization","text":"<p>ptv3 \u7684\u6838\u5fc3\u7a81\u7834\u5728\u4e8e\u629b\u5f03\u4e86\u4f20\u7edf\u70b9\u4e91\u7f51\u7edc\u4e2d\u6602\u8d35\u7684\u90bb\u57df\u67e5\u8be2\uff08KNN \u6216 Ball Query\uff09\uff0c\u8f6c\u800c\u4f7f\u7528\u7a7a\u95f4\u586b\u5145\u66f2\u7ebf\u6765\u5b9e\u73b0\u9ad8\u6548\u7684\u5c40\u90e8\u6027\u5206\u7ec4\u3002</p> <p>\u4e3a\u4ec0\u4e48\u9700\u8981\u5e8f\u5217\u5316\uff1f</p> <p>\u4f20\u7edf\u505a\u6cd5\uff08\u5982 ptv2/v1\uff0cPointNet++\uff09\uff0c\u4e0d\u5bf9\u70b9\u505a\u4efb\u4f55\u5904\u7406\uff0c\u5c06\u70b9\u96c6\u89c6\u4e3a\u65e0\u5e8f\u96c6\u5408\uff0c\u70b9\u5728\u5185\u5b58\u4e2d\u662f\u4e71\u5e8f\u5b58\u50a8\u7684\uff1b\u4e3a\u4e86\u505a\u5377\u79ef\u6216 attention\uff0c\u5fc5\u987b\u5148\u627e\u5230\u90bb\u5c45\uff0c\u786e\u5b9a\u8ba1\u7b97\u6ce8\u610f\u529b\u6216\u8005\u5377\u79ef\u7684\u8303\u56f4\uff0c\u8fd9\u9700\u8981 KNN \u6216 Radius Search \u6765\u641c\u5bfb\u90bb\u5c45\uff0c\u8fd9\u4e9b\u64cd\u4f5c\u8bbe\u8ba1\u5927\u91cf\u7684\u968f\u673a\u5185\u5b58\u8bbf\u95ee\uff08Random Memory Access\uff09\uff0c\u5bf9 GPU \u6781\u5176\u4e0d\u53cb\u597d\uff0c\u5bfc\u81f4\u663e\u5b58\u5360\u7528\u9ad8\u3001\u901f\u5ea6\u6162\u3002</p> <p>ptv3 \u901a\u8fc7\u6309\u7167\u67d0\u79cd\u7279\u5b9a\u89c4\u5219\uff0c\u5982\uff08z-order \u6216 Hilbert \u66f2\u7ebf\uff09\uff0c\u628a\u70b9\u4e91\u6309\u7167\u7a7a\u95f4\u4f4d\u7f6e\u6392\u597d\u5e8f\uff0c\u901a\u5e38\u6309\u7167\u8fd9\u79cd\u7a7a\u95f4\u586b\u5145\u66f2\u7ebf\u7684\u8fde\u63a5\u987a\u5e8f\u6392\u5e8f\uff0c\u8fd9\u6837\u5728\u66f2\u7ebf\u987a\u5e8f\u4e0a\u76f8\u90bb\uff08\u5185\u5b58\u91cc\u76f8\u90bb\uff09\u7684\u70b9\uff0c\u5728 3D \u7a7a\u95f4\u91cc\u5927\u6982\u7387\u4e5f\u662f\u76f8\u90bb\u7684\u3002\u8fd9\u6837\u6211\u4eec\u5c31\u4e0d\u9700\u8981\u8fdb\u884c\u8017\u65f6\u7684 KNN \u6765\u627e\u90bb\u5c45\u4e86\uff0c\u76f4\u63a5\u5207\u4e00\u6bb5\u5185\u5b58\uff08Patch\uff09\u51fa\u6765\u7b97 Attention \u5c31\u53ef\u4ee5\u4e86\u3002</p> <p>\u5e8f\u5217\u5316\u7684\u5177\u4f53\u6d41\u7a0b</p> <p>ptv3 \u7684\u5e8f\u5217\u5316\u8fc7\u7a0b\u53ef\u4ee5\u6982\u62ec\u4e3a\uff1a\u7f51\u683c\u5316\uff08Grid\uff09-&gt; \u7f16\u7801\uff08code\uff09-&gt; \u6392\u5e8f\uff08sort\uff09-&gt; \u5206\u5757(Patch)\u3002</p> <p>\u7b2c\u4e00\u6b65\uff1a\u7f51\u683c\u5316\u4e0e\u5750\u6807\u6620\u5c04\uff08Grid Sampling\uff09</p> <p>\u9996\u5148\u5c06\u8fde\u7eed\u7684\u6d6e\u70b9\u6570\u5750\u6807 \\((x,y,z)\\) \u6620\u5c04\u5230\u79bb\u6563\u7684\u6574\u6570\u7f51\u683c\u5750\u6807 \\((x_{idx},y_{idx},z_{idx})\\) \u4e0a\uff0c\u8fd9\u4e00\u6b65\u6709\u70b9\u50cf\u4f53\u7d20\u5316\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u65b9\u4fbf\u540e\u7eed\u7684\u7f16\u7801\u3002</p> <p>\u7b2c\u4e8c\u6b65\uff1a\u7a7a\u95f4\u586b\u5145\u66f2\u7ebf\u7f16\u7801\uff08Space-Filling Curve Encoding\uff09</p> <p>\u8fd9\u4e00\u6b65\u662f\u5e8f\u5217\u5316\u7684\u7075\u9b42\u662f\uff0c\u662f\u51b3\u5b9a\u70b9\u4e91\u5e8f\u5217\u987a\u5e8f\u7684\u5173\u952e\u3002ptv3 \u901a\u5e38\u4f7f\u7528 z-order curve\uff08Morton Code\uff09\u6216 Hilbert Curve\u3002\u5b83\u4eec\u53ef\u4ee5\u5c06 3D \u7684\u6574\u6570\u5750\u6807(x, y, z)\u8f6c\u5316\u6210\u4e00\u4e2a\u4e3a\u552f\u4e00\u7684 1D \u6574\u6570\uff0c\u5e76\u4e14\u5177\u6709\u826f\u597d\u7684\u7a7a\u95f4\u5c40\u90e8\u6027\uff0c\u4e5f\u5c31\u662f\u5728 3D \u7a7a\u95f4\u4e2d\u9760\u8fd1\u7684\u4e24\u4e2a\u70b9\uff0c\u5b83\u4eec\u7684 Morton Code \u6570\u503c\u901a\u5e38\u4e5f\u975e\u5e38\u63a5\u8fd1\u3002</p> <p>\u7b2c\u4e09\u6b65\uff1a\u6392\u5e8f\uff08Sorting\uff09</p> <p>\u6839\u636e\u8ba1\u7b97\u51fa\u7684 Morton Code \u4e8c\u8fdb\u5236\u503c\u5f97\u5927\u5c0f\u5bf9\u6240\u6709\u70b9\u8fdb\u884c\u91cd\u6392\u3002\u91cd\u6392\u540e\uff0c\u5185\u5b58\u4e2d\u5f97\u70b9\u4e91\u4e0d\u518d\u662f\u4e71\u5e8f\u7684\uff0c\u800c\u662f\u6839\u636e Morton Code \u7684\u5927\u5c0f\u987a\u5e8f\u5728\u5185\u5b58\u4e2d\u8fde\u7eed\u6392\u5217\uff0c\u8fd9\u4e9b\u70b9\u5728\u7a7a\u95f4\u4e2d\u4f1a\u6cbf\u7740 Z \u5b57\u5f62\u66f2\u7ebf\u5728\u7a7a\u95f4\u4e2d\u873f\u8712\u6392\u5217\u3002</p> <p>\u7b2c\u56db\u6b65\uff1a\u5206\u5757\uff08Patching/Flattening\uff09</p> <p>\u5c06\u6392\u597d\u5e8f\u7684\u957f\u5e8f\u5217\uff0c\u76f4\u63a5\u6309\u7167\u56fa\u5b9a\u7684\u957f\u5ea6\uff08Block Size\uff0c\u4f8b\u5982 1024 \u6216 2048\uff09\u5207\u5206\u6210\u82e5\u5e72\u4e2a Patch\uff0c\u8fd9\u4e00\u6b65\u5c31\u662f\u7528\u6765\u786e\u5b9a\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u8303\u56f4\u7684\uff0c\u76f8\u6bd4\u4e8e knn \u7684\u90bb\u57df\u67e5\u8be2\uff0c\u7531\u4e8e\u67e5\u8be2\u590d\u6742\uff0c\u90bb\u57df\u4e00\u822c\u8bbe\u4e3a 16 \u6216\u8005 32\uff0c\u5f88\u96be\u63d0\u5347\uff0c\u4f46\u662f\u8fd9\u91cc\u7531\u4e8e\u8fd9\u4e2a\u957f\u5e8f\u5217\u5728\u5185\u5b58\u4e2d\u8fde\u7eed\u6392\u5217\uff0c\u53ef\u4ee5\u8f7b\u677e\u901a\u8fc7 reshape \u5b9e\u73b0\u5206\u5757\uff0c\u901f\u5ea6\u6781\u5feb\uff0c\u540c\u65f6\u90bb\u57df\u53ef\u4ee5\u8f7b\u677e\u8bbe\u7f6e\u7684\u5f88\u5927\uff0c\u5982 1024 \u6216 2048\uff0c\u4e14\u5bf9\u8017\u65f6\u6ca1\u6709\u5f71\u54cd\u3002</p>"},{"location":"models/PointTransformer/#serialized-attention","title":"\u5e8f\u5217\u5316\u6ce8\u610f\u529b\uff08Serialized Attention\uff09","text":"<p>\u5b8c\u6210\u4e0a\u8ff0\u5e8f\u5217\u5316\u4e4b\u540e\uff0c3D \u4efb\u52a1\u5c31\u53d8\u6210\u4e86 1D \u5e8f\u5217\u4efb\u52a1\u3002</p> <p>\u5c40\u90e8 attention\uff0c\u5728\u6bcf\u4e00\u4e2a patch \u5185\u90e8\u8fdb\u884c self-attention \u8fd0\u7b97\uff08\u6807\u51c6\u7684\u70b9\u79ef\u6ce8\u610f\u529b\uff09\uff0c\u5bf9 patch \u5185\u90e8\u6240\u6709\u70b9\u8fdb\u884c\u7279\u5f81\u66f4\u65b0\uff1b</p>"},{"location":"models/PointTransformer/#xcpe","title":"\u4f4d\u7f6e\u7f16\u7801\uff08xCPE\uff09","text":"<p>\u5728\u5c06 3D \u70b9\u4e91\u4f7f\u7528\u5e8f\u5217\u5316\u5c55\u5e73\u4e3a 1D \u5e8f\u5217\u4e4b\u524d\uff0c\u5bf9 3D \u70b9\u4e91\u8fdb\u884c\u7a00\u758f\u5377\u79ef\uff0c\u5c06\u8ba1\u7b97\u7ed3\u679c\u4f5c\u4e3a\u4f4d\u7f6e\u7f16\u7801\uff0c\u52a0\u5230\u70b9\u7684\u7279\u5f81\u4e2d\uff0c\u7136\u540e\u5c55\u5e73\u7684 1D \u5e8f\u5217\u7684\u70b9\u7684\u7279\u5f81\u4e2d\u5c31\u5305\u542b\u4e86\u4f4d\u7f6e\u7f16\u7801\u4fe1\u606f\uff0c\u76f8\u6bd4\u4e8e ptv2 \u4f7f\u7528\u5750\u6807\u5dee\uff0c\u7ecf\u8fc7 mlp \u6620\u5c04\u7684\u5750\u6807\u7f16\u7801\u8ba1\u7b97\u65b9\u5f0f\u6765\u8bf4\uff0c\u907f\u514d\u4e86 KNN \u90bb\u57df\u67e5\u8be2\uff0c\u540c\u65f6\u6ce8\u610f\u529b\u9000\u5316\u4f7f\u7528\u6807\u51c6\u70b9\u79ef\u6ce8\u610f\u529b\uff0c\u53ef\u4ee5\u901a\u8fc7 FlashAttention \u6765\u52a0\u901f\u8ba1\u7b97\u3002</p> <p>\u4f46\u662f\u7b80\u5355\u7684\u6392\u5e8f\u5207\u7247\u6709\u4e00\u4e2a\u81f4\u547d\u5f31\u70b9\uff1a\u8fb9\u754c\u6548\u5e94\u3002\u6bd4\u5982\u70b9 A \u7d22\u5f15 1023\uff0c\u70b9 B \u5728\u7d22\u5f15 1024\uff0c\u5b83\u4fe9\u5728 3D \u7a7a\u95f4\u53ef\u80fd\u7d27\u6328\u7740\uff0c\u4f46\u662f\u5374\u88ab\u5f3a\u884c\u5207\u5206\u5230\u4e86\u4e24\u4e2a\u4e0d\u540c\u7684 Patch \u91cc\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5728\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u4ea4\u4e92\u3002\u89e3\u51b3\u65b9\u6cd5\u5982\u4e0b\uff1a</p> <ul> <li>\u591a\u91cd\u6392\u5e8f\uff0c\u5728\u4e0d\u540c\u7684 Transformer \u5c42\u4e2d\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u6392\u5e8f\u903b\u8f91\uff08\u4f8b\u5982\u5c42 1 \u7528 z-order\uff0c\u5c42 2 \u7528 Hilbert\uff0c\u6216\u8005\u5bf9\u5750\u6807\u8fdb\u884c shift \u518d\u6392\u5e8f\uff09\uff0c\u5904\u7406\u4e4b\u540e\uff0c\u8fd9\u4e00\u5c42\u7684\u8fb9\u754c\u70b9\uff0c\u5728\u4e0b\u4e00\u5c42\u91cd\u65b0\u6392\u5e8f\u540e\u53ef\u80fd\u5c31\u53d8\u6210\u4e86\u4e2d\u5fc3\u70b9\uff0c\u901a\u8fc7\u591a\u5c42\u5806\u53e0\uff0c\u4fe1\u606f\u5c31\u80fd\u5728\u6574\u4e2a\u70b9\u4e91\u4e2d\u6d41\u52a8\u3002</li> </ul> <p>\u6362\u53e5\u8bdd\u8bf4\uff0c\u5c31\u662f\u6bcf\u6b21\u8ba1\u7b97\u5e8f\u5217\u6ce8\u610f\u529b\u4e4b\u524d\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u5e8f\u5217\u5316\u987a\u5e8f\uff0c\u5f97\u5230\u4e0d\u540c\u7684 1D \u5e8f\u5217\uff0c\u8fd9\u6837\u6bcf\u4e00\u5c42\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u90bb\u5c45\u90fd\u4e0d\u540c\uff0c\u8fd9\u4e00\u5c42\u53ef\u80fd\u5c06\u90bb\u5c45\u62c6\u5f00\u4e86\uff0c\u53ef\u80fd\u4e0b\u4e00\u5c42\u5c31\u5728\u4e00\u8d77\u4e86\uff0c\u8fd9\u6837\u6ce8\u610f\u529b\u7684\u4ea4\u4e92\u5c31\u80fd\u8de8\u8d8a\u66f4\u5927\u8303\u56f4\uff0c\u5728\u6574\u4e2a\u70b9\u4e91\u95f4\u6d41\u52a8\u3002</p> <p>\u53c2\u8003\uff1a</p> <p>Gemini \u5bf9\u8bdd\u8bb0\u5f55</p>"},{"location":"models/octfomer/","title":"OctFormer\uff1aOctree-based Transformers for 3D Point Clouds","text":""},{"location":"models/octfomer/#octformeroctree-based-transformers-for-3d-point-clouds","title":"OctFormer\uff1aOctree-based Transformers for 3D Point Clouds","text":""},{"location":"models/octfomer/#_1","title":"\u521b\u65b0\u4e0e\u8d21\u732e","text":"<p>\u6838\u5fc3\u601d\u60f3\u4e0e\u80cc\u666f\u75db\u70b9</p> <p>\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u5728\u4e8e\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u516b\u53c9\u6811\u6ce8\u610f\u529b\u673a\u5236\uff08Octree Attention\uff09\u7684\u70b9\u4e91\u9aa8\u5e72\u7f51\u7edc\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u70b9\u4e91 Transformer \u7684\u6548\u7387\u74f6\u9888\u3002\u5728\u4ee5\u5f80\u7684\u65b9\u6cd5\u4e2d\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u901a\u5e38\u4f9d\u8d56\u4e8e KNN \u6216 Ball Query \u6765\u6784\u5efa\u5c40\u90e8\u90bb\u57df\u3002\u8fd9\u610f\u5473\u7740\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u4e2d\u5fc3\u70b9\uff0c\u7f51\u7edc\u90fd\u9700\u8981\u8fdb\u884c\u4e00\u6b21\u6602\u8d35\u7684\u6700\u8fd1\u90bb\u641c\u7d22\u3002\u8fd9\u79cd\u65b9\u5f0f\u4e0d\u4ec5\u8017\u65f6\uff0c\u800c\u4e14\u5bfc\u81f4\u4e86\u5927\u91cf\u7684\u8ba1\u7b97\u5197\u4f59\u2014\u2014\u56e0\u4e3a\u90bb\u57df\u4e4b\u95f4\u5f80\u5f80\u9ad8\u5ea6\u91cd\u53e0\uff08\u70b9 A \u65e2\u662f\u70b9 B \u7684\u90bb\u5c45\uff0c\u4e5f\u53ef\u80fd\u662f\u70b9 C \u7684\u90bb\u5c45\uff09\u3002\u8fd9\u79cd\u201c\u6ed1\u52a8\u7a97\u53e3\u201d\u5f0f\u7684\u8ba1\u7b97\u6a21\u5f0f\u65e0\u6cd5\u6709\u6548\u5229\u7528 GPU \u7684\u5e76\u884c\u80fd\u529b\uff0c\u6210\u4e3a\u4e86\u9650\u5236\u6a21\u578b\u5904\u7406\u5927\u89c4\u6a21\u70b9\u4e91\u7684\u4e3b\u8981\u969c\u788d\u3002</p> <p>\u6838\u5fc3\u673a\u5236\uff1a\u4ece\u7a7a\u95f4\u641c\u7d22\u5230\u5e8f\u5217\u5207\u5206</p> <p>OctFormer \u5f7b\u5e95\u6452\u5f03\u4e86\u6602\u8d35\u7684\u90bb\u57df\u641c\u7d22\uff0c\u8f6c\u800c\u91c7\u7528\u4e00\u79cd\u201c\u6392\u5e8f+\u5207\u5206\u201d\u7684\u7b56\u7565\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5b83\u9996\u5148\u5bf9\u8f93\u5165\u70b9\u4e91\u6784\u5efa\u516b\u53c9\u6811\uff0c\u5229\u7528\u975e\u7a7a\u53f6\u5b50\u8282\u70b9\uff08\u4f53\u7d20\uff09\u7684\u6574\u6570\u5750\u6807\u8ba1\u7b97 Morton \u7801\uff08Shuffled Key\uff09\u3002\u57fa\u4e8e Morton \u7801\u7684\u6392\u5e8f\u5c06\u539f\u672c\u6563\u4e71\u7684\u4e09\u7ef4\u7a7a\u95f4\u4f53\u7d20\u6620\u5c04\u4e3a\u4e00\u7ef4\u7684 Z-order \u5e8f\u5217\u3002Z-order \u7684\u7279\u6027\u4fdd\u8bc1\u4e86\u5e8f\u5217\u4e2d\u76f8\u90bb\u7684\u5143\u7d20\u5728\u7269\u7406\u7a7a\u95f4\u4e2d\u4e5f\u662f\u7d27\u5bc6\u76f8\u90bb\u7684\u3002</p> <p>\u57fa\u4e8e\u8fd9\u4e2a\u6709\u5e8f\u5e8f\u5217\uff0cOctFormer \u76f4\u63a5\u6309\u56fa\u5b9a\u6570\u91cf \\(K\\)\uff08\u4f8b\u5982 32 \u4e2a\u70b9\uff09\u8fdb\u884c\u622a\u65ad\u5212\u5206\uff0c\u5c06\u5e8f\u5217\u5207\u5206\u4e3a\u4e00\u4e2a\u4e2a\u4e92\u4e0d\u91cd\u53e0\u7684\u5c40\u90e8\u7a97\u53e3\u3002\u867d\u7136\u8fd9\u79cd\u5207\u5206\u65b9\u5f0f\u4f1a\u5bfc\u81f4\u7a97\u53e3\u5728\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u7684\u51e0\u4f55\u5f62\u72b6\u53d8\u5f97\u4e0d\u89c4\u5219\uff08\u4e0d\u518d\u662f\u6807\u51c6\u7684\u7acb\u65b9\u4f53\uff09\uff0c\u4f46\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u7a97\u53e3\u7684\u5f62\u72b6\u5e76\u4e0d\u654f\u611f\uff0c\u56e0\u6b64\u6027\u80fd\u672a\u53d7\u5f71\u54cd\u3002\u8fd9\u4e00\u8bbe\u8ba1\u7684\u6700\u5927\u4f18\u52bf\u5728\u4e8e\uff1a\u5b83\u5c06\u590d\u6742\u7684\u7a7a\u95f4\u90bb\u57df\u641c\u7d22\u7b80\u5316\u4e3a\u4e86\u6781\u4f4e\u6210\u672c\u7684 Tensor Reshape \u64cd\u4f5c\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u4e8c\u6b21\u65b9\u964d\u4e3a\u7ebf\u6027\uff0c\u6781\u5927\u5730\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\u3002</p> <p>\u611f\u53d7\u91ce\u6269\u5c55\u4e0e\u5e76\u884c\u8ba1\u7b97</p> <p>\u5f53\u7136\uff0c\u8fd9\u79cd\u786c\u6027\u7684\u5e8f\u5217\u5207\u5206\u4e5f\u5b58\u5728\u526f\u4f5c\u7528\uff1a\u7269\u7406\u7a7a\u95f4\u8fb9\u754c\u4e0a\u7684\u70b9\u53ef\u80fd\u4f1a\u4e0e\u5176\u539f\u672c\u7684\u51e0\u4f55\u90bb\u5c45\u88ab\u5212\u5206\u5230\u4e0d\u540c\u7684\u7a97\u53e3\u4e2d\uff0c\u4ece\u800c\u5207\u65ad\u4e86\u5c40\u90e8\u7684\u4ea4\u4e92\u3002\u4e3a\u4e86\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u8bba\u6587\u5f15\u5165\u4e86\u6269\u5f20\u6ce8\u610f\u529b\uff08Dilated Attention\uff09\u3002\u7c7b\u4f3c\u4e8e\u7a7a\u6d1e\u5377\u79ef\uff0c\u5b83\u901a\u8fc7\u5728\u5e8f\u5217\u4e2d\u95f4\u9694\u91c7\u6837\uff08\u4f8b\u5982\u6bcf\u9694 4 \u4e2a\u70b9\u9009\u4e00\u4e2a\uff09\u6765\u6784\u5efa\u7a97\u53e3\uff0c\u5728\u4e0d\u589e\u52a0\u8ba1\u7b97\u91cf\u7684\u524d\u63d0\u4e0b\u663e\u8457\u6269\u5927\u4e86\u611f\u53d7\u91ce\uff0c\u4fc3\u8fdb\u4e86\u8de8\u7a97\u53e3\u7684\u4fe1\u606f\u4ea4\u6d41\u3002\u8fd9\u79cd\u56fa\u5b9a\u70b9\u6570\u7684\u7a97\u53e3\u5212\u5206\u7b56\u7565\uff08\u65e0\u8bba\u662f\u6807\u51c6\u8fd8\u662f\u6269\u5f20\u6a21\u5f0f\uff09\u90fd\u5b8c\u7f8e\u5951\u5408\u4e86 GPU \u7684 SIMD \u67b6\u6784\uff0c\u4f7f\u5f97\u5e76\u884c\u8ba1\u7b97\u6548\u7387\u8fbe\u5230\u4e86\u6781\u81f4\u3002</p> <p>\u6761\u4ef6\u4f4d\u7f6e\u7f16\u7801 (CPE)</p> <p>\u6700\u540e\uff0c\u9488\u5bf9\u7a97\u53e3\u5f62\u72b6\u4e0d\u89c4\u5219\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff08Relative PE\uff09\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u3002OctFormer \u521b\u65b0\u6027\u5730\u5f15\u5165\u4e86\u6761\u4ef6\u4f4d\u7f6e\u7f16\u7801\uff08Conditional Positional Encoding, CPE\uff09\u3002\u5b83\u4e0d\u518d\u4f7f\u7528\u56fa\u5b9a\u7684\u7f16\u7801\u8868\uff0c\u800c\u662f\u5229\u7528\u516b\u53c9\u6811\u7279\u6709\u7684\u6df1\u5ea6\u5377\u79ef\uff08Depthwise Convolution\uff09\uff0c\u6839\u636e\u5f53\u524d\u7684\u7279\u5f81\u72b6\u6001\u52a8\u6001\u751f\u6210\u4f4d\u7f6e\u7f16\u7801\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u52a8\u6001\u7f16\u7801\u65b9\u5f0f\u6bd4\u56fa\u5b9a\u7f16\u7801\u66f4\u9002\u5408\u5904\u7406\u975e\u7ed3\u6784\u5316\u7684\u70b9\u4e91\u6570\u636e\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002</p>"},{"location":"models/octfomer/#_2","title":"\u7f51\u7edc\u67b6\u6784","text":"<p>OctFormer \u7684\u6574\u4f53\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p>Figure 1: OctFormer \u7684\u6574\u4f53\u7f51\u7edc\u67b6\u6784<p></p> <p>\u4e3b\u8981\u5305\u62ec\u7279\u5f81\u5d4c\u5165 Embedding\u3001OctFormer Block\u3001Downsampling \u4e09\u4e2a\u6a21\u5757\u3002</p>"},{"location":"models/octfomer/#embedding","title":"Embedding","text":"<p>\u5728\u8fdb\u5165\u795e\u7ecf\u7f51\u7edc\u4e4b\u524d\uff0c\u539f\u59cb\u70b9\u4e91\u9700\u8981\u7ecf\u8fc7\u7279\u5b9a\u7684\u7ed3\u6784\u5316\u5904\u7406\uff0c\u8fd9\u662f OctFormer \u80fd\u9ad8\u6548\u8fd0\u884c\u7684\u57fa\u77f3\u3002\u5047\u8bbe\u539f\u59cb\u70b9\u4e91\u5305\u542b M \u4e2a\u70b9\uff0c\u6bcf\u4e2a\u70b9\u6709\u5750\u6807 \\((x,y,z)\\) \u548c\u7279\u5f81\uff08\u5982\u989c\u8272 RGB\u3001\u6cd5\u5411\u91cf\u7b49\uff09\u3002</p>"},{"location":"models/octfomer/#_3","title":"\u6570\u636e\u9884\u5904\u7406","text":"<p>\u7b2c\u4e00\u6b65\u662f\u5bf9\u70b9\u4e91\u5750\u6807\u8fdb\u884c\u5f52\u4e00\u5316\uff08\u8bba\u6587\u4e2d\u63d0\u5230\u7684\u662f\u4e58\u4ee5\u4e00\u4e2a\u7f29\u653e\u56e0\u5b50 scale factor 0.01m\uff09\uff0c\u7136\u540e\u6784\u5efa\u6df1\u5ea6\u4e3a 11 \u7684\u516b\u53c9\u6811\uff0c\u8fd9\u76f8\u5f53\u4e8e\u5c06\u7a7a\u95f4\u5212\u5206\u4e3a 2048\u00d72048\u00d72048 \u4e2a\u5fae\u5c0f\u4f53\u7d20\uff0c\u7136\u540e\u6839\u636e\u6bcf\u4e2a\u975e\u7a7a\u4f53\u7d20\u5728\u8fd9 2048\u00d72048\u00d72048 \u7684\u7acb\u65b9\u4f53\u7f51\u683c\u4e2d\u7684\u6574\u6570\u5750\u6807\uff0c\u4e3a\u6bcf\u4e2a\u975e\u7a7a\u4f53\u7d20\u8ba1\u7b97 Shuffle Key\uff08Morton Code\uff09\uff0c\u5e76\u6839\u636e\u8fd9\u4e2a Key \u5bf9\u975e\u7a7a\u4f53\u7d20\u8fdb\u884c\u6392\u5e8f\uff08Z-order \u6392\u5e8f\uff09\u3002</p> <p>\u7136\u540e\u662f\u7279\u5f81\u521d\u59cb\u5316\uff0c\u5c06\u5c5e\u4e8e\u540c\u4e00\u4e2a\u516b\u53c9\u6811\u53f6\u5b50\u8282\u70b9\u7684\u70b9\u7684\u7279\u5f81\uff08\u4f4d\u7f6e\u3001\u989c\u8272\u3001\u6cd5\u5411\u91cf\uff09\u53d6\u5e73\u5747\u503c\uff0c\u4f5c\u4e3a\u8fd9\u4e2a\u975e\u7a7a\u4f53\u7d20\u8282\u70b9\u7684\u521d\u59cb\u7279\u5f81\u3002\u56e0\u6b64\u521d\u59cb\u5f20\u91cf\u5f62\u72b6\u4e3a \\((N_{raw},C_{in})\\)\uff0c\u5176\u4e2d \\(N_{raw}\\) \u662f\u975e\u7a7a\u53f6\u5b50\u8282\u70b9\u7684\u6570\u91cf\uff0c\\(C_{in}\\) \u662f\u8f93\u5165\u7279\u5f81\u7ef4\u5ea6\uff08\u901a\u5e38\u5305\u542b\u4f4d\u7f6e\u3001\u989c\u8272\u3001\u6cd5\u5411\u91cf\uff09\u3002</p>"},{"location":"models/octfomer/#_4","title":"\u516b\u53c9\u6811\u5377\u79ef","text":"<p>\u8fd9\u4e00\u6b65\u7684\u4f5c\u7528\u662f\u5c06\u4f4e\u7ef4\u51e0\u4f55\u7279\u5f81\u6620\u5c04\u5230\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4\uff0c\u5e76\u8fdb\u884c\u521d\u6b65\u7684\u7a7a\u95f4\u4e0b\u91c7\u6837\u3002\u9996\u5148\u63a5\u6536\u524d\u4e00\u6b65\u6392\u597d\u5e8f\u7684\u975e\u7a7a\u4f53\u7d20\u7684\u7279\u5f81\u5f20\u91cf \\((N_{raw},C_{in})\\)</p> <p>\u8ba1\u7b97\u8fc7\u7a0b\uff1a\u91c7\u7528 5 \u5c42\u516b\u53c9\u6811\u5377\u79ef\u5e8f\u5217\uff08\u6838\u5fc3\u90fd\u662f\u5c06\u8f93\u5165\u7279\u5f81\u548c\u5377\u79ef\u6838\u8fdb\u884c\u76f8\u4e58\u5e76\u6c42\u548c\uff0c\u7136\u540e\u6ed1\u52a8\u5377\u79ef\u7a97\u53e3\uff0c\u5e76\u6539\u53d8\u901a\u9053\u6570\u3001\u7a7a\u95f4\u5206\u8fa8\u7387\uff09\uff0c\u91c7\u7528\u7684\u5377\u79ef\u6838\u5927\u5c0f/\u6b65\u957f\u5e8f\u5217\u4e3a\uff1a(3,1) \\(\\to\\) (2,2) \\(\\to\\) (3,1) \\(\\to\\) (2,2) \\(\\to\\) (3,1) \u3002\u5176\u4e2d\u4e24\u6b21\u6b65\u957f\u4e3a 2 \u7684\u5377\u79ef\u5b9e\u73b0\u4e86\u7a7a\u95f4\u5206\u8fa8\u7387\u7684 4 \u500d\u4e0b\u91c7\u6837\uff08\u76f8\u5f53\u4e8e\u5e8f\u5217\u957f\u5ea6\u7f29\u77ed\u4e3a\u539f\u6765 \u00bc\uff09\u3002</p> <p>\u8f93\u51fa\u5f62\u72b6\uff1a\u7a7a\u95f4\u7ef4\u5ea6\uff1a\\(N=N_{raw}/4\\)\uff08\u8fd1\u4f3c\uff09\uff0c\u548c\u56fe\u4e2d\u6807\u6ce8\u7684 \\(S/4\\) \u4e00\u81f4\u3002\u901a\u9053\u7ef4\u5ea6\uff1a\u4ece\u539f\u59cb\u7684\u4f4d\u7f6e+RGB\\\u6cd5\u5411\u91cf\u6620\u5c04\u5230 \\(C\\)\uff08\u901a\u5e38\u662f 96 \u7ef4\uff09\uff1b\u5904\u7406\u540e\u7684\u5f20\u91cf\u5f62\u72b6\u4e3a \\((N,C)\\)\u3002</p>"},{"location":"models/octfomer/#octformer-block","title":"OctFormer Block","text":"<p>\u7f51\u7edc\u7684\u6838\u5fc3\u7ed3\u6784\uff0c\u6839\u636e\u56fe\u793a\uff0c\u4e24\u4e2a\u8fde\u7eed\u7684 Block \u5206\u522b\u4f7f\u7528 <code>Dilation=1</code> \u548c <code>Dilation=4</code>\u3002</p> <p></p>Figure 2: OctFormer Block<p></p>"},{"location":"models/octfomer/#cpe","title":"\u6761\u4ef6\u4f4d\u7f6e\u7f16\u7801\uff08CPE\uff09","text":"<p>\u8f93\u5165\u4e3a\u524d\u9762 5 \u5c42\u516b\u53c9\u6811\u5377\u79ef\u7684\u7ed3\u679c \\(X=(N,C)\\)\uff0c\u4f7f\u7528\u516b\u53c9\u6811\u6df1\u5ea6\u5377\u79ef\u52a8\u6001\u751f\u6210\u4f4d\u7f6e\u7f16\u7801\u5e76\u52a0\u5230\u8f93\u5165\u4e0a\u3002\u5177\u4f53\u8ba1\u7b97\u65b9\u5f0f\u5982\u4e0b\uff1a</p> \\[ X = X+BatchNorm(DepthwiseConv(X)) \\] <p>\u53ef\u80fd\u662f\u56e0\u4e3a X \u5305\u542b\u4e86\u516b\u53c9\u6811\u5377\u79ef\u524d\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u518d\u901a\u8fc7\u516b\u53c9\u6811\u6df1\u5ea6\u5377\u79ef\uff0c\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u8fdb\u4e00\u6b65\u5904\u7406\uff0c\u5f97\u5230\u80fd\u591f\u8868\u5f81\u4f4d\u7f6e\u7684\u7279\u5f81\uff0c\u52a0\u5230\u539f\u59cb\u7684\u7ed3\u679c \\(X\\) \u4e0a\u3002</p>"},{"location":"models/octfomer/#_5","title":"\u6807\u51c6\u516b\u53c9\u6811\u6ce8\u610f\u529b","text":""},{"location":"models/octfomer/#dilation-1","title":"Dilation = 1","text":"<p>\u7b2c\u4e00\u6b65\u662f\u586b\u5145\uff08Padding\uff09\uff1a</p> <p>\u6211\u4eec\u9700\u8981\u68c0\u67e5 \\(N\\) \u662f\u5426\u80fd\u88ab\u7a97\u53e3\u5927\u5c0f \\(K=32\\) \u6574\u9664\uff0c\u5982\u679c\u4e0d\u80fd\u6574\u9664\uff0c\u5219\u8865\u96f6\u5230 \\(\\hat{N}\\)\u3002</p> <p>\u7b2c\u4e8c\u6b65\u662f\u7a97\u53e3\u5212\u5206\uff08Window Partition\uff09\uff1a</p> <p>\u6211\u4eec\u5c06\u8f93\u5165\u5f20\u91cf \\((\\hat{N},C)\\) \u53d8\u4e3a \\((B,K,C)\\)\uff0c\u5176\u4e2d \\(B=\\hat{N}/32\\) \u662f\u7a97\u53e3\u6570\u91cf\u3002\u6b64\u65f6\uff0c\u6bcf\u4e2a \\(K\\) \u7ef4\u5ea6\u5185\u7684 32 \u4e2a\u70b9\u5728 Z \u5e8f\u4e0a\u662f\u8fde\u7eed\u7684\uff08\u7a7a\u95f4\u4e0a\u4e5f\u662f\u805a\u96c6\u7684\uff09\u3002</p> <p>\u7b2c\u4e09\u6b65\u662f\u8fdb\u884c Attention \u7684\u8ba1\u7b97\uff1a</p> <p>\u7531\u4e8e\u6bcf\u4e2a\u7a97\u53e3\u5185\u70b9\u7684\u6570\u91cf\u90fd\u4e00\u6837\uff0c\u6211\u4eec\u53ef\u4ee5 concat \u8d77\u6765\u5e76\u884c\u6267\u884c <code>Multi-head Self-Attention</code>\uff0c\u590d\u6742\u5ea6\u4ece \\(O(N^2)\\) \u964d\u4e3a\u8fd1\u4f3c\u7ebf\u6027 \\(O(KN)\\)\uff0c\\(K\\) \u4e3a\u7a97\u53e3\u5185\u70b9\u4e91\u4e2a\u6570</p> <p>\u7b2c\u56db\u6b65\u662f\u9006\u64cd\u4f5c\uff1a</p> <p>\u5c06 attention \u8ba1\u7b97\u7ed3\u679c Flatten \u56de \\((\\hat{N},C)\\)\uff0c\u7136\u540e\u79fb\u9664\u586b\u5145\u90e8\u5206\uff0c\u6062\u590d\u4e3a \\((N,C)\\)\u3002</p> <p>\u7b2c\u4e94\u6b65\u662f\u524d\u9988\u7f51\u7edc MLP\uff1a</p> <p>\u7ecf\u8fc7 LayerNorm \u5c42\u5f52\u4e00\u5316\u540e\u8fdb\u5165 MLP\uff08\u4e24\u5c42\u5168\u8fde\u63a5\uff0c\u4e2d\u95f4 GELU \u6fc0\u6d3b\uff09\uff0c\u901a\u9053\u81a8\u80c0\u6bd4\u4e3a 4\uff0c\u901a\u8fc7\u7b2c\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\uff0c\u901a\u9053\u6570\u53d8\u4e3a \\(4C\\)\uff0c\u7b2c\u4e8c\u5c42\u5168\u8fde\u63a5\u5c42\u5c06\u901a\u9053\u6570\u53d8\u56de \\(C\\)\u3002</p>"},{"location":"models/octfomer/#dilation-4","title":"Dilation = 4","text":"<p>\u76ee\u7684\u662f\u6269\u5927\u611f\u53d7\u91ce\uff0c\u8ba9\u4fe1\u606f\u5728\u4e0d\u540c\u7a97\u53e3\u95f4\u901a\u8fc7\u3002\u5177\u4f53\u539f\u7406\u7c7b\u4f3c\u6251\u514b\u724c\u53d1\u724c\uff0c\u4e4b\u524d <code>Dilation=1</code> \u7684\u65f6\u5019\uff0c\u5c31\u50cf\u662f\u7ed9\u4e00\u4e2a\u4eba\u8fde\u7eed\u53d1\u724c\uff0c\u53d1\u5b8c 32 \u5f20\u4f5c\u4e3a\u4e00\u7ec4\uff0c\u7136\u540e\u518d\u63a5\u7740\u7ed9\u540c\u4e00\u4e2a\u4eba\u53d1\uff0c\u4f5c\u4e3a\u7b2c\u4e8c\u7ec4\uff0c\u4e00\u4e2a\u4eba\u4f1a\u5f97\u5230\u5f88\u591a\u7ec4\u724c\uff0c\u4f46\u662f\u6bcf\u7ec4\u724c\u90fd\u662f\u5728 Z \u5e8f\uff08\u7269\u7406\u7a7a\u95f4\uff09\u4e0a\u76f8\u90bb\u7684\uff0c\u611f\u53d7\u91ce\u6709\u9650\uff1b\u4f46\u662f <code>Dilation=4</code> \u7684\u65f6\u5019\uff0c\u5c31\u76f8\u5f53\u4e8e\u8f6e\u6d41\u7ed9 4 \u4e2a\u4eba\u53d1\u724c\uff0c\u5148\u7ed9\u7b2c\u4e00\u4e2a\u4eba\u53d1\u4e00\u5f20\uff0c\u518d\u7ed9\u7b2c\u4e8c\u4e2a\u4eba\u53d1\u4e00\u5f20\uff0c\u518d\u7ed9\u7b2c\u4e09\u4e2a\u4eba\u53d1\u4e00\u5f20\uff0c\u6700\u540e\u7ed9\u7b2c\u56db\u4e2a\u4eba\u53d1\u4e00\u5f20\uff0c\u7136\u540e\u7ee7\u7eed\u518d\u7ed9\u7b2c\u4e00\u4e2a\u4eba\u53d1\u4e00\u5f20\uff0c\u5982\u6b64\u5f80\u590d\uff0c\u76f4\u5230\u6bcf\u4e2a\u4eba\u624b\u91cc\u90fd\u6709 32 \u5f20\u724c\u4e86\uff0c\u8fd9\u5c31\u662f\u4e00\u7ec4\uff0c\u6b64\u65f6\u6bcf\u4e2a\u4eba\u624b\u91cc\u7684 32 \u5f20\u724c\u5728 Z \u5e8f\u4e0a\u4e0d\u662f\u76f8\u90bb\u7684\uff0c\u662f\u9694\u4e86 3 \u4e2a\u4f4d\u7f6e\u7684\uff0c\u76f8\u5f53\u4e8e\u539f\u6765\u53ea\u80fd\u770b\u5230 32 \u4e2a\u70b9\u8303\u56f4\uff0c\u73b0\u5728\u80fd\u770b\u5230 32\u00d74 = 128 \u4e2a\u70b9\u8303\u56f4\uff0c\u6bcf\u4e2a\u4eba 32 \u5f20\u724c\u662f\u4e00\u7ec4\uff0c\u7136\u540e\u63a5\u7740\u53d1\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u6bcf\u4e2a\u4eba\u624b\u91cc\u724c\u4e00\u6837\u591a\uff0c\u7ec4\u6570\u4e00\u81f4\uff0c\u56e0\u6b64\u5fc5\u987b\u8981\u7ed9\u5e8f\u5217\u586b\u5145\u8865\u96f6\uff0c\u4f7f\u5f97 \\(\\hat{N}\\) \u80fd\u88ab \\(K\\times D=32\u00d74=128\\) \u6574\u9664\u3002\u5177\u4f53\u5b9e\u73b0\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <p>\u6269\u5f20\u5212\u5206 (Dilated Partition):</p> <ul> <li>Reshape: \u53d8\u4e3a \\((B', K, D, C)\\)\uff0c\u5373 \\((B', 32, 4, C)\\)\u3002</li> <li>Transpose (\u8f6c\u7f6e): \u4ea4\u6362\u7ef4\u5ea6\u53d8\u4e3a \\((B', D, K, C) \\to (B', 4, 32, C)\\)\u3002</li> <li>Flatten: \u5408\u5e76\u524d\u4e24\u7ef4 \\(\\to (B' \\times 4, 32, C)\\) 13\u3002</li> </ul> <p>\u89e3\u91ca: \u8fd9\u76f8\u5f53\u4e8e\u628a\u539f\u672c\u8fde\u7eed\u7684\u5e8f\u5217\uff0c\u6309\u95f4\u9694 4 \u62bd\u53d6\u70b9\u7ec4\u6210\u65b0\u7a97\u53e3\u3002</p> <p>\u5212\u5206\u597d\u7a97\u53e3\u540e\uff0c\u548c\u4e4b\u524d\u4e00\u6837\uff0c\u4ee5\u7ec4\u4e3a\u57fa\u672c\u5355\u4f4d concat \u8d77\u6765\u5e76\u884c\u6267\u884c attention\uff0c\u7136\u540e\u9006\u5411\u6267\u884c\u6269\u5f20\u5212\u5206\u6b65\u9aa4\uff0c\u6062\u590d \\((N,C)\\)</p>"},{"location":"models/octfomer/#downsampling","title":"Downsampling","text":"<p>\u8bba\u6587\u4e2d\u4f7f\u7528\u7684\u4e0b\u91c7\u6837\u6a21\u5757\u6bd4\u8f83\u7b80\u5355\uff0c\u6ca1\u6709\u4f7f\u7528 Max Pooling \u6216 Average Pooling \u8fd9\u6837\u7684\u6c60\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u76f4\u63a5\u4f7f\u7528\u6b65\u957f\u4e3a 2 \u7684\u516b\u53c9\u6811\u5377\u79ef\u6765\u5b9e\u73b0\u7684\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u4f7f\u7528\u7684\u5377\u79ef\u6838\u5927\u5c0f\u4e3a 2\uff0c\u6b65\u957f\u4e3a 2\uff08\u5b9e\u73b0\u957f\u5ea6\u51cf\u534a\uff09\uff0c\u4f46\u662f\u901a\u9053\u6570\u91cf\u52a0\u500d\uff08\u5377\u79ef\u6838\u6570\u91cf\u8bbe\u7f6e\u4e3a \\(2C\\) \u5373\u53ef\uff09\uff0c\u5377\u79ef\u64cd\u4f5c\u4e4b\u540e\u7d27\u8ddf\u4e00\u4e2a Batch Normalzation\uff08\u6279\u91cf\u5f52\u4e00\u5316\u5c42\uff09\u3002</p>"},{"location":"models/swin3d/","title":"Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding","text":""},{"location":"models/swin3d/#swin3d-a-pretrained-transformer-backbone-for-3d-indoor-scene-understanding","title":"Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding","text":"<p>\u8bba\u6587\u6838\u5fc3\u662f\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e94\u7528\u5728 3D \u70b9\u4e91\u9886\u57df\u7684\u9884\u8bad\u7ec3 Backbone\uff0c\u5c06\u539f\u5148\u5e94\u7528\u5728 2D \u56fe\u50cf\u9886\u57df\u7684 Swin Transformer \u9002\u914d\u5230\u4e86 3D \u70b9\u4e91\uff0c\u4f46\u662f\u76f4\u63a5\u6269\u5c55\u4f1a\u6709\u5185\u5b58\u8017\u8d39\u5927\uff0c\u6548\u679c\u5e76\u4e0d\u591f\u597d\u7684\u95ee\u9898\uff0c\u8bba\u6587\u4e2d\u901a\u8fc7\u4f18\u5316\u6ce8\u610f\u529b\u7684\u5185\u5b58\u5360\u7528\u5230\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u4ee5\u53ca\u70b9\u4e91\u4f4d\u7f6e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u70b9\u53ef\u80fd\u5728\u5176\u5360\u636e\u7684\u4f53\u7d20\u5185\u7684\u4efb\u610f\u4f4d\u7f6e\u90fd\u6709\u53ef\u80fd\uff1b</p> <p>Swin3D \u7684\u6838\u5fc3\u4ecd\u7136\u662f\u7a97\u53e3\u6ce8\u610f\u529b\uff0c\u501f\u9274\u4e86 2D Swin Transformer \u7684\u8bbe\u8ba1\u7406\u5ff5\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u548c\u79fb\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u673a\u5236\u6765\u9ad8\u6548\u5904\u7406 3D \u70b9\u4e91\u6570\u636e</p> <p>Swin3D \u7684\u6574\u4f53\u67b6\u6784\u5206\u4e3a 5 \u4e2a\u9636\u6bb5\uff08Stages\uff09\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u5c42\u7ea7\u5f0f\u7684\u7279\u5f81\u63d0\u53d6\u5668\u3002</p> <ul> <li>\u8f93\u5165\u6570\u636e\uff1a\u539f\u59cb 3D \u70b9\u4e91\uff0c\u5305\u542b\u70b9\u7684\u4f4d\u7f6e P \u548c\u5176\u4ed6\u4fe1\u53f7\uff08\u5982 RGB \u989c\u8272\u3001\u6cd5\u5411\u91cf\u7b49\uff09\uff0c\u8868\u793a\u4e3a \\(s_p \\in \\mathbb{R}^m\\)\uff1b\u5bf9\u4e8e\u989c\u8272\u3001\u6cd5\u5411\u91cf\u7b49\u6210\u5206\uff0c\u90fd\u8981\u5f52\u4e00\u5316\u5230 \\([-1,1]\\)\uff0c\u5e38\u7528\u8bbe\u7f6e\u4e3a m = 6\uff0c\u5305\u542b 3D \u70b9\u5750\u6807\u548c RGB \u989c\u8272\u5206\u91cf\uff1b</li> <li>\u6838\u5fc3\u6d41\u7a0b\uff1a<code>Voxelization</code> \\(\\to\\) <code>Stage-1</code> \\(\\to\\) <code>Downsample</code> \\(\\to\\) <code>Stage-2</code> ... \\(\\to\\) <code>Stage-5</code>\u3002</li> <li>\u8f93\u51fa\uff1a\u591a\u5c3a\u5ea6 \u7684\u4f53\u7d20\u7279\u5f81\uff0c\u53ef\u7528\u4e8e\u4e0b\u6e38\u7684\u5206\u5272\u6216\u68c0\u6d4b\u4efb\u52a1 \u3002</li> </ul> <p></p>Figure 1: Swin3D \u6574\u4f53\u7f51\u7edc\u67b6\u6784\u56fe<p></p>"},{"location":"models/swin3d/#voxelization","title":"Voxelization","text":"<p>\u4f53\u7d20\u5316\u6a21\u5757\uff0c\u8bba\u6587\u4e2d\u4f7f\u7528\u7a00\u758f\u4f53\u7d20\u6765\u8868\u793a\u70b9\uff0c\u5982\u56fe 1 \u6240\u793a\uff0c\u6839\u636e\u8f93\u5165\u70b9\u4e91\uff0c\u521b\u5efa\u4e86 5 \u4e2a\u4e0d\u540c\u5c42\u7ea7\u7684\u7a00\u758f\u5316\u4f53\u7d20\u7f51\u683c\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5bf9\u4e8e\u5ba4\u5185\u573a\u666f\uff0c\u5212\u5206\u6700\u7ec6\u7684\u7f51\u683c\u662f 2cm\uff0c\u7136\u540e\u6bcf\u63d0\u9ad8\u4e00\u7ea7\uff0c\u7f51\u683c\u5c3a\u5bf8\u589e\u52a0\u4e00\u500d\uff1b</p> <p>\u70b9\u4fe1\u606f\u4ee5\u4ece\u6700\u7cbe\u7ec6\u7684\u7ea7\u522b\u5230\u6700\u7c97\u7565\u7ea7\u522b\u7684\u5982\u4e0b\u65b9\u5f0f\u5b58\u50a8\u5728\u4f53\u7d20\u4e2d</p> <ul> <li>\u5bf9\u4e8e\u6700\u7cbe\u7ec6\u7684\u4f53\u7d20\u7f51\u683c \\(v\\)\uff0c\u8bba\u6587\u4ece\u8fd9\u4e2a\u4f53\u7d20\u7f51\u683c\u4e2d\u968f\u673a\u6311\u9009\u4e00\u4e2a\u70b9\u4ee3\u8868\u8fd9\u4e2a\u4f53\u7d20\uff0c\u8bb0\u4e3a \\(r_v\\)\uff1b</li> <li>\u540e\u7eed\u5c42\u7ea7\uff08l+1\uff09\u4e2d\uff0c\u540e\u7eed\u5c42\u7ea7\u4f53\u7d20\u90fd\u6bd4\u6700\u7cbe\u7ec6\u7684\u4f53\u7d20\u7f51\u683c\u8981\u5927\uff0c\u4e00\u4e2a\u4f53\u7d20\u76f8\u5f53\u4e8e\u4e4b\u524d\u56db\u4e2a\u4f53\u7d20\uff0c\u8fd9\u65f6\u4ece\u5b50\u4f53\u7d20\u7684\u4ee3\u8868\u70b9\u4e2d\u9009\u62e9\u6700\u63a5\u8fd1\u51e0\u4f55\u4e2d\u5fc3\u7684\u70b9\uff1b</li> <li>\u8fd9\u4e00\u6b65\u5c06\u65e0\u5e8f\u7684\u70b9\u4e91\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u7a00\u758f\u4f53\u7d20\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u70b9\u7684\u539f\u59cb\u4fe1\u53f7 \\(s_v\\) \u3002</li> </ul>"},{"location":"models/swin3d/#initial-feature-embedding","title":"Initial Feature Embedding","text":"<p>\u8bba\u6587\u4e2d\u63d0\u5230\uff0c\u53c2\u8003 Stratified transformer for 3D point cloud segmentation.\u53d1\u73b0\u7684\uff0c\u76f4\u63a5\u4f7f\u7528\u7ebf\u6027\u5c42\u6216 MLP \u5c06\u539f\u59cb\u7279\u5f81\u6295\u5f71\u5230\u9ad8\u7ef4\u7a7a\u95f4\u5bf9\u4e8e Swin \u7cfb\u5217\u7684 transformer \u67b6\u6784\u65e0\u6cd5\u4ea7\u751f\u6bd4\u8f83\u597d\u7684\u6548\u679c\uff0c\u56e0\u6b64\u8bba\u6587\u4e2d\u63d0\u51fa\u4f7f\u7528\u4e00\u4e2a <code>3*3*3</code> \u7684\u5377\u79ef\u6838\u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884c\u7a00\u758f\u5377\u79ef\uff08\u901a\u8fc7\u54c8\u5e0c\u8868\u5b58\u50a8\u975e\u7a7a\u4f53\u7d20\u7d22\u5f15\uff0c\u907f\u514d\u5927\u91cf\u7a7a\u4f53\u7d20\u7684\u65e0\u6548\u8ba1\u7b97\uff09\uff0c\u4ee5\u53ca BN \u6279\u91cf\u5f52\u4e00\u5316\u548c ReLU \u6fc0\u6d3b\u5c42\uff0c\u5c06\u8f93\u5165\u4f53\u7d20\u7279\u5f81\u53d8\u6362\u5230 \\(\\mathbb{R}^{C_1}\\)</p> <p>\u8f93\u5165\u7279\u5f81\u7531\u4f53\u7d20 \\(v\\) \u7684\u4ee3\u8868\u70b9\u5750\u6807\u548c\u4f53\u7d20\u4e2d\u5fc3\u5750\u6807\u4e4b\u5dee\uff08\\(r_v-c_v\\)\uff09\u548c\u5176\u4ed6\u4ee3\u8868\u70b9\u7279\u5f81\uff08\u5982 RGB\u3001\u6cd5\u5411\u91cf\u7b49\uff09\uff0c\u76f8\u8f83\u4e8e Stratified transformer for 3D point cloud segmentation \u4e2d\u4f7f\u7528\u7684 KPConv\uff0c\u8bba\u6587\u4e2d\u63d0\u51fa\u7684 initial feature embedding \u66f4\u8f7b\u91cf\uff1b</p> <p>\u6574\u7406\u5982\u4e0b\uff1a</p> <ul> <li>\u8f93\u5165\uff1a\u4f53\u7d20 \\(v\\) \u7684\u539f\u59cb\u7279\u5f81\u3002\u8fd9\u91cc\u7684\u8f93\u5165\u7279\u5f81\u662f\u7531\u201c\u4f4d\u7f6e\u504f\u79fb\u91cf\u201d\uff08\\(r_v - c_v\\)\uff0c\u5373\u4ee3\u8868\u70b9\u5750\u6807\u51cf\u53bb\u4f53\u7d20\u4e2d\u5fc3\u5750\u6807\uff09\u548c\u5176\u4ed6\u4fe1\u53f7\uff08\u5982\u989c\u8272\uff09\u62fc\u63a5\u800c\u6210\u3002</li> <li>\u64cd\u4f5c\uff1a\u4f7f\u7528\u4e00\u5c42 \\(3 \\times 3 \\times 3\\) \u7684 \u7a00\u758f\u5377\u79ef (Sparse Convolution)\uff0c\u901a\u8fc7 Batch Normalization (BN) \u548c ReLU \u6fc0\u6d3b\u51fd\u6570\u3002</li> <li>\u76ee\u7684\uff1a\u5c06\u4f4e\u7ef4\u7684\u539f\u59cb\u4fe1\u53f7\u6295\u5f71\u5230\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4 \\(\\mathbb{R}^{C_1}\\)\u3002</li> </ul>"},{"location":"models/swin3d/#contextual-relative-signal-encodingcrse","title":"Contextual relative signal encoding\uff08cRSE\uff09","text":"<p>\u4e0a\u4e0b\u6587\u76f8\u5bf9\u4fe1\u53f7\u7f16\u7801\uff0c\u672c\u8d28\u662f\u5bf9 Swin Transformer \u4e2d\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u4e00\u79cd\u5e7f\u4e49\u5316\u589e\u5f3a</p>"},{"location":"models/swin3d/#1-crse","title":"1\u3001\u4e3a\u4ec0\u4e48\u8981\u6709 cRSE\uff1f","text":"<p>\u5728\u6807\u51c6\u7684 2D Swin Transformer \u4e2d\uff0c\u50cf\u7d20\u662f\u6392\u5217\u5728\u89c4\u5219\u7f51\u683c\u4e0a\u7684\uff0c\u76f8\u5bf9\u4f4d\u7f6e\u662f\u56fa\u5b9a\u7684\u3002\u4f46\u5728 3D \u70b9\u4e91\u4e2d\uff0cSwin3D \u9762\u4e34\u4e24\u4e2a\u7279\u6b8a\u6311\u6218\uff1a</p> <ol> <li>\u4f4d\u7f6e\u4e0d\u89c4\u5219 (Spatial Irregularity)\uff1a\u70b9\u5728\u4f53\u7d20\u5185\u53ef\u4ee5\u662f\u4efb\u610f\u4f4d\u7f6e\uff0c\u4e0d\u4ec5\u4ec5\u662f\u7f51\u683c\u4e2d\u5fc3 1\u3002</li> <li>\u4fe1\u53f7\u4e0d\u89c4\u5219 (Signal Irregularity)\uff1a\u9664\u4e86\u4f4d\u7f6e\uff0c\u70b9\u4e91\u8fd8\u5305\u542b\u989c\u8272\uff08RGB\uff09\u3001\u6cd5\u5411\u91cf\uff08Normal\uff09\u7b49\u4fe1\u53f7\u3002\u5728\u4e00\u4e2a\u7a97\u53e3\u5185\uff0c\u8fd9\u4e9b\u4fe1\u53f7\u7684\u76f8\u5bf9\u53d8\u5316\uff08\u4f8b\u5982\u4e24\u4e2a\u70b9\u989c\u8272\u5dee\u5f02\u5f88\u5927\uff09\u5bf9\u4e8e\u7406\u89e3\u573a\u666f\u975e\u5e38\u91cd\u8981\u3002</li> </ol> <p>\u539f\u7406\u89e3\u91ca\uff1a\u4f20\u7edf\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u53ea\u544a\u8bc9\u6ce8\u610f\u529b\u673a\u5236\uff1a\u201c\u70b9 A \u548c\u70b9 B \u5728\u7a7a\u95f4\u4e0a\u8ddd\u79bb\u662f\u591a\u5c11\u201d\u3002cRSE (Contextual Relative Signal Encoding) \u5219\u8bd5\u56fe\u544a\u8bc9\u6ce8\u610f\u529b\u673a\u5236\uff1a\u201c\u70b9 A \u548c\u70b9 B \u4e0d\u4ec5\u7a7a\u95f4\u8ddd\u79bb\u662f \\(X\\)\uff0c\u800c\u4e14\u5b83\u4eec\u7684\u989c\u8272\u5dee\u5f02\u662f \\(Y\\)\uff0c\u6cd5\u5411\u91cf\u5dee\u5f02\u662f \\(Z\\)\u3002\u201d</p> <p>\u8fd9\u79cd\u7f16\u7801\u88ab\u79f0\u4e3a\u201cContextual\uff08\u4e0a\u4e0b\u6587\u7684\uff09\u201d\uff0c\u662f\u56e0\u4e3a\u5b83\u4e0d\u4ec5\u4ec5\u52a0\u4e00\u4e2a\u9759\u6001\u7684\u504f\u7f6e\u503c\uff0c\u800c\u662f\u8ba9\u8fd9\u4e2a\u504f\u7f6e\u503c\u4e0e\u5f53\u524d\u7684 Query \u548c Key \u8fdb\u884c\u4ea4\u4e92\uff0c\u4f7f\u5f97\u6ce8\u610f\u529b\u673a\u5236\u80fd\u52a8\u6001\u5730\u6839\u636e\u4fe1\u53f7\u5dee\u5f02\u6765\u8c03\u6574\u5173\u6ce8\u5ea6 \u3002</p>"},{"location":"models/swin3d/#2-crse","title":"2. \u8ba1\u7b97\u8fc7\u7a0b\uff1acRSE \u662f\u5982\u4f55\u8fd0\u4f5c\u7684\uff1f","text":"<p>cRSE \u7684\u8ba1\u7b97\u8fc7\u7a0b\u53ef\u4ee5\u5206\u4e3a\u4e09\u4e2a\u6b65\u9aa4\uff1a\u4fe1\u53f7\u5dee\u5206\u3001\u91cf\u5316\u4e0e\u67e5\u8868\u3001\u878d\u5165\u6ce8\u610f\u529b\u673a\u5236\u3002</p>"},{"location":"models/swin3d/#delta-s_ij","title":"\u7b2c\u4e00\u6b65\uff1a\u8ba1\u7b97\u4fe1\u53f7\u5dee\u5f02 (\\(\\Delta s_{ij}\\))","text":"<p>\u5bf9\u4e8e\u7a97\u53e3\u5185\u7684\u4efb\u610f\u4e24\u4e2a\u4f53\u7d20 \\(i\\) \u548c \\(j\\)\uff0c\u9996\u5148\u8ba1\u7b97\u5b83\u4eec\u539f\u59cb\u4fe1\u53f7\u7684\u5dee\u5f02\u3002</p> \\[ \\Delta s_{ij} = s_{v_i} - s_{v_j} \\] <p>\u8fd9\u91cc\u7684\u4fe1\u53f7 \\(s\\) \u662f\u4e00\u4e2a\u590d\u5408\u5411\u91cf\uff0c\u901a\u5e38\u5305\u542b\uff1a</p> <ul> <li>\u4f4d\u7f6e\uff1a\\(x, y, z\\)</li> <li>\u989c\u8272\uff1a\\(r, g, b\\)</li> <li>\u6cd5\u5411\u91cf\uff1a\\(n_x, n_y, n_z\\)\uff0c\u8fd9\u610f\u5473\u7740 cRSE \u4e0d\u4ec5\u7f16\u7801\u4f4d\u7f6e\u5dee\uff0c\u4e5f\u7f16\u7801\u989c\u8272\u5dee\u548c\u6cd5\u5411\u91cf\u5dee\u3002</li> </ul>"},{"location":"models/swin3d/#quantization-look-up-table","title":"\u7b2c\u4e8c\u6b65\uff1a\u91cf\u5316\u4e0e\u67e5\u8868 (Quantization &amp; Look-up Table)","text":"<p>\u7531\u4e8e \\(\\Delta s_{ij}\\) \u662f\u8fde\u7eed\u7684\u6d6e\u70b9\u6570\uff0c\u65e0\u6cd5\u76f4\u63a5\u4f5c\u4e3a\u7d22\u5f15\u53bb\u67e5\u627e\u53c2\u6570\u3002\u56e0\u6b64\u9700\u8981\u5c06\u5176 \u91cf\u5316 \u4e3a\u6574\u6570\u7d22\u5f15\uff0c\u7136\u540e\u53bb\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684 \u67e5\u627e\u8868 (Look-up Table, LUT) \u4e2d\u53d6\u503c\u3002</p> <ol> <li>\u91cf\u5316\u516c\u5f0f \uff1a\u5bf9\u4e8e\u4fe1\u53f7\u7684\u7b2c \\(l\\) \u4e2a\u5206\u91cf\uff08\u4f8b\u5982\u7ea2\u8272\u5206\u91cf R\uff09\uff0c\u8ba1\u7b97\u7d22\u5f15 \\(I_l\\)\uff1a</li> <li> \\[ I_l(\\Delta) = \\left\\lfloor \\frac{(\\Delta [l] - min_{val}) \\times L}{\\text{range}} \\right\\rfloor \\] <ul> <li>\\(min_{val}\\) \u548c \\(\\text{range}\\) \u662f\u9884\u5b9a\u4e49\u7684\u8303\u56f4\uff08\u4f8b\u5982 RGB \u989c\u8272\u8303\u56f4\u662f \\([-1, 1]\\)\uff09\u3002</li> <li>\\(L\\) \u662f\u8868\u7684\u5927\u5c0f\uff08\u4f8b\u5982\u989c\u8272\u548c\u6cd5\u5411\u91cf\u8bbe\u4e3a 16\uff0c\u4f4d\u7f6e\u8bbe\u4e3a 4\uff09\u3002</li> </ul> </li> <li> <p>\u67e5\u8868\u6620\u5c04 \uff1a\u901a\u8fc7\u7d22\u5f15 \\(I_l\\)\uff0c\u4ece\u53ef\u5b66\u4e60\u7684\u8868 \\(t^Q, t^K, t^V\\) \u4e2d\u53d6\u51fa\u5bf9\u5e94\u7684\u5411\u91cf\u3002</p> </li> <li> \\[ t_{Q, h}(\\Delta) = \\sum_{l = 1}^{m} t_{l, h}^Q [I_l(\\Delta)] \\] <p>\u8fd9\u610f\u5473\u7740\u5c06\u4f4d\u7f6e\u5dee\u3001\u989c\u8272\u5dee\u3001\u6cd5\u5411\u91cf\u5dee\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\u76f8\u52a0\uff0c\u5f97\u5230\u4e00\u4e2a\u7efc\u5408\u7684\u4fe1\u53f7\u5dee\u5f02\u7f16\u7801\u3002</p> </li> </ol>"},{"location":"models/swin3d/#integration","title":"\u7b2c\u4e09\u6b65\uff1a\u878d\u5165\u6ce8\u610f\u529b\u8ba1\u7b97 (Integration)","text":"<p>\u8fd9\u662f\u6700\u5173\u952e\u7684\u4e00\u6b65\u3002cRSE \u4e0d\u4ec5\u4ec5\u662f\u7ed9 Attention Score \u52a0\u4e00\u4e2a\u6807\u91cf \\(b\\)\uff0c\u5b83\u662f\u5c06\u4fe1\u53f7\u5dee\u5f02\u7f16\u7801\u6295\u5f71\u540e\uff0c\u5206\u522b\u4e0e Query \u548c Key \u8fdb\u884c\u4ea4\u4e92\u3002</p> <ol> <li>\u4fee\u6539 Attention Score (\\(e_{ij}\\))\uff0c\u539f\u59cb Attention \u662f \\((Q \\cdot K^T) / \\sqrt{d}\\)\u3002\u52a0\u5165 cRSE \u540e\uff0c\u516c\u5f0f\u53d8\u4e3a\uff1a</li> </ol> \\[ e_{ij, h} = \\frac{(f_i W_{Q, h})(f_j W_{K, h})^T + b_{ij, h}}{\\sqrt{d}} \\] <p>\u5176\u4e2d \\(b_{ij,h}\\) \u662f\u4e0a\u4e0b\u6587\u504f\u5dee\u9879\uff1a</p> \\[ b_{ij, h} = \\underbrace{(f_i W_{Q, h}) \\cdot t_{Q, h}(\\Delta s_{ij})}_{\\text{Query \u4e0e\u4fe1\u53f7\u5dee\u7684\u4ea4\u4e92}} + \\underbrace{(f_j W_{K, h}) \\cdot t_{K, h}(\\Delta s_{ij})}_{\\text{Key \u4e0e\u4fe1\u53f7\u5dee\u7684\u4ea4\u4e92}} \\] <ul> <li>\u76f4\u89c2\u7406\u89e3\uff1a\u8fd9\u4f7f\u5f97\u6ce8\u610f\u529b\u5206\u6570\u4e0d\u4ec5\u53d6\u51b3\u4e8e \\(Q\\) \u548c \\(K\\) \u7684\u76f8\u4f3c\u5ea6\uff0c\u8fd8\u53d6\u51b3\u4e8e \\(Q\\) \u5bf9\u201c\u4fe1\u53f7\u5dee\u5f02\u201d\u7684\u654f\u611f\u5ea6\u4ee5\u53ca \\(K\\) \u5bf9\u201c\u4fe1\u53f7\u5dee\u5f02\u201d\u7684\u654f\u611f\u5ea6\u3002</li> <li>\u4fee\u6539 Output Value (\\(f^*\\))</li> </ul> <p>cRSE \u4e0d\u4ec5\u5f71\u54cd\u6743\u91cd\u7684\u8ba1\u7b97\uff0c\u8fd8\u76f4\u63a5\u628a\u4fe1\u53f7\u5dee\u5f02\u4fe1\u606f\u52a0\u5230\u4e86 Value (\\(V\\)) \u4e0a 10\uff1a</p> \\[ f_{i, h}^* = \\frac{\\sum_{j} \\exp(e_{ij, h}) (f_j W_{V, h} + t_{V, h}(\\Delta s_{ij}))}{\\sum_{j} \\exp(e_{ij, h})} \\] <ul> <li>\u8fd9\u91cc \\(t_{V,h}(\\Delta s_{ij})\\) \u88ab\u76f4\u63a5\u52a0\u5230\u4e86 \\(V\\) \u7279\u5f81\u4e0a\u3002\u8fd9\u610f\u5473\u7740\u5982\u679c\u4e24\u4e2a\u70b9\u7684\u989c\u8272\u5dee\u5f02\u5f88\u5927\uff0c\u8fd9\u4e2a\u5dee\u5f02\u672c\u8eab\u4e5f\u4f1a\u88ab\u4f5c\u4e3a\u7279\u5f81\u4f20\u9012\u5230\u4e0b\u4e00\u5c42\u3002</li> </ul>"},{"location":"models/swin3d/#_1","title":"\u603b\u7ed3","text":"<p>cRSE \u7684\u672c\u8d28 \u662f\u5c06 [\u4f4d\u7f6e\u5dee, \u989c\u8272\u5dee, \u6cd5\u5411\u91cf\u5dee] \u8fd9\u4e00\u7269\u7406\u4e16\u754c\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u901a\u8fc7 \u91cf\u5316\u67e5\u8868 \u7684\u65b9\u5f0f\u53d8\u6210\u53ef\u5b66\u4e60\u7684\u5411\u91cf\uff0c\u5e76\u5f3a\u884c\u6ce8\u5165\u5230 Transformer \u7684 Query-Key \u5339\u914d\u8fc7\u7a0b \u4ee5\u53ca Value \u805a\u5408\u8fc7\u7a0b \u4e2d\u3002</p> <p>\u8fd9\u4f7f\u5f97 Swin3D \u80fd\u591f\u7406\u89e3\uff1a\u201c\u867d\u7136\u8fd9\u4e2a\u70b9\u5728\u7a7a\u95f4\u4e0a\u5f88\u8fd1\uff0c\u4f46\u989c\u8272\u5b8c\u5168\u4e0d\u540c\uff08\u53ef\u80fd\u662f\u8fb9\u754c\uff09\uff0c\u6240\u4ee5\u6211\u5e94\u8be5\u51cf\u5c11\u5bf9\u5b83\u7684\u6ce8\u610f\u529b\uff08\u964d\u4f4e \\(e_{ij}\\)\uff09\u201d\u3002</p>"},{"location":"models/swin3d/#w-msa3d-and-sw-msa3d","title":"W-MSA3D and SW-MSA3D","text":"<p>Swin3D \u4e2d\u7684 Transformer Block\uff0cS-MSA3D \u7528\u4e8e\u89c4\u5219\u7a97\u53e3\uff0cSW-MSA3D \u7528\u4e8e\u504f\u79fb\u7a97\u53e3\uff0c</p> <p>S-MSA3D (\u89c4\u5219\u7a97\u53e3)\uff1a</p> <ul> <li>\u5207\u5206\u65b9\u5f0f\uff1a\u89c4\u5219\u7a97\u53e3\u4ece\u4ece\u5750\u6807\u539f\u70b9 \\((0,0,0)\\) \u5f00\u59cb\uff0c\u6309\u7167\u56fa\u5b9a\u7684\u7a97\u53e3\u5927\u5c0f \\(M \\times M \\times M\\) \u628a\u6574\u4e2a\u70b9\u4e91\u4f53\u7d20\u7f51\u683c\u5207\u6210\u6574\u9f50\u7684\u5c0f\u65b9\u5757 \uff1b</li> <li>\u5c40\u9650\u6027\uff1a\u81ea\u6ce8\u610f\u529b\u8ba1\u7b97\u88ab\u9650\u5236\u5728\u6bcf\u4e2a \\(M \\times M \\times M\\) \u7684\u5c0f\u65b9\u5757\u5185\u90e8\u3002\u4e0d\u540c\u65b9\u5757\u4e4b\u95f4\u7684\u4f53\u7d20\u65e0\u6cd5\u8fdb\u884c\u4ea4\u4e92\u3002\u5982\u679c\u6ca1\u6709\u540e\u7eed\u6b65\u9aa4\uff0c\u6574\u4e2a\u7f51\u7edc\u5c31\u4f1a\u53d8\u6210\u4e00\u4e2a\u4e2a\u5b64\u7acb\u7684\u201c\u5b64\u5c9b\u201d\uff0c\u4e22\u5931\u5168\u5c40\u4fe1\u606f\u3002</li> </ul> <p>SW-MSA3D (\u79fb\u4f4d\u7a97\u53e3)</p> <ul> <li>\u5207\u5206\u65b9\u5f0f\uff1a\u5728 S-MSA3D \u7684\u57fa\u7840\u4e0a\uff0c\u5c06\u5207\u5206\u7f51\u683c\u5411\u53f3\u3001\u4e0b\u3001\u540e\u65b9\u79fb\u52a8\u3002</li> <li>\u79fb\u52a8\u504f\u79fb\u91cf\uff1a\u504f\u79fb\u91cf\u901a\u5e38\u662f\u7a97\u53e3\u5927\u5c0f\u7684\u4e00\u534a\uff0c\u5373 \\((\\lfloor \\frac{M}{2} \\rfloor, \\lfloor \\frac{M}{2} \\rfloor, \\lfloor \\frac{M}{2} \\rfloor)\\) 6\u3002</li> <li>\u76ee\u7684\uff1a\u6253\u7834\u201c\u5b64\u5c9b\u201d\u3002\u901a\u8fc7\u79fb\u52a8\u7a97\u53e3\uff0c\u539f\u6765\u7684\u8fb9\u754c\u53d8\u6210\u4e86\u65b0\u7a97\u53e3\u7684\u4e2d\u5fc3\u3002\u8fd9\u6837\uff0c\u539f\u672c\u5728 S-MSA3D \u4e2d\u5c5e\u4e8e\u4e24\u4e2a\u4e0d\u540c\u7a97\u53e3\u7684\u76f8\u90bb\u4f53\u7d20\uff0c\u5728 SW-MSA3D \u4e2d\u5c31\u4f1a\u88ab\u5305\u542b\u5728\u540c\u4e00\u4e2a\u7a97\u53e3\u5185\u8fdb\u884c\u4ea4\u4e92\u3002</li> </ul>"},{"location":"models/swin3d/#downsample","title":"Downsample","text":"<p>\\(l\\) \u5c42\u7684\u4f53\u7d20\u5982\u4f55\u901a\u8fc7\u4e0b\u91c7\u6837\u53d8\u6210 \\(l+1\\) \u5c42\u7684\u4f53\u7d20\u5462\uff1f\\(l+1\\) \u5c42\u662f\u5728\u539f\u59cb\u70b9\u4e91\u4e2d\u91c7\u7528 \\(l\\) \u5c42\u53cc\u500d\u7684\u7f51\u683c\u5927\u5c0f\u5212\u5206\u7684\u4f53\u7d20\uff0c\\(l\\) \u5c42\u4f53\u7d20\u4e2d\u6bcf\u4e2a\u4f53\u7d20\u7684\u7279\u8bca\u8868\u793a\u7ecf\u8fc7 <code>LayerNorm+Linear Layer</code>\uff0c\u5c06\u7279\u5f81\u7ef4\u5ea6\u4ece \\(C_l\\) \u63d0\u5347\u5230 \\(C_{l+1}\\)\uff0c\u8fd9\u662f\u5728 l \u5c42\u7684\u4f53\u7d20\u6570\u91cf\u662f\u64cd\u4f5c\u7684\uff1b\u7136\u540e\u662f KNNPooling\uff0c\u8fd9\u662f\u9488\u5bf9\u7a00\u758f\u6570\u636e\u7684\u7279\u6b8a\u6c60\u5316\u3002\u5bf9\u4e8e\u4e0b\u4e00\u5c42\uff08\\(l+1\\) \u5c42\uff09\u7684\u6bcf\u4e2a\u4f53\u7d20\uff0c\u5728\u4e0a\u4e00\u5c42\uff08\\(l\\) \u5c42\uff09\u4e2d\u627e\u5230\u5176 K \u4e2a\u6700\u8fd1\u90bb (K-Nearest Neighbors) \u4f53\u7d20\uff0c\u7136\u540e\u6267\u884c \u6700\u5927\u6c60\u5316 (Max Pooling) 21\u3002\u9ed8\u8ba4 \\(k=16\\)\u3002</p>"},{"location":"models/swin3d/#pointcept","title":"\u5728pointcept\u4e2d\u590d\u73b0\u6559\u7a0b","text":""},{"location":"models/swin3d/#1","title":"1\u3001\u521b\u5efa\u81ea\u5df1\u7684\u6570\u636e\u96c6\u8bfb\u53d6\u5668","text":"<p>\u5728<code>pointcept/datasets</code>\u4e0b\u65b0\u5efa\u4e00\u4e2a<code>keypoint_dataset.py</code>\uff0c\u5728\u91cc\u9762\u521b\u5efa\u4e00\u4e2apytorch\u98ce\u683c\u7684\u6570\u636e\u52a0\u8f7d\u5668\uff0c\u5177\u4f53\u4ee3\u7801\u5982\u4e0b\uff1a</p> Note <pre><code>import os\nimport glob\nfrom typing import Any\nfrom typing import Any\nfrom typing import Any\nfrom typing import Any\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\nfrom .builder import DATASETS\nfrom .transform import Compose, TRANSFORMS\n\n@DATASETS.register_module()\nclass KeypointDataset(Dataset):\n    def __init__(self,\n                split='train',\n                data_root='data',\n                transform=None,\n                test_mode=False,\n                loop=1):\n        super().__init__()\n        self.data_root = data_root\n        self.split = split\n        # \u52a0\u8f7d\u8f6c\u6362\u6d41\u6c34\u7ebf (GridSample, ToTensor \u7b49)\n        self.transform = Compose(transform)\n        self.test_mode = test_mode\n        self.loop = loop if not test_mode else 1\n\n        # \u626b\u63cf\u6587\u4ef6\n        self.data_list = self._get_file_list()\n        print(f\"[{self.split}] Loaded {len(self.data_list)} samples from {self.data_root}\")\n\n    def _get_file_list(self):\n        split_path = os.path.join(self.data_root, self.split)\n        if not os.path.exists(split_path):\n            raise ValueError(f\"Data path does not exist: {split_path}\")\n\n        # \u5339\u914d\u7279\u5f81\u6587\u4ef6: *d_pc_clipped.npy\n        feature_files = glob.glob(os.path.join(split_path, \"*_d_pc_clipped.npy\"))\n        data_list = []\n\n        for feat_path in feature_files:\n            filename = os.path.basename(feat_path)\n            # \u89e3\u6790\u6587\u4ef6\u540d: dev_2_005J_20251102_110034_430_d_pc_clipped.npy\n            # parts: ['dev', '2', '005J', '20251102', '110034', '430', ...]\n            parts = filename.split('_')\n\n            # \u63d0\u53d6\u65f6\u95f4\u6233 (\u6839\u636e\u4f60\u7684\u793a\u4f8b\u662f\u7b2c3,4,5\u4e2a\u90e8\u5206)\n            # \u8bf7\u6839\u636e\u5b9e\u9645\u6587\u4ef6\u540d\u8c03\u6574\u8fd9\u91cc\u7684\u7d22\u5f15\n            try:\n                timestamp = f\"{parts[3]}_{parts[4]}_{parts[5]}\"\n            except IndexError:\n                print(f\"Skipping invalid filename: {filename}\")\n                continue\n\n            label_filename = f\"\u5173\u952e\u70b9\u5750\u6807_{timestamp}.npy\"\n            label_path = os.path.join(split_path, label_filename)\n\n            if os.path.exists(label_path):\n                data_list.append({\n                    \"feat_path\": feat_path,\n                    \"label_path\": label_path,\n                    \"name\": filename\n                })\n\n        return data_list\n\n    def __len__(self):\n        return len(self.data_list) * self.loop\n\n    def __getitem__(self, idx):\n        idx = idx % len(self.data_list)\n        info = self.data_list[idx]\n\n        # 1. \u52a0\u8f7d\u6570\u636e\n        raw_data = np.load(info[\"feat_path\"]).astype(np.float32)\n        coord = raw_data[:, 0:3]\n        feat = raw_data[:, 3:]\n        target = np.load(info[\"label_path\"]).astype(np.float32)\n\n        # \u63d0\u53d6\u7ed9 Swin3D \u505a\u4f4d\u7f6e\u7f16\u7801\u8f85\u52a9\u7684\u7279\u5f81 (coord_feat)\n        # Swin3D \u9700\u8981\u8fd9\u4e2a\u952e\u3002\u65e2\u7136\u6ca1\u6709 RGB\uff0c\u5c31\u7528 \"\u6cd5\u5411\u91cf\" (\u7b2c3,4,5\u5217) \u4ee3\u66ff\n        # \u7ef4\u5ea6: (N, 3)\n        coord_feat = raw_data[:, 3:6]\n\n        # ================= [\u65b0\u589e] \u6570\u636e\u5b89\u5168\u68c0\u67e5 =================\n        # \u68c0\u67e5\u662f\u5426\u6709 NaN \u6216 Inf\n        if np.isnan(coord).any() or np.isinf(coord).any():\n            print(f\"\u26a0\ufe0f Warning: Found NaN/Inf in {info['name']}, replacing with 0.\")\n            coord = np.nan_to_num(coord) # \u5c06 NaN \u66ff\u6362\u4e3a 0\n\n        if np.isnan(target).any() or np.isinf(target).any():\n            print(f\"\u26a0\ufe0f Warning: Found NaN/Inf in target of {info['name']}, replacing with 0.\")\n            target = np.nan_to_num(target)\n        # =====================================================\n\n        # 2. \u53bb\u4e2d\u5fc3\u5316\n        centroid = np.mean(coord, axis=0)\n        coord -= centroid\n        target -= centroid\n\n        # 3. \u5f52\u4e00\u5316\n        # \u589e\u52a0 eps \u9632\u6b62\u9664\u4ee5 0 \u7684\u9690\u60a3\n        dist = np.sqrt(np.sum(coord ** 2, axis=1))\n        m = np.max(dist) if dist.shape[0] &gt; 0 else 0\n\n        if m &lt; 1e-6:\n            m = 1.0\n\n        m = float(m) \n        # coord = coord / m  &lt;-- \u539f\u4ee3\u7801\n        # target = target / m &lt;-- \u539f\u4ee3\u7801\n\n        # [\u4fee\u6539\u5efa\u8bae] \u9632\u6b62 m \u4e3a 0 (\u867d\u7136\u4f60\u524d\u9762\u5904\u7406\u4e86\uff0c\u4f46\u53cc\u91cd\u4fdd\u9669\u66f4\u597d)\n        scale = np.array(m, dtype=np.float32) \n\n        coord = coord / scale\n        target = target / scale\n\n        # \u6784\u9020\u6570\u636e\u5b57\u5178\n        data_dict = dict(\n            coord=coord,\n            feat=feat,\n            target=target, \n            coord_feat=coord_feat,  # [\u65b0\u589e] Swin3D \u4f4d\u7f6e\u7f16\u7801\u8f85\u52a9\u7279\u5f81\n            name=info[\"name\"],\n            centroid=centroid, \n            scale=scale  # [\u91cd\u70b9] \u8fd9\u91cc\u4f20\u5165 numpy \u6570\u7ec4\uff0c\u65b9\u4fbf DataLoader \u81ea\u52a8\u5806\u53e0\n        )\n\n        # 4. \u5e94\u7528\u53d8\u6362 (GridSample \u7b49)\n        if self.transform is not None:\n            data_dict = self.transform(data_dict)\n\n        return data_dict\n</code></pre> <p>\u4e3b\u8981\u4f5c\u7528\u662f\u4ece\u6570\u636e\u96c6\u8def\u5f84\u4e0b\u8bfb\u53d6\u6570\u636e\u96c6\uff0c\u6839\u636e\u65f6\u95f4\u6233\u6765\u5339\u914d\u6837\u672c\u7279\u5f81\u548c\u6807\u7b7e\uff0c\u5e76\u8fdb\u884c\u9884\u5904\u7406\uff0c\u5305\u62ec\u53bb\u4e2d\u5fc3\u5316\u3001\u5f52\u4e00\u5316\uff0c\u4ee5\u53ca\u6839\u636e\u6a21\u578b\u67b6\u6784\u7279\u70b9\uff0c\u662f\u5426\u8fdb\u884c\u7f51\u683c\u5316\u8fd8\u662f\u4e0b\u91c7\u6837\u7b49\u7b49\uff0c\u7136\u540e\u7531\u7edf\u4e00\u7684\u6570\u636e\u751f\u6210\u5668\u6253\u5305\u4e3abatch\uff0c\u4f9b\u540e\u9762\u4f7f\u7528\u3002</p> <p>\u7136\u540e\u5728\u540c\u7ea7\u76ee\u5f55\u4e0b\u7684<code>__init__.py</code>\u4e2d\u6ce8\u518c\u6211\u4eec\u81ea\u5df1\u521b\u5efa\u7684\u81ea\u5df1\u7684\u6570\u636e\u96c6\u52a0\u8f7d\u7c7b\uff0c\u5728\u6587\u4ef6\u672b\u5c3e\u6dfb\u52a0\u4e00\u884c\uff1a</p> Note <pre><code># keypoint\nfrom .keypoint_dataset import KeypointDataset\n</code></pre>"},{"location":"models/swin3d/#2","title":"2\u3001\u521b\u5efa\u6a21\u578b\u914d\u7f6e\u6587\u4ef6","text":"<p>\u5728<code>configs</code>\u4e0b\u65b0\u5efa\u4e00\u4e2a\u6587\u4ef6\u5939<code>my_dataset</code>\uff0c\u7136\u540e\u65b0\u5efa\u4e00\u4e2a<code>keypoint_swin3d.py</code>\uff0c<code>pointcept</code>\u4e2d\u901a\u8fc7py\u6587\u4ef6\u914d\u7f6e\u6a21\u578b\u53c2\u6570\uff0c\u5305\u62ec\u8bad\u7ec3\u7ed3\u679c\u3001\u65e5\u5fd7\u7b49\u7684\u4fdd\u5b58\u8def\u5f84\uff0c\u6a21\u578b\u7f51\u7edc\u7ed3\u6784\u8d85\u53c2\u6570\uff0c\u6570\u636e\u96c6\u8def\u5f84\uff0c\u6570\u636e\u9884\u5904\u7406\u65b9\u5f0f\uff0c\u4ee5\u53ca\u4f18\u5316\u5668\u3001\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u3001\u94a9\u5b50\u51fd\u6570\u7b49\u7b49\uff1b</p> <p><code>keypoint_swin3d.py</code>\u6587\u4ef6\u5185\u5bb9\u5982\u4e0b\uff1a</p> Note <pre><code>_base_ = [\"../_base_/default_runtime.py\"]\n\n# ==============================================================================\n# Global Settings\n# ==============================================================================\nepoch = 100 \nsave_path = \"exp/keypoint_swin3d\"\n# ==============================================================================\n# Model Settings (Swin3D)\n# ==============================================================================\nmodel = dict(\n    type=\"KeypointSwin3D\",\n    num_keypoints=6,\n    backbone_conf=dict(\n        type=\"Swin3D-v1m1\",\n        in_channels=4, # \u6216 4\uff0c\u53d6\u51b3\u4e8e\u4f60\u7684 coord_feat \u903b\u8f91\n        num_classes=64,\n\n        base_grid_size=0.02,\n        quant_size=50,       # \u5fc5\u987b\u662f\u6574\u6570\n        num_layers=4,        # \u5fc5\u987b\u663e\u5f0f\u6307\u5b9a\u4e3a 4\n\n        depths=[2, 2, 6, 2],\n        channels=[64, 128, 256, 512],\n\n        # [\u6838\u5fc3\u4fee\u6539] \u5fc5\u987b\u5168\u4e3a\u5076\u6570\uff01\n        # \u539f\u6765\u662f [3, 6, 12, 24] -&gt; \u6539\u4e3a [6, 12, 24, 48] \u6216\u8005 [4, 8, 16, 32]\n        num_heads=[4, 8, 16, 32], \n\n        window_sizes=[5, 7, 7, 7],\n        up_k=3,\n        drop_path_rate=0.2,\n        stem_transformer=True,\n        down_stride=2,\n        upsample=\"linear\",\n        knn_down=True,\n        cRSE=\"XYZ_RGB\",\n        fp16_mode=1, \n    ),\n\n    hidden_dim=256,\n)\n\n# ==============================================================================\n# Data Settings\n# ==============================================================================\nnum_worker = 4\nbatch_size = 8\ndata_root = \"/home/gzh/point/DataSets\"\ngrid_size_val = 0.02 # \u8fd9\u91cc\u7684 grid_size \u5fc5\u987b\u4e0e\u6a21\u578b\u7684 quant_size/base_grid_size \u5339\u914d\n\ndata = dict(\n    train=dict(\n        type=\"KeypointDataset\",\n        split=\"train\",\n        data_root=data_root,\n        transform=[\n            dict(type=\"Update\", keys_dict=dict(index_valid_keys=[\"coord\", \"feat\", \"coord_feat\"], grid_size=grid_size_val)),\n            dict(type=\"GridSample\", grid_size=grid_size_val, hash_type=\"fnv\", mode=\"train\", return_grid_coord=True),\n            dict(type=\"ToTensor\"),\n            dict(type=\"Collect\", \n                keys=(\"coord\", \"grid_coord\", \"feat\", \"target\",\"coord_feat\", \"grid_size\", \"scale\"), \n                offset_keys_dict=dict(offset=\"coord\"), \n                feat_keys=(\"feat\",),\n                coord_feat_keys=(\"coord_feat\",))\n        ],\n        loop=1,\n    ),\n    val=dict(\n        type=\"KeypointDataset\",\n        split=\"val\",\n        data_root=data_root,\n        transform=[\n            dict(type=\"Update\", keys_dict=dict(index_valid_keys=[\"coord\", \"feat\", \"coord_feat\"], grid_size=grid_size_val)),\n            dict(type=\"GridSample\", grid_size=grid_size_val, hash_type=\"fnv\", mode=\"train\", return_grid_coord=True),\n            dict(type=\"ToTensor\"),\n            dict(type=\"Collect\", \n                keys=(\"coord\", \"grid_coord\", \"feat\", \"target\", \"coord_feat\", \"grid_size\", \"scale\"), \n                offset_keys_dict=dict(offset=\"coord\"), \n                feat_keys=(\"feat\",),\n                coord_feat_keys=(\"coord_feat\",))\n        ],\n    ),\n    test=dict(\n        type=\"KeypointDataset\",\n        split=\"test\",\n        data_root=data_root,\n        transform=[\n            dict(type=\"Update\", keys_dict=dict(index_valid_keys=[\"coord\", \"feat\", \"coord_feat\"], grid_size=grid_size_val)),\n            dict(type=\"GridSample\", grid_size=grid_size_val, hash_type=\"fnv\", mode=\"train\", return_grid_coord=True),\n            dict(type=\"ToTensor\"),\n            dict(type=\"Collect\", \n                keys=(\"coord\", \"grid_coord\", \"feat\", \"target\", \"coord_feat\", \"grid_size\", \"scale\"), \n                offset_keys_dict=dict(offset=\"coord\"), \n                feat_keys=(\"feat\",),\n                coord_feat_keys=(\"coord_feat\",))\n        ],\n    ),\n)\n\n# ==============================================================================\n# Training Settings\n# ==============================================================================\noptimizer = dict(type=\"AdamW\", lr=0.002, weight_decay=0.05)\nscheduler = dict(type=\"CosineAnnealingLR\", eta_min=1e-5) \n\nhooks = [\n    dict(type=\"CheckpointLoader\"),\n    dict(type=\"IterationTimer\", warmup_iter=10),\n    dict(type=\"InformationWriter\"),\n    dict(type=\"KeypointEvaluator\"),\n    dict(type=\"CheckpointSaver\", save_freq=20)\n]\n</code></pre>"},{"location":"models/swin3d/#3","title":"3\u3001\u521b\u5efa\u5177\u4f53\u7f51\u7edc\u6a21\u578b\u7ed3\u6784","text":"<p>\u7531\u4e8e<code>pointcept</code>\u4e2d\u73b0\u6709\u7684\u7f51\u7edc\u7ed3\u6784\u57fa\u672c\u90fd\u662f\u57fa\u4e8e\u70b9\u4e91\u5206\u7c7b\u548c\u70b9\u4e91\u7684\u8bed\u4e49\u5206\u5272\u7684\uff0c\u6ca1\u6709\u76f4\u63a5\u53ef\u7528\u4e8e\u70b9\u4e91\u5173\u952e\u70b9\u9884\u6d4b\u6216\u8005\u56de\u5f52\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u4eff\u7167<code>pointcept/models</code>\u8def\u5f84\u4e0b\uff0c\u5df2\u6709\u7684\u5404\u79cd\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u6765\u4fee\u6539\u5206\u7c7b\u5934\u6216\u8005\u5206\u5272\u5934\uff0c\u6539\u4e3a\u6211\u4eec\u7684\u5173\u952e\u70b9\u56de\u5f52\u5934\uff1b\u5bf9\u4e8e<code>swin3d</code>\u800c\u8a00\uff0c\u6211\u4eec\u5728<code>pointcept/models</code>\u6587\u4ef6\u5939\u4e0b\u521b\u5efa\u6211\u4eec\u7684\u57fa\u4e8e<code>swin3d</code>\u7684\u5173\u952e\u70b9\u56de\u5f52\u5934\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6<code>keypoint_swin3d.py</code>\uff0c\u5177\u4f53\u4ee3\u7801\u5982\u4e0b\uff1a</p> Note <pre><code># ==============================================================================\n# pointcept/models/keypoint_swin3d.py\n# \u4ee3\u7801\u4f5c\u7528\uff1aSwin3D \u5173\u952e\u70b9\u68c0\u6d4b\u6a21\u578b\u67b6\u6784\n# ==============================================================================\n\nimport torch\nimport torch.nn as nn\nfrom pointcept.models.builder import MODELS, build_model\n\n@MODELS.register_module(\"KeypointSwin3D\")\nclass KeypointSwin3D(nn.Module):\n    def __init__(self, \n                backbone_conf, \n                num_keypoints=6, \n                hidden_dim=256):\n        super().__init__()\n        # 1. \u6784\u5efa\u9aa8\u5e72\u7f51\u7edc (Swin3D)\n        self.backbone = build_model(backbone_conf)\n\n        # 2. \u81ea\u52a8\u83b7\u53d6\u9aa8\u5e72\u8f93\u51fa\u901a\u9053\u6570\n        # Swin3D \u7684 channels \u53c2\u6570\u901a\u5e38\u662f\u4e00\u4e2a\u5217\u8868 [C1, C2, C3, C4]\n        if 'channels' in backbone_conf:\n            in_channels = backbone_conf['channels'][0]\n        else:\n            in_channels = 96 # \u9ed8\u8ba4\u5907\u7528\u503c\n\n        # 3. \u56de\u5f52\u5934 (Regression Head)\n        self.num_keypoints = num_keypoints\n        output_dim = num_keypoints * 3\n\n        self.reg_head = nn.Sequential(\n            nn.Linear(in_channels, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n        # 4. \u635f\u5931\u51fd\u6570\n        self.criterion = nn.MSELoss()\n\n    def forward(self, data_dict):\n        # === [\u6838\u5fc3\u4fee\u590d] \u6784\u9020 Swin3D \u5fc5\u987b\u7684 coord_feat ===\n        if \"coord_feat\" not in data_dict:\n            coord = data_dict[\"coord\"]\n            feat = data_dict[\"feat\"]\n\n            # \u83b7\u53d6 Stem Layer (\u7b2c\u4e00\u5c42\u5377\u79ef) \u671f\u671b\u7684\u8f93\u5165\u901a\u9053\u6570\n            # \u4fee\u6b63\uff1a\u6839\u636e mink_layers.py\uff0cMinkConvBNRelu \u4f7f\u7528 conv_layers (Sequential)\n            try:\n                stem = self.backbone.stem_layer\n                if hasattr(stem, \"conv_layers\"): \n                    # \u8bbf\u95ee Sequential \u7684\u7b2c\u4e00\u4e2a\u6a21\u5757 (MinkowskiConvolution)\n                    expected_channels = stem.conv_layers[0].in_channels\n                elif hasattr(stem, \"conv\"):\n                    expected_channels = stem.conv.in_channels\n                else:\n                    # \u5982\u679c\u65e0\u6cd5\u63a8\u65ad\uff0c\u9ed8\u8ba4\u4f7f\u7528\u914d\u7f6e\u4e2d\u7684 feat \u7ef4\u5ea6\n                    expected_channels = feat.shape[1]\n            except Exception:\n                expected_channels = feat.shape[1]\n\n            # \u6839\u636e\u6a21\u578b\u671f\u671b\u51b3\u5b9a\u662f\u5426\u62fc\u63a5\u5750\u6807\n            if expected_channels == feat.shape[1] + 3:\n                data_dict[\"coord_feat\"] = torch.cat([coord, feat], dim=1)\n            else:\n                # \u9ed8\u8ba4\u53ea\u4f7f\u7528\u7279\u5f81 (\u5982\u679c\u662f 4 \u901a\u9053)\n                data_dict[\"coord_feat\"] = feat\n\n        # === 1. \u7279\u5f81\u63d0\u53d6 (Backbone) ===\n        output = self.backbone(data_dict)\n\n        # \u517c\u5bb9\u6027\u5904\u7406\uff1aSwin3D \u53ef\u80fd\u76f4\u63a5\u8fd4\u56de Tensor\uff0c\u4e5f\u53ef\u80fd\u8fd4\u56de SparseTensor\n        if hasattr(output, \"F\"): \n            feat = output.F\n        else: \n            feat = output\n\n        # === 2. \u5168\u5c40\u6c60\u5316 (Global Pooling) ===\n        # \u4f7f\u7528 offset \u5c06 batch \u4e2d\u6bcf\u4e2a\u6837\u672c\u7684\u70b9\u7279\u5f81\u805a\u5408\n        offset = data_dict[\"offset\"].int()\n        batch_feats = []\n        start = 0\n\n        # \u6ce8\u610f\uff1a\u5982\u679c Swin3D \u4f7f\u7528\u4e86\u4f53\u7d20\u5316\u5bfc\u81f4\u70b9\u6570\u53d8\u5316\uff0c\u5fc5\u987b\u4f7f\u7528 offset2batch \u7b49\u65b9\u5f0f\u91cd\u65b0\u8ba1\u7b97\n        # \u4f46 Pointcept \u7684 Swin3DUNet \u5728\u5206\u5272\u6a21\u5f0f\u4e0b\u901a\u5e38\u4f1a\u63d2\u503c\u56de\u539f\u59cb\u70b9\u6570\uff0c\u6216\u8005\u4fdd\u6301\u4e00\u4e00\u5bf9\u5e94\n        # \u4e3a\u4e86\u5b89\u5168\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u957f\u5ea6\u68c0\u67e5\n        if feat.shape[0] != offset[-1].item():\n            # \u5982\u679c\u7279\u5f81\u70b9\u6570\u4e0e\u539f\u59cb offset \u4e0d\u4e00\u81f4 (\u8bf4\u660e\u88ab\u4f53\u7d20\u5316\u4e0b\u91c7\u6837\u4e86)\n            # \u6211\u4eec\u9700\u8981\u91cd\u65b0\u8ba1\u7b97\u4e00\u4e2a batch \u7d22\u5f15\n            batch_idx = data_dict.get(\"batch\", None)\n            if batch_idx is None:\n                # \u5982\u679c\u6ca1\u6709 batch \u7d22\u5f15\uff0c\u5c1d\u8bd5\u7528 coordinates \u63a8\u65ad (SparseTensor \u7684 coordinates \u7b2c\u4e00\u5217\u662f batch_idx)\n                if hasattr(output, \"C\"):\n                    batch_idx = output.C[:, 0]\n                else:\n                    raise RuntimeError(\"Output feature size mismatch and cannot infer batch index.\")\n\n            # \u4f7f\u7528 scatter_mean \u6216\u7b80\u5355\u7684\u5faa\u73af\u8fdb\u884c\u6c60\u5316\n            for b in range(len(offset)):\n                mask = (batch_idx == b)\n                if mask.any():\n                    sample_feat = feat[mask].mean(dim=0)\n                else:\n                    sample_feat = torch.zeros_like(feat[0])\n                batch_feats.append(sample_feat)\n        else:\n            # \u6b63\u5e38\u60c5\u51b5\uff1a\u70b9\u6570\u4e00\u4e00\u5bf9\u5e94\n            for i in range(len(offset)):\n                end = offset[i]\n                sample_feat = feat[start:end].mean(dim=0) \n                batch_feats.append(sample_feat)\n                start = end\n\n        global_feat = torch.stack(batch_feats, dim=0) # (B, C)\n\n        # === 3. \u5173\u952e\u70b9\u56de\u5f52 ===\n        pred_flat = self.reg_head(global_feat)\n        pred = pred_flat.view(-1, self.num_keypoints, 3)\n\n        result_dict = {}\n\n        # === 4. Loss \u4e0e \u76d1\u63a7 ===\n        if \"target\" in data_dict:\n            target = data_dict[\"target\"]\n\n            pred_for_loss = pred if pred.shape == target.shape else pred.view(-1, 3)\n            loss = self.criterion(pred_for_loss, target)\n            if loss.ndim &gt; 0: loss = loss.mean()\n            result_dict[\"loss\"] = loss\n\n            if self.training:\n                with torch.no_grad():\n                    k = self.num_keypoints\n                    pred_metric = pred.view(-1, k, 3)\n                    target_metric = target.view(-1, k, 3)\n\n                    dist = torch.norm(pred_metric - target_metric, p=2, dim=-1)\n\n                    if \"scale\" in data_dict:\n                        scale = data_dict[\"scale\"]\n                        if scale.ndim == 1: scale = scale.view(-1, 1)\n                        dist = dist * scale\n\n                    result_dict[\"train/mean_dist\"] = dist.mean()\n\n                    kp_dist_mean = dist.mean(dim=0)\n                    for i in range(k):\n                        result_dict[f\"train/kp{i}_dist\"] = kp_dist_mean[i]\n\n        if self.training:\n            return result_dict\n        else:\n            result_dict[\"pred\"] = pred\n            return result_dict\n</code></pre> <p>\u5bf9\u4e8e<code>swin3d</code>\u800c\u8a00\uff0c\u6211\u4eec\u53ea\u4f7f\u7528<code>stage5</code>\uff0c\u4e5f\u5c31\u662f\u6700\u540e\u4e00\u4e2a\u9636\u6bb5\u8f93\u51fa\u7684\u6700\u9ad8\u5c42\uff08\u8bed\u4e49\u6700\u5f3a\u3001\u5206\u8fa8\u7387\u6700\u4f4e\uff09\u7684\u7279\u5f81\uff0c\u7136\u540e\u5728\u4f53\u7d20\u6570\u91cf\u7ef4\u5ea6N\u4e0a\u8fdb\u884c\u5e73\u5747\u6c60\u5316\uff0c\u5f97\u5230\u901a\u9053\u4e3a\\(C_5\\)\u7684\u7279\u5f81\u5411\u91cf\uff0c\u7136\u540e\u901a\u8fc7\u56de\u5f52\u5934\uff08\u4e00\u4e2a\u7b80\u5355\u76843\u5c42MLP\uff09\u5c06\u7279\u5f81\u6620\u5c04\u5230<code>number_points*3</code>\u7ef4\u5ea6\u4e0a\uff0c\u7136\u540e\u4f7f\u7528\u771f\u5b9e\u5173\u952e\u70b9\u5750\u6807\u4f18\u5316\u8fd9\u4e2a\u8f93\u51fa\uff0c\u5f97\u5230\u6211\u4eec\u60f3\u8981\u7684\u5173\u952e\u70b9\u5750\u6807\u3002</p> <p>\u521b\u5efa\u597d<code>pointcept/models/keypoint_swin3d.py</code>\u6587\u4ef6\u540e\uff0c\u548c\u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6\u7c7b\u4f3c\uff0c\u5728<code>pointcept/models/__init__.py</code>\u4e2d\u6ce8\u518c\u6211\u4eec\u521b\u5efa\u7684\u6a21\u578b\u7f51\u7edc\u67b6\u6784\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u6587\u4ef6\u672b\u5c3e\u6dfb\u52a0\u4e00\u884c\uff0c\u5bfc\u5165\u6211\u4eec\u521b\u5efa\u7684\u6a21\u578b\u7f51\u7edc\u67b6\u6784\u7c7b</p> Note <pre><code>from .keypoint_swin3d import KeypointSwin3D     # \u57fa\u4e8eSwin3D\u7684\u5173\u952e\u70b9\u68c0\u6d4b\u6a21\u578b\n</code></pre>"},{"location":"models/swin3d/#4","title":"4\u3001\u8bad\u7ec3\u6a21\u578b","text":"<p>\u5728tools/train.py\u4e2d\uff0c\u5206\u522b\u8fd0\u884c\u5982\u4e0b\u4ee3\u7801\uff1a</p> Note <pre><code>export PYTHONPATH=.\nsource .venv/bin/activate\npython tools/train.py --config-file configs/my_dataset/keypoint_swin3d.py\n</code></pre> <p>\u5373\u53ef\u5f00\u59cb\u8bad\u7ec3</p>"},{"location":"models/swin3d/#5","title":"5\u3001\u63a8\u7406","text":"<p>\u65b0\u5efa<code>tools/inference.py</code>\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a\u5b9e\u73b0\u4e86trian\u3001val\u3001test\u7684\u5355\u72ec\u6279\u91cf\u8bc4\u4f30\uff0c\u5e76\u7ed8\u5236\u5173\u952e\u70b9\u8bef\u5dee\u6563\u70b9\u56fe\u3002\u4ee5\u53ca\u5355\u6837\u672c\u63a8\u7406\u5e76\u4f7f\u7528open3d\u7ed8\u5236\u5173\u952e\u70b9\u53ef\u89c6\u5316</p> Note <pre><code>\"\"\"\nKeypoint Detection Inference &amp; Visualization Script\n\u529f\u80fd\uff1a\n1. \u652f\u6301\u5355\u6837\u672c\u63a8\u7406\uff1a\u8ba1\u7b97\u8bef\u5dee + Open3D \u53ef\u89c6\u5316\uff08\u7403\u4f53=\u771f\u503c\uff0c\u7acb\u65b9\u4f53=\u9884\u6d4b\uff09\n2. \u652f\u6301\u6279\u91cf\u63a8\u7406\uff1a\u8ba1\u7b97\u6574\u4e2a\u6570\u636e\u96c6\u7684\u5e73\u5747\u8bef\u5dee (Mean) \u548c\u6807\u51c6\u5dee (Std)\n3. \u67b6\u6784\u901a\u7528\uff1a\u901a\u8fc7 config \u6587\u4ef6\u81ea\u52a8\u52a0\u8f7d\u5bf9\u5e94\u7684\u6a21\u578b\u67b6\u6784\n\"\"\"\n\nimport argparse\nimport os\nimport sys\nimport numpy as np\nimport torch\nimport open3d as o3d\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# \u6dfb\u52a0\u9879\u76ee\u6839\u76ee\u5f55\u5230 python path\uff0c\u786e\u4fdd\u80fd\u5bfc\u5165 pointcept\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"../../\")))\n\nfrom pointcept.utils.config import Config, DictAction\nfrom pointcept.models import build_model\nfrom pointcept.datasets import build_dataset, point_collate_fn\nfrom pointcept.utils.misc import intersection_and_union, make_dirs\nfrom pointcept.engines.defaults import default_argument_parser\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=\"Pointcept Keypoint Inference\")\n    parser.add_argument(\"--config-file\", default=\"configs/my_dataset/keypoint_ptv3.py\", help=\"\u914d\u7f6e\u6587\u4ef6\u8def\u5f84\")\n    parser.add_argument(\"--options\", nargs=\"+\", action=DictAction, help=\"\u8986\u76d6\u914d\u7f6e\u6587\u4ef6\u7684\u53c2\u6570\")\n    parser.add_argument(\"--weights\", default=None, required=True, help=\"\u6a21\u578b\u6743\u91cd\u6587\u4ef6\u8def\u5f84 (.pth)\")\n    parser.add_argument(\"--subset\", default=\"val\", choices=[\"train\", \"val\", \"test\"], help=\"\u6570\u636e\u96c6\u5212\u5206\")\n    parser.add_argument(\"--idx\", type=int, default=-1, help=\"\u5355\u6837\u672c\u7d22\u5f15\u3002\u5982\u679c\u4e3a -1\uff0c\u5219\u8fdb\u884c\u6279\u91cf\u63a8\u7406\")\n\n    # \u53ef\u89c6\u5316\u53c2\u6570\n    parser.add_argument(\"--visualize\", action=\"store_true\", help=\"\u662f\u5426\u5f00\u542f Open3D \u53ef\u89c6\u5316 (\u4ec5\u5355\u6837\u672c\u6a21\u5f0f\u6709\u6548)\")\n    parser.add_argument(\"--sphere-radius\", type=float, default=0.05, help=\"\u771f\u5b9e\u5173\u952e\u70b9(\u7403)\u7684\u534a\u5f84\")\n    parser.add_argument(\"--cube-size\", type=float, default=0.08, help=\"\u9884\u6d4b\u5173\u952e\u70b9(\u6b63\u65b9\u4f53)\u7684\u8fb9\u957f\")\n    parser.add_argument(\"--point-size\", type=float, default=2.0, help=\"Open3D \u53ef\u89c6\u5316\u65f6\u70b9\u4e91\u7684\u70b9\u5927\u5c0f\")\n    parser.add_argument(\"--save-dir\", default=None, help=\"\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84 (\u53ef\u9009)\")\n\n    args = parser.parse_args()\n    return args\n\ndef setup_model(cfg, weights_path):\n    \"\"\"\u52a0\u8f7d\u6a21\u578b\u548c\u6743\u91cd\"\"\"\n    print(f\"=&gt; Building model from config: {cfg.model.type}\")\n    model = build_model(cfg.model)\n\n    if os.path.isfile(weights_path):\n        print(f\"=&gt; Loading weights from {weights_path}\")\n        checkpoint = torch.load(weights_path, map_location=\"cuda\")\n        state_dict = checkpoint.get(\"state_dict\", checkpoint)\n        # \u79fb\u9664 'module.' \u524d\u7f00 (\u5982\u679c\u662f DDP \u8bad\u7ec3\u4fdd\u5b58\u7684)\n        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n        model.load_state_dict(new_state_dict, strict=True)\n    else:\n        raise FileNotFoundError(f\"No weights found at {weights_path}\")\n\n    model.cuda()\n    model.eval()\n    return model\n\ndef create_colored_mesh(geometry_type, center, color, size):\n    \"\"\"\u521b\u5efa\u5e26\u989c\u8272\u7684\u51e0\u4f55\u4f53 (\u7403\u6216\u7acb\u65b9\u4f53)\"\"\"\n    if geometry_type == 'sphere':\n        mesh = o3d.geometry.TriangleMesh.create_sphere(radius=size)\n    elif geometry_type == 'box':\n        mesh = o3d.geometry.TriangleMesh.create_box(width=size, height=size, depth=size)\n        # Box \u9ed8\u8ba4\u539f\u70b9\u5728\u89d2\u843d\uff0c\u9700\u8981\u5e73\u79fb\u5230\u4e2d\u5fc3\n        mesh.translate(-np.array([size/2, size/2, size/2]))\n\n    mesh.translate(center)\n    mesh.paint_uniform_color(color)\n    return mesh\n\ndef visualize_single(coord, pred_kps, target_kps, args, num_kps):\n    \"\"\"\u4f7f\u7528 Open3D \u53ef\u89c6\u5316 (\u652f\u6301\u8c03\u6574\u70b9\u5927\u5c0f)\"\"\"\n    print(f\"=&gt; Visualizing... (Point Size: {args.point_size})\")\n    geometries = []\n\n    # 1. \u70b9\u4e91 (\u7070\u8272)\n    pcd = o3d.geometry.PointCloud()\n    pcd.points = o3d.utility.Vector3dVector(coord)\n    pcd.paint_uniform_color([0.7, 0.7, 0.7]) # \u7070\u8272\u70b9\u4e91\n    geometries.append(pcd)\n\n    # 2. \u5173\u952e\u70b9\u989c\u8272\u6620\u5c04\n    cmap = plt.get_cmap(\"jet\")\n    colors = [cmap(i / (num_kps - 1 if num_kps &gt; 1 else 1))[:3] for i in range(num_kps)]\n\n    # 3. \u7ed8\u5236\u5173\u952e\u70b9\n    for i in range(num_kps):\n        # \u771f\u5b9e\u503c\uff1a\u5706\u7403 (Sphere)\n        if target_kps is not None:\n            sphere = create_colored_mesh('sphere', target_kps[i], colors[i], args.sphere_radius)\n            geometries.append(sphere)\n\n        # \u9884\u6d4b\u503c\uff1a\u6b63\u65b9\u4f53 (Cube)\n        cube = create_colored_mesh('box', pred_kps[i], colors[i], args.cube_size)\n        geometries.append(cube)\n\n    # 4. [\u4fee\u6539\u6838\u5fc3] \u4f7f\u7528 Visualizer \u6765\u63a7\u5236\u6e32\u67d3\u9009\u9879\n    vis = o3d.visualization.Visualizer()\n    vis.create_window(window_name=f\"Sample {args.idx} (Sphere=GT, Cube=Pred)\", width=1024, height=768)\n\n    # \u6dfb\u52a0\u6240\u6709\u51e0\u4f55\u4f53\n    for geom in geometries:\n        vis.add_geometry(geom)\n\n    # \u83b7\u53d6\u5e76\u4fee\u6539\u6e32\u67d3\u9009\u9879\n    opt = vis.get_render_option()\n    opt.point_size = args.point_size        # [\u5173\u952e] \u8bbe\u7f6e\u70b9\u7684\u5927\u5c0f\n    opt.background_color = np.asarray([1, 1, 1]) # [\u53ef\u9009] \u8bbe\u7f6e\u80cc\u666f\u4e3a\u767d\u8272\uff0c\u770b\u8d77\u6765\u66f4\u6e05\u6670\n\n    vis.run()\n    vis.destroy_window()\n\n\ndef inference_single_sample(cfg, model, dataset, args):\n    \"\"\"\u5355\u6837\u672c\u63a8\u7406\u903b\u8f91\"\"\"\n    idx = args.idx\n    if idx &gt;= len(dataset):\n        print(f\"Error: Index {idx} out of bounds (Dataset size: {len(dataset)})\")\n        return\n\n    # 1. \u83b7\u53d6\u6570\u636e\n    data_dict = dataset[idx]\n    # Collate: \u5373\u4f7f\u662f\u5355\u4e2a\u6837\u672c\uff0c\u4e5f\u9700\u8981\u4f2a\u9020\u6210 batch \u4e3a 1 \u7684\u5f62\u5f0f (\u589e\u52a0 batch \u7ef4\u5ea6)\n    data_dict = point_collate_fn([data_dict])\n\n    # \u8f6c\u79fb\u5230 GPU\n    for key in data_dict:\n        if isinstance(data_dict[key], torch.Tensor):\n            data_dict[key] = data_dict[key].cuda(non_blocking=True)\n\n    # 2. \u63a8\u7406\n    with torch.no_grad():\n        result = model(data_dict)\n        # \u517c\u5bb9\u4e0d\u540c\u7684\u8fd4\u56de\u683c\u5f0f (\u6709\u7684\u6a21\u578b\u8fd4\u56de\u5b57\u5178\uff0c\u6709\u7684\u8fd4\u56de Tensor)\n        pred = result[\"pred\"] if isinstance(result, dict) else result\n\n    # 3. \u6570\u636e\u540e\u5904\u7406 (GPU -&gt; CPU -&gt; Numpy)\n    # pred shape: (1, K, 3) -&gt; (K, 3)\n    # target shape: (1, K, 3) -&gt; (K, 3)\n    num_kps = cfg.model.num_keypoints\n    pred = pred.view(-1, num_kps, 3).cpu().numpy()[0]\n\n    target = None\n    if \"target\" in data_dict:\n        target = data_dict[\"target\"].view(-1, num_kps, 3).cpu().numpy()[0]\n\n    # \u83b7\u53d6\u70b9\u4e91\u5750\u6807\u7528\u4e8e\u53ef\u89c6\u5316 (\u4f18\u5148\u7528\u539f\u59cb coord\uff0c\u5982\u679c\u6ca1\u6709\u5219\u7528 grid_coord * grid_size)\n    coord = data_dict[\"coord\"].cpu().numpy()\n\n    # 4. \u8ba1\u7b97\u8bef\u5dee (\u9006\u5f52\u4e00\u5316)\n    scale = 1.0\n    if \"scale\" in data_dict:\n        scale = data_dict[\"scale\"].cpu().numpy()[0] # (1,) -&gt; scalar\n    elif \"grid_size\" in data_dict:\n        # \u5982\u679c\u6ca1\u6709 scale \u53ea\u6709 grid_size\uff0c\u4e14 target \u662f\u4f53\u7d20\u5750\u6807\uff0c\u5219\u7528 grid_size\n        scale = data_dict[\"grid_size\"]\n        if isinstance(scale, torch.Tensor): scale = scale.item()\n\n    print(f\"\\n====== Inference Result [Sample IDX: {idx}] ======\")\n    print(f\"Scale Factor: {scale}\")\n\n    if target is not None:\n        # \u8ba1\u7b97\u6b27\u6c0f\u8ddd\u79bb\n        # \u6ce8\u610f\uff1apred \u548c target \u76ee\u524d\u901a\u5e38\u662f\u5728\u5f52\u4e00\u5316\u5750\u6807\u7cfb\u4e0b\n        diff = np.linalg.norm(pred - target, axis=-1) # (K,)\n\n        # \u9006\u5f52\u4e00\u5316\u5230\u539f\u59cb\u7269\u7406\u5c3a\u5ea6\n        real_diff = diff * scale \n\n        print(\"-\" * 40)\n        print(f\"{'Keypoint ID':&lt;15} | {'Error (Original Scale)':&lt;25}\")\n        print(\"-\" * 40)\n        for i in range(num_kps):\n            print(f\"KP {i:&lt;12} | {real_diff[i]:.4f}\")\n        print(\"-\" * 40)\n        print(f\"Mean Error      | {np.mean(real_diff):.4f}\")\n        print(\"-\" * 40)\n\n    # 5. \u53ef\u89c6\u5316\n    if args.visualize:\n        # \u5750\u6807\u901a\u5e38\u4e5f\u9700\u8981\u7f29\u653e\u4ee5\u4fbf\u53ef\u89c6\u5316\u6b63\u786e\uff08\u5982\u679c coord \u4e5f\u662f\u5f52\u4e00\u5316\u7684\uff09\n        # \u8fd9\u91cc\u6211\u4eec\u76f4\u63a5\u753b\u5f52\u4e00\u5316\u7a7a\u95f4\u4e0b\u7684\uff0c\u6216\u8005\u5168\u90e8\u4e58 scale\n        # \u4e3a\u4e86\u65b9\u4fbf\u89c2\u5bdf\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u76f4\u63a5\u753b\u5f52\u4e00\u5316\u7a7a\u95f4\u4e0b\u7684\u5373\u53ef\uff0c\u53ea\u8981 scale \u4e00\u81f4\n        visualize_single(coord, pred, target, args, num_kps)\n\n\ndef plot_batch_errors(all_errors, num_kps):\n    \"\"\"\n    \u7ed8\u5236\u5173\u952e\u70b9\u8bef\u5dee\u6563\u70b9\u56fe\n    layout: 2\u884c3\u5217 (\u9488\u5bf96\u4e2a\u5173\u952e\u70b9)\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    # \u8bbe\u7f6e\u7ed8\u56fe\u98ce\u683c\n    plt.style.use('ggplot')\n\n    # \u521b\u5efa\u753b\u5e03\uff0c2\u884c3\u5217\n    rows, cols = 2, 3\n    fig, axes = plt.subplots(rows, cols, figsize=(18, 10))\n    fig.suptitle('Keypoint Prediction Errors (Batch Inference)', fontsize=16)\n\n    # \u5c55\u5e73 axes \u65b9\u4fbf\u7d22\u5f15\n    axes = axes.flatten()\n\n    # \u6837\u672c\u5e8f\u53f7 (X\u8f74)\n    x = np.arange(all_errors.shape[0])\n\n    for i in range(num_kps):\n        if i &gt;= len(axes): break # \u9632\u6b62\u5173\u952e\u70b9\u6570\u91cf\u8d85\u8fc7\u5b50\u56fe\u6570\u91cf\n\n        ax = axes[i]\n        y = all_errors[:, i] # \u7b2c i \u4e2a\u5173\u952e\u70b9\u7684\u6240\u6709\u6837\u672c\u8bef\u5dee\n\n        # \u7edf\u8ba1\u6307\u6807\n        mean_val = np.mean(y)\n        std_val = np.std(y)\n        upper_limit = mean_val + 2 * std_val\n\n        # 1. \u7ed8\u5236\u6563\u70b9\n        ax.scatter(x, y, alpha=0.6, s=10, c='blue', label='Sample Error')\n\n        # 2. \u7ed8\u5236\u5e73\u5747\u503c\u865a\u7ebf (\u7ea2\u8272)\n        ax.axhline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.4f}')\n\n        # 3. \u7ed8\u5236 2*\u6807\u51c6\u5dee \u865a\u7ebf (\u7eff\u8272)\n        ax.axhline(upper_limit, color='green', linestyle='--', linewidth=2, label=f'Mean+2Std: {upper_limit:.4f}')\n\n        # \u6807\u7b7e\u8bbe\u7f6e\n        ax.set_title(f'Keypoint {i}', fontsize=12)\n        ax.set_xlabel('Sample Index')\n        ax.set_ylabel('Error (m)')\n        ax.legend(loc='upper right', fontsize=8)\n        ax.grid(True, which='both', linestyle='--', alpha=0.7)\n\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # \u8c03\u6574\u5e03\u5c40\u9632\u6b62\u91cd\u53e0\n    plt.show() # \u5f39\u51fa\u7a97\u53e3\n\ndef inference_batch(cfg, model, dataset, args):\n    \"\"\"\u6279\u91cf\u63a8\u7406\u903b\u8f91\"\"\"\n    print(f\"=&gt; Start Batch Inference on [{args.subset}] set...\")\n    dataloader = torch.utils.data.DataLoader(\n        dataset, \n        batch_size=cfg.data.batch_size if hasattr(cfg.data, \"batch_size\") else 1,\n        shuffle=False, \n        num_workers=cfg.num_worker, \n        collate_fn=point_collate_fn,\n        pin_memory=True\n    )\n\n    num_kps = cfg.model.num_keypoints\n    all_errors = [] # \u5b58\u50a8\u6240\u6709\u6837\u672c\u6240\u6709\u5173\u952e\u70b9\u7684\u8bef\u5dee\n\n    model.eval()\n    with torch.no_grad():\n        for i, data_dict in enumerate(tqdm(dataloader)):\n            # GPU\n            for key in data_dict:\n                if isinstance(data_dict[key], torch.Tensor):\n                    data_dict[key] = data_dict[key].cuda(non_blocking=True)\n\n            # Forward\n            result = model(data_dict)\n            pred = result[\"pred\"] if isinstance(result, dict) else result\n\n            target = data_dict[\"target\"]\n\n            # Reshape (B, K, 3)\n            pred = pred.view(-1, num_kps, 3)\n            target = target.view(-1, num_kps, 3)\n\n            # Calc Distance in Normalized Space\n            dist = torch.norm(pred - target, p=2, dim=-1) # (B, K)\n\n            # Inverse Normalization\n            if \"scale\" in data_dict:\n                scale = data_dict[\"scale\"] # (B,)\n                if scale.ndim == 1: scale = scale.view(-1, 1)\n                dist = dist * scale\n            elif \"grid_size\" in data_dict:\n                # Fallback logic\n                g = data_dict[\"grid_size\"]\n                dist = dist * g\n\n            all_errors.append(dist.cpu().numpy())\n\n    # Concatenate all batches: (Total_Samples, K)\n    all_errors = np.concatenate(all_errors, axis=0)\n\n    # Statistics\n    mean_per_kp = np.mean(all_errors, axis=0)\n    std_per_kp = np.std(all_errors, axis=0)\n    total_mean = np.mean(all_errors)\n\n    print(\"\\n====== Batch Inference Statistics ======\")\n    print(f\"Total Samples: {all_errors.shape[0]}\")\n    print(\"-\" * 65)\n    print(f\"{'Keypoint ID':&lt;15} | {'Mean Error':&lt;20} | {'Std Dev':&lt;20}\")\n    print(\"-\" * 65)\n    for i in range(num_kps):\n        print(f\"KP {i:&lt;12} | {mean_per_kp[i]:.5f}            | {std_per_kp[i]:.5f}\")\n    print(\"-\" * 65)\n    print(f\"{'OVERALL':&lt;15} | {total_mean:.5f}\")\n    print(\"-\" * 65)\n\n    # [\u65b0\u589e] \u8c03\u7528\u7ed8\u56fe\u51fd\u6570\n    print(\"=&gt; Plotting error distribution...\")\n    plot_batch_errors(all_errors, num_kps)\n\ndef main():\n    args = get_args()\n\n    # 1. \u52a0\u8f7d\u914d\u7f6e\n    cfg = Config.fromfile(args.config_file)\n    if args.options:\n        cfg.merge_from_dict(args.options)\n\n    # 2. \u6784\u5efa\u6a21\u578b\n    model = setup_model(cfg, args.weights)\n\n    # 3. \u6784\u5efa\u6570\u636e\u96c6\n    # \u6ce8\u610f\uff1a\u53ea\u6784\u5efa args.subset \u6307\u5b9a\u7684\u90a3\u4e00\u90e8\u5206 (train/val/test)\n    if args.subset not in cfg.data:\n        raise ValueError(f\"Subset {args.subset} not found in config.data\")\n\n    dataset_cfg = cfg.data[args.subset]\n    dataset_cfg.data_root = cfg.data_root # \u786e\u4fdd data_root \u88ab\u6b63\u786e\u4f20\u9012\n    dataset = build_dataset(dataset_cfg)\n\n    print(f\"=&gt; Loaded {len(dataset)} samples from {args.subset} set.\")\n\n    # 4. \u6267\u884c\u63a8\u7406\n    if args.idx != -1:\n        # \u5355\u6837\u672c\u6a21\u5f0f\n        inference_single_sample(cfg, model, dataset, args)\n    else:\n        # \u6279\u91cf\u6a21\u5f0f\n        inference_batch(cfg, model, dataset, args)\n\n\n\"\"\"\n## \u57fa\u4e8e Pointcept-PTv3 \u6a21\u578b\u7684\u63a8\u7406\u811a\u672c\npython tools/inference.py \\\n    --config-file configs/my_dataset/keypoint_ptv3.py \\\n    --weights exp/keypoint_ptv3/model/model_best.pth \\\n    --subset test \\\n    --idx -1 \\\n    --visualize \\\n    --sphere-radius 0.02 \\\n    --cube-size 0.02\n====== Batch Inference Statistics ======\nTotal Samples: 28\n-----------------------------------------------------------------\nKeypoint ID     | Mean Error           | Std Dev             \n-----------------------------------------------------------------\nKP 0            | 22.65371            | 13.36939\nKP 1            | 21.20184            | 13.95168\nKP 2            | 30.23071            | 20.58898\nKP 3            | 27.92994            | 20.37176\nKP 4            | 32.97409            | 18.85650\nKP 5            | 34.39021            | 21.52718\n-----------------------------------------------------------------\nOVERALL         | 28.23009\n-----------------------------------------------------------------\n\n\n\n## \u57fa\u4e8e Pointcept-OctFormer \u6a21\u578b\u7684\u63a8\u7406\u811a\u672c\npython tools/inference.py \\\n    --config-file configs/my_dataset/keypoint_octformer.py \\\n    --weights exp/keypoint_octformer/model/model_best.pth \\\n    --subset test \\\n    --idx -1 \\\n    --visualize \\\n    --sphere-radius 0.02 \\\n    --cube-size 0.02\n====== Batch Inference Statistics ======\nTotal Samples: 28\n-----------------------------------------------------------------\nKeypoint ID     | Mean Error           | Std Dev             \n-----------------------------------------------------------------\nKP 0            | 33.27346            | 16.75899\nKP 1            | 26.27490            | 15.12749\nKP 2            | 31.13291            | 19.68741\nKP 3            | 27.60023            | 18.44568\nKP 4            | 32.59894            | 17.00893\nKP 5            | 38.96297            | 19.05381\n-----------------------------------------------------------------\nOVERALL         | 31.64057\n-----------------------------------------------------------------\n\n## \u57fa\u4e8e Pointcept-PTv1 \u6a21\u578b\u7684\u63a8\u7406\u811a\u672c\nexport PYTHONPATH=.\npython tools/inference.py \\\n    --config-file configs/my_dataset/keypoint_ptv1.py \\\n    --weights exp/keypoint_ptv1/model/model_best.pth \\\n    --subset test \\\n    --idx -1 \\\n    --visualize \\\n    --sphere-radius 0.02 \\\n    --cube-size 0.02\n====== Batch Inference Statistics ======\nTotal Samples: 28\n-----------------------------------------------------------------\nKeypoint ID     | Mean Error           | Std Dev             \n-----------------------------------------------------------------\nKP 0            | 26.13216            | 11.06119\nKP 1            | 24.93169            | 17.54638\nKP 2            | 31.74557            | 21.16514\nKP 3            | 24.36304            | 16.39521\nKP 4            | 22.96082            | 11.83866\nKP 5            | 32.36544            | 11.43148\n-----------------------------------------------------------------\nOVERALL         | 27.08312\n-----------------------------------------------------------------\n\n## \u57fa\u4e8e Pointcept-PTv2 \u6a21\u578b\u7684\u63a8\u7406\u811a\u672c\npython tools/inference.py \\\n    --config-file configs/my_dataset/keypoint_ptv2.py \\\n    --weights exp/keypoint_ptv2/model/model_best.pth \\\n    --subset train \\\n    --idx -1 \\\n    --visualize \\\n    --sphere-radius 0.02 \\\n    --cube-size 0.02\n====== Batch Inference Statistics ======\nTotal Samples: 28\n-----------------------------------------------------------------\nKeypoint ID     | Mean Error           | Std Dev             \n-----------------------------------------------------------------\nKP 0            | 27.17042            | 15.76558\nKP 1            | 21.63920            | 18.46684\nKP 2            | 30.25765            | 20.59952\nKP 3            | 25.22526            | 18.56907\nKP 4            | 25.64672            | 13.56527\nKP 5            | 31.95988            | 13.46944\n-----------------------------------------------------------------\nOVERALL         | 26.98319\n-----------------------------------------------------------------\n\n\n## \u57fa\u4e8e Swin3D \u6a21\u578b\u7684\u63a8\u7406\u811a\u672c\npython tools/inference.py \\\n    --config-file configs/my_dataset/keypoint_swin3d.py \\\n    --weights exp/keypoint_swin3d/model/model_best.pth \\\n    --subset test \\\n    --idx -1 \\\n    --visualize \\\n    --sphere-radius 0.02 \\\n    --cube-size 0.02\n====== Batch Inference Statistics ======\nTotal Samples: 28\n-----------------------------------------------------------------\nKeypoint ID     | Mean Error           | Std Dev             \n-----------------------------------------------------------------\nKP 0            | 19.49621            | 11.82266\nKP 1            | 21.12213            | 17.46186\nKP 2            | 31.11461            | 21.69423\nKP 3            | 25.54762            | 19.42591\nKP 4            | 23.38527            | 13.12805\nKP 5            | 25.49153            | 12.77503\n-----------------------------------------------------------------\nOVERALL         | 24.35956\n-----------------------------------------------------------------\n\"\"\"\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u4f8b\u5982\uff0c</p> Note <pre><code>python tools/inference.py \\\n--config-file configs/my_dataset/keypoint_swin3d.py \\\n--weights exp/keypoint_swin3d/model/model_best.pth \\\n--subset test \\\n--idx 10 \\\n--visualize \\\n--sphere-radius 0.02 \\\n--cube-size 0.02\n</code></pre> <p>\u8fd0\u884c\u6548\u679c\u5982\u4e0b\uff1a</p> Note <pre><code>====== Inference Result [Sample IDX: 10] ======\nScale Factor: 873.6885986328125\n----------------------------------------\nKeypoint ID     | Error (Original Scale)\n----------------------------------------\nKP 0            | 12.1654\nKP 1            | 6.9847\nKP 2            | 10.8451\nKP 3            | 16.2290\nKP 4            | 14.2673\nKP 5            | 12.6374\n----------------------------------------\nMean Error      | 12.1882\n----------------------------------------\n=&gt; Visualizing... (Point Size: 2.0)\n</code></pre> <p></p>Figure 2: image-20251214115708498<p></p>"}]}